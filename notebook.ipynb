{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17ec8d6a-4218-49b9-a549-0977cec82967",
   "metadata": {
    "id": "MVpsYfWg3z0B"
   },
   "source": [
    "# PW1 - Handwritten character recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d682452d-e56e-4de8-a420-4418d63790a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your name here (e.g. \"Edmond Dant√®s\") so I can grade your work\n",
    "your_name = \"Laurent Vong\"\n",
    "assert your_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8538cf7-81e0-481a-8059-be38b611aafb",
   "metadata": {
    "id": "8CcAqNjJ3z0F"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math, sys, os, torch, torchvision\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c864b86e-6e6b-4d8a-82c8-6822072a676f",
   "metadata": {
    "id": "3Wxb9pdV3z0F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu: False \n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using gpu: %s ' % torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa038da6-b812-4053-9b72-8ff97ceb3b9b",
   "metadata": {
    "id": "1Sjq8zzf3z0G"
   },
   "source": [
    "We will be training many models. Select a number of epochs to train each model. If you are using a slow machine, or if you want to restart training often and have many development iterations, we suggest `NUM_EPOCH = 2`. If you are using a fast machine, or have a GPU available, of if you are confident that you can write accurate code first try, you will get better accuracies by increasing this constant. You could be able to afford up to `NUM_EPOCH = 10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "137adce6-13cc-4ccc-aaf3-42230e322a9b",
   "metadata": {
    "id": "L9CF0H4O3z0G"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCH = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce850e9-ef4e-4323-af2d-be6b94e98994",
   "metadata": {
    "id": "65e20f5e"
   },
   "source": [
    "# Part A - Linear, MLP, and CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aff4bd-8b1d-4531-89d8-64ce4e2b6357",
   "metadata": {
    "id": "KSAiV2ov3z0H"
   },
   "source": [
    "## Handwritten digit recognition dataset\n",
    "\n",
    "We will use the MNIST database (Modified National Institute of Standards and Technology database). It contains tens of thousands of pictures of handwritten digits. This database was compiled in 1994, as part of the effort in the 1990s to standardize automation of sorting devices with human input, for instance sorting mail with handwritten postal codes at the post office. This is now often considered one of the first real successes of neural networks, and the first easy example on which performance of new such algorithms is tested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3429898a-0f57-4cdf-9aa6-7b1121ee4e53",
   "metadata": {},
   "source": [
    "Load the dataset (train and test splits) using `torchvision`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e1c523-4b78-492a-b103-2861af8c3d89",
   "metadata": {
    "id": "Zu3hU4dQ3z0H"
   },
   "outputs": [],
   "source": [
    "root_dir = './data/MNIST/'\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=root_dir,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=root_dir,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "batch_size = 8\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77fbaba-b01f-46d0-a1d7-47c59faaf042",
   "metadata": {},
   "source": [
    "How many examples in each split? \n",
    "\n",
    "Plot the first image and label of the training set using `matplotlib`\n",
    "\n",
    "What is the input dimension?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "083f07f4-e129-4e9b-b26e-a32fd4bdb99d",
   "metadata": {
    "id": "9fgMls5P3z0I",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data/MNIST/\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data/MNIST/\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print((train_dataset))\n",
    "print((test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dc2fbd26-b017-435a-822e-ad382eabd8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":dimensions: torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhUUlEQVR4nO3de3RU9fnv8c8QYLiYDIaQWwmYgIrKRQsSs0SMkh9J2roA0YOKq+DxYMXgD0RF0yoX62+lYotURPC0SnQpXmgF1Fq6FEyoNUBBkUWrkdBQQJJwcWUmBAkh2ecPjlNHEnCHGZ4kvF9r7bWYPd9n9jObLR/37D3f8TiO4wgAgLOsg3UDAIBzEwEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQScoV27dsnj8ejXv/512F6zqKhIHo9HRUVFYXtNoLUhgHBOKiwslMfj0ebNm61biYi5c+fK4/GctHTp0sW6NSCoo3UDACJnyZIlOu+884KPo6KiDLsBQhFAQDt20003KS4uzroNoEl8BAc049ixY5o9e7aGDh0qn8+n7t2765prrtEHH3zQbM1TTz2lvn37qmvXrrr22mu1ffv2k8Z8/vnnuummmxQbG6suXbpo2LBheuutt07bz5EjR/T555/r4MGD3/s9OI6jQCAgJr1Ha0QAAc0IBAL6/e9/r8zMTD3xxBOaO3euDhw4oOzsbG3duvWk8S+99JKefvpp5eXlKT8/X9u3b9f111+vqqqq4Jh//OMfuuqqq/TZZ5/p4Ycf1m9+8xt1795dY8eO1cqVK0/Zz6ZNm3TJJZfomWee+d7vIS0tTT6fT9HR0br99ttDegGs8REc0Izzzz9fu3btUufOnYPrpkyZogEDBmjRokV6/vnnQ8aXlZVpx44d+sEPfiBJysnJUXp6up544gktWLBAkjR9+nT16dNHf//73+X1eiVJ99xzj0aMGKGHHnpI48aNC1vv06ZNU0ZGhrxer/76179q8eLF2rRpkzZv3qyYmJiwbAc4EwQQ0IyoqKjgRfvGxkZVV1ersbFRw4YN08cff3zS+LFjxwbDR5KGDx+u9PR0vfvuu1qwYIG++uorrVu3To899phqampUU1MTHJudna05c+boyy+/DHmNb8vMzPzeH6VNnz495PH48eM1fPhwTZw4Uc8++6wefvjh7/U6QCTxERxwCi+++KIGDx6sLl26qGfPnurVq5f+9Kc/ye/3nzT2wgsvPGndRRddpF27dkk6cYbkOI4effRR9erVK2SZM2eOJGn//v0Rey+33XabEhMT9f7770dsG4AbnAEBzXj55Zc1efJkjR07Vg8++KDi4+MVFRWlgoIC7dy50/XrNTY2SpIeeOABZWdnNzmmf//+Z9Tz6aSkpOirr76K6DaA74sAAprxhz/8QWlpaXrzzTfl8XiC6785W/muHTt2nLTuiy++0AUXXCDpxA0BktSpUydlZWWFv+HTcBxHu3bt0hVXXHHWtw00hY/ggGZ8c/3n29ddNm7cqJKSkibHr1q1Sl9++WXw8aZNm7Rx40bl5uZKkuLj45WZmannnntOFRUVJ9UfOHDglP24uQ27qddasmSJDhw4oJycnNPWA2cDZ0A4p73wwgtas2bNSeunT5+un/zkJ3rzzTc1btw4/fjHP1Z5ebmWLl2qSy+9VIcPHz6ppn///hoxYoSmTp2quro6LVy4UD179tSsWbOCYxYvXqwRI0Zo0KBBmjJlitLS0lRVVaWSkhLt3btXn376abO9btq0Sdddd53mzJmjuXPnnvJ99e3bVxMmTNCgQYPUpUsXffjhh3rttdd0+eWX62c/+9n330FABBFAOKctWbKkyfWTJ0/W5MmTVVlZqeeee05/+ctfdOmll+rll1/WihUrmpwk9Kc//ak6dOighQsXav/+/Ro+fLieeeYZJSUlBcdceuml2rx5s+bNm6fCwkIdOnRI8fHxuuKKKzR79uywva+JEyfqo48+0h//+EcdPXpUffv21axZs/SLX/xC3bp1C9t2gDPhcfiKNADAANeAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJVvc9oMbGRu3bt0/R0dEh058AANoGx3FUU1Oj5ORkdejQ/HlOqwugffv2KSUlxboNAMAZ2rNnj3r37t3s860ugKKjoyVJI/QjdVQn424AAG4dV70+1LvBf8+bE7EAWrx4sZ588klVVlZqyJAhWrRokYYPH37aum8+duuoTuroIYAAoM35//PrnO4ySkRuQnj99dc1c+ZMzZkzRx9//LGGDBmi7OzsiP7YFgCgbYlIAC1YsEBTpkzRHXfcoUsvvVRLly5Vt27d9MILL0RicwCANijsAXTs2DFt2bIl5Ae3OnTooKysrCZ/R6Wurk6BQCBkAQC0f2EPoIMHD6qhoUEJCQkh6xMSElRZWXnS+IKCAvl8vuDCHXAAcG4w/yJqfn6+/H5/cNmzZ491SwCAsyDsd8HFxcUpKipKVVVVIeurqqqUmJh40niv1yuv1xvuNgAArVzYz4A6d+6soUOHau3atcF1jY2NWrt2rTIyMsK9OQBAGxWR7wHNnDlTkyZN0rBhwzR8+HAtXLhQtbW1uuOOOyKxOQBAGxSRAJowYYIOHDig2bNnq7KyUpdffrnWrFlz0o0JAIBzl8dxHMe6iW8LBALy+XzK1BhmQgCANui4U68irZbf71dMTEyz48zvggMAnJsIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmOho3QDQmng6uv9PIqpXXAQ6CY/SBy5oUV1Dt0bXNX377Xdd0+0ej+uaygWdXdd8POx11zWSdLCh1nVN+or7Xdf0n7nBdU17wBkQAMAEAQQAMBH2AJo7d648Hk/IMmDAgHBvBgDQxkXkGtBll12m999//z8bacHn6gCA9i0iydCxY0clJiZG4qUBAO1ERK4B7dixQ8nJyUpLS9PEiRO1e/fuZsfW1dUpEAiELACA9i/sAZSenq7CwkKtWbNGS5YsUXl5ua655hrV1NQ0Ob6goEA+ny+4pKSkhLslAEArFPYAys3N1c0336zBgwcrOztb7777rqqrq/XGG280OT4/P19+vz+47NmzJ9wtAQBaoYjfHdCjRw9ddNFFKisra/J5r9crr9cb6TYAAK1MxL8HdPjwYe3cuVNJSUmR3hQAoA0JewA98MADKi4u1q5du/TRRx9p3LhxioqK0q233hruTQEA2rCwfwS3d+9e3XrrrTp06JB69eqlESNGaMOGDerVq1e4NwUAaMPCHkCvvfZauF8SrVTUJRe6rnG8nVzX7Lu2h+uar69yP4mkJMX63Nf9dUjLJrpsb/58JNp1zRPP5Liu2Thoueua8vqvXddI0q+q/st1TfJfnRZt61zEXHAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMRPwH6dD6NWT+sEV1CwoXu665qFPnFm0LZ1e90+C6Zvaiya5rOta6n7gzY8U01zXRXx53XSNJ3oPuJzHttnlji7Z1LuIMCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABggtmwIW/pvhbVbTma4rrmok5VLdpWe3N/xVWua/51OM51TWG/P7iukSR/o/tZqhOe/qhF22rN3O8FuMEZEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABNMRgodr6hsUd2iJ252XfM/ObWua6K2nee65tN7FrmuaanHDw52XVOW1c11TUN1heua2zLucV0jSbv+231Nqj5t0bZw7uIMCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkmI0WLxS4rcV3T6+2ermsaDn3luuaygf/bdY0k/WPkC65r3vq/17quia/+yHVNS3hKWjZBaKr7v1rANc6AAAAmCCAAgAnXAbR+/XrdcMMNSk5Olsfj0apVq0KedxxHs2fPVlJSkrp27aqsrCzt2LEjXP0CANoJ1wFUW1urIUOGaPHixU0+P3/+fD399NNaunSpNm7cqO7duys7O1tHjx4942YBAO2H65sQcnNzlZub2+RzjuNo4cKFeuSRRzRmzBhJ0ksvvaSEhAStWrVKt9xyy5l1CwBoN8J6Dai8vFyVlZXKysoKrvP5fEpPT1dJSdO31dTV1SkQCIQsAID2L6wBVFlZKUlKSEgIWZ+QkBB87rsKCgrk8/mCS0pKSjhbAgC0UuZ3weXn58vv9weXPXv2WLcEADgLwhpAiYmJkqSqqqqQ9VVVVcHnvsvr9SomJiZkAQC0f2ENoNTUVCUmJmrt2rXBdYFAQBs3blRGRkY4NwUAaONc3wV3+PBhlZWVBR+Xl5dr69atio2NVZ8+fTRjxgw9/vjjuvDCC5WamqpHH31UycnJGjt2bDj7BgC0ca4DaPPmzbruuuuCj2fOnClJmjRpkgoLCzVr1izV1tbqrrvuUnV1tUaMGKE1a9aoS5cu4esaANDmeRzHcayb+LZAICCfz6dMjVFHTyfrdtBGffHclS2r+8lS1zV3/HuU65oDI2pc16ixwX0NYOC4U68irZbf7z/ldX3zu+AAAOcmAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJ1z/HALQFlzz0RYvq7hjkfmbrZX3Xnn7Qd1x7c57rmujXN7iuAVozzoAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYYDJStEsN1f4W1R2aeonrmt1vfe265uHHX3Jdk/+/xrmucT7xua6RpJT/KXFf5Dgt2hbOXZwBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMMFkpMC3NH76meuaW+Y96LrmlTm/dl2z9Sr3E5jqKvclknRZ92muay78XYXrmuP/2uW6Bu0HZ0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMeBzHcayb+LZAICCfz6dMjVFHTyfrdoCIcK6+3HVNzK/2uq55Ne0vrmtaasAH/8d1zcXz/K5rGnb8y3UNzq7jTr2KtFp+v18xMTHNjuMMCABgggACAJhwHUDr16/XDTfcoOTkZHk8Hq1atSrk+cmTJ8vj8YQsOTk54eoXANBOuA6g2tpaDRkyRIsXL252TE5OjioqKoLLq6++ekZNAgDaH9e/iJqbm6vc3NxTjvF6vUpMTGxxUwCA9i8i14CKiooUHx+viy++WFOnTtWhQ4eaHVtXV6dAIBCyAADav7AHUE5Ojl566SWtXbtWTzzxhIqLi5Wbm6uGhoYmxxcUFMjn8wWXlJSUcLcEAGiFXH8Edzq33HJL8M+DBg3S4MGD1a9fPxUVFWnUqFEnjc/Pz9fMmTODjwOBACEEAOeAiN+GnZaWpri4OJWVlTX5vNfrVUxMTMgCAGj/Ih5Ae/fu1aFDh5SUlBTpTQEA2hDXH8EdPnw45GymvLxcW7duVWxsrGJjYzVv3jyNHz9eiYmJ2rlzp2bNmqX+/fsrOzs7rI0DANo21wG0efNmXXfddcHH31y/mTRpkpYsWaJt27bpxRdfVHV1tZKTkzV69Gj98pe/lNfrDV/XAIA2j8lIgTYiKiHedc2+Cf1btK2ND/3WdU2HFnyiP7F8tOsa/4jmv9aB1oHJSAEArRoBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwETYf5IbQGQ0VO13XZPwtPsaSTo667jrmm6ezq5rfnfBO65rfjJuhuuabis3uq5B5HEGBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwASTkQIGGkdc7rpm581dXNcMvHyX6xqpZROLtsSir65wXdNt9eYIdAILnAEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwwWSkwLd4hg10XfPFf7ufuPN3V7/oumZkl2Oua86mOqfedc2Gr1Ldb6ixwn0NWiXOgAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJhgMlK0eh1T+7qu2XlHcou2NXfCa65rxp93sEXbas1+XjXMdU3xb69yXXP+iyWua9B+cAYEADBBAAEATLgKoIKCAl155ZWKjo5WfHy8xo4dq9LS0pAxR48eVV5ennr27KnzzjtP48ePV1VVVVibBgC0fa4CqLi4WHl5edqwYYPee+891dfXa/To0aqtrQ2Oue+++/T2229rxYoVKi4u1r59+3TjjTeGvXEAQNvm6iaENWvWhDwuLCxUfHy8tmzZopEjR8rv9+v555/X8uXLdf3110uSli1bpksuuUQbNmzQVVe5v0gJAGifzugakN/vlyTFxsZKkrZs2aL6+nplZWUFxwwYMEB9+vRRSUnTd7vU1dUpEAiELACA9q/FAdTY2KgZM2bo6quv1sCBAyVJlZWV6ty5s3r06BEyNiEhQZWVlU2+TkFBgXw+X3BJSUlpaUsAgDakxQGUl5en7du367XX3H9v4tvy8/Pl9/uDy549e87o9QAAbUOLvog6bdo0vfPOO1q/fr169+4dXJ+YmKhjx46puro65CyoqqpKiYmJTb6W1+uV1+ttSRsAgDbM1RmQ4ziaNm2aVq5cqXXr1ik1NTXk+aFDh6pTp05au3ZtcF1paal2796tjIyM8HQMAGgXXJ0B5eXlafny5Vq9erWio6OD13V8Pp+6du0qn8+nO++8UzNnzlRsbKxiYmJ07733KiMjgzvgAAAhXAXQkiVLJEmZmZkh65ctW6bJkydLkp566il16NBB48ePV11dnbKzs/Xss8+GpVkAQPvhcRzHsW7i2wKBgHw+nzI1Rh09nazbwSl0vKCP6xr/0CTXNRMeW3P6Qd9xd49/ua5p7e6vcP8pQsmz7icVlaTYwk3uixobWrQttD/HnXoVabX8fr9iYmKaHcdccAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEy36RVS0Xh2Tmv7l2VP56oXuLdrW1NRi1zW3Rle1aFut2bQvR7iu+XjJ5a5r4v6w3XVNbE2J6xrgbOEMCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkmIz1LjmUPc19z31eua37e/13XNaO71rquae2qGr5uUd3It+53XTPgkc9d18RWu58ktNF1BdC6cQYEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABJORniW7xrrP+i8GrYhAJ+GzuLqf65rfFo92XeNp8LiuGfB4uesaSbqwaqPrmoYWbQkAZ0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMeBzHcayb+LZAICCfz6dMjVFHTyfrdgAALh136lWk1fL7/YqJiWl2HGdAAAATBBAAwISrACooKNCVV16p6OhoxcfHa+zYsSotLQ0Zk5mZKY/HE7LcfffdYW0aAND2uQqg4uJi5eXlacOGDXrvvfdUX1+v0aNHq7a2NmTclClTVFFREVzmz58f1qYBAG2fq19EXbNmTcjjwsJCxcfHa8uWLRo5cmRwfbdu3ZSYmBieDgEA7dIZXQPy+/2SpNjY2JD1r7zyiuLi4jRw4EDl5+fryJEjzb5GXV2dAoFAyAIAaP9cnQF9W2Njo2bMmKGrr75aAwcODK6/7bbb1LdvXyUnJ2vbtm166KGHVFpaqjfffLPJ1ykoKNC8efNa2gYAoI1q8feApk6dqj//+c/68MMP1bt372bHrVu3TqNGjVJZWZn69et30vN1dXWqq6sLPg4EAkpJSeF7QADQRn3f7wG16Axo2rRpeuedd7R+/fpTho8kpaenS1KzAeT1euX1elvSBgCgDXMVQI7j6N5779XKlStVVFSk1NTU09Zs3bpVkpSUlNSiBgEA7ZOrAMrLy9Py5cu1evVqRUdHq7KyUpLk8/nUtWtX7dy5U8uXL9ePfvQj9ezZU9u2bdN9992nkSNHavDgwRF5AwCAtsnVNSCPx9Pk+mXLlmny5Mnas2ePbr/9dm3fvl21tbVKSUnRuHHj9Mgjj5zyc8BvYy44AGjbInIN6HRZlZKSouLiYjcvCQA4RzEXHADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADAREfrBr7LcRxJ0nHVS45xMwAA146rXtJ//j1vTqsLoJqaGknSh3rXuBMAwJmoqamRz+dr9nmPc7qIOssaGxu1b98+RUdHy+PxhDwXCASUkpKiPXv2KCYmxqhDe+yHE9gPJ7AfTmA/nNAa9oPjOKqpqVFycrI6dGj+Sk+rOwPq0KGDevfufcoxMTEx5/QB9g32wwnshxPYDyewH06w3g+nOvP5BjchAABMEEAAABNtKoC8Xq/mzJkjr9dr3Yop9sMJ7IcT2A8nsB9OaEv7odXdhAAAODe0qTMgAED7QQABAEwQQAAAEwQQAMAEAQQAMNFmAmjx4sW64IIL1KVLF6Wnp2vTpk3WLZ11c+fOlcfjCVkGDBhg3VbErV+/XjfccIOSk5Pl8Xi0atWqkOcdx9Hs2bOVlJSkrl27KisrSzt27LBpNoJOtx8mT5580vGRk5Nj02yEFBQU6Morr1R0dLTi4+M1duxYlZaWhow5evSo8vLy1LNnT5133nkaP368qqqqjDqOjO+zHzIzM086Hu6++26jjpvWJgLo9ddf18yZMzVnzhx9/PHHGjJkiLKzs7V//37r1s66yy67TBUVFcHlww8/tG4p4mprazVkyBAtXry4yefnz5+vp59+WkuXLtXGjRvVvXt3ZWdn6+jRo2e508g63X6QpJycnJDj49VXXz2LHUZecXGx8vLytGHDBr333nuqr6/X6NGjVVtbGxxz33336e2339aKFStUXFysffv26cYbbzTsOvy+z36QpClTpoQcD/PnzzfquBlOGzB8+HAnLy8v+LihocFJTk52CgoKDLs6++bMmeMMGTLEug1TkpyVK1cGHzc2NjqJiYnOk08+GVxXXV3teL1e59VXXzXo8Oz47n5wHMeZNGmSM2bMGJN+rOzfv9+R5BQXFzuOc+LvvlOnTs6KFSuCYz777DNHklNSUmLVZsR9dz84juNce+21zvTp0+2a+h5a/RnQsWPHtGXLFmVlZQXXdejQQVlZWSopKTHszMaOHTuUnJystLQ0TZw4Ubt377ZuyVR5ebkqKytDjg+fz6f09PRz8vgoKipSfHy8Lr74Yk2dOlWHDh2ybimi/H6/JCk2NlaStGXLFtXX14ccDwMGDFCfPn3a9fHw3f3wjVdeeUVxcXEaOHCg8vPzdeTIEYv2mtXqZsP+roMHD6qhoUEJCQkh6xMSEvT5558bdWUjPT1dhYWFuvjii1VRUaF58+bpmmuu0fbt2xUdHW3dnonKykpJavL4+Oa5c0VOTo5uvPFGpaamaufOnfr5z3+u3NxclZSUKCoqyrq9sGtsbNSMGTN09dVXa+DAgZJOHA+dO3dWjx49Qsa25+Ohqf0gSbfddpv69u2r5ORkbdu2TQ899JBKS0v15ptvGnYbqtUHEP4jNzc3+OfBgwcrPT1dffv21RtvvKE777zTsDO0Brfcckvwz4MGDdLgwYPVr18/FRUVadSoUYadRUZeXp62b99+TlwHPZXm9sNdd90V/POgQYOUlJSkUaNGaefOnerXr9/ZbrNJrf4juLi4OEVFRZ10F0tVVZUSExONumodevTooYsuukhlZWXWrZj55hjg+DhZWlqa4uLi2uXxMW3aNL3zzjv64IMPQn4/LDExUceOHVN1dXXI+PZ6PDS3H5qSnp4uSa3qeGj1AdS5c2cNHTpUa9euDa5rbGzU2rVrlZGRYdiZvcOHD2vnzp1KSkqybsVMamqqEhMTQ46PQCCgjRs3nvPHx969e3Xo0KF2dXw4jqNp06Zp5cqVWrdunVJTU0OeHzp0qDp16hRyPJSWlmr37t3t6ng43X5oytatWyWpdR0P1ndBfB+vvfaa4/V6ncLCQuef//ync9dddzk9evRwKisrrVs7q+6//36nqKjIKS8vd/72t785WVlZTlxcnLN//37r1iKqpqbG+eSTT5xPPvnEkeQsWLDA+eSTT5x///vfjuM4zq9+9SunR48ezurVq51t27Y5Y8aMcVJTU52vv/7auPPwOtV+qKmpcR544AGnpKTEKS8vd95//33nhz/8oXPhhRc6R48etW49bKZOner4fD6nqKjIqaioCC5HjhwJjrn77rudPn36OOvWrXM2b97sZGRkOBkZGYZdh9/p9kNZWZnz2GOPOZs3b3bKy8ud1atXO2lpac7IkSONOw/VJgLIcRxn0aJFTp8+fZzOnTs7w4cPdzZs2GDd0lk3YcIEJykpyencubPzgx/8wJkwYYJTVlZm3VbEffDBB46kk5ZJkyY5jnPiVuxHH33USUhIcLxerzNq1CintLTUtukIONV+OHLkiDN69GinV69eTqdOnZy+ffs6U6ZMaXf/k9bU+5fkLFu2LDjm66+/du655x7n/PPPd7p16+aMGzfOqaiosGs6Ak63H3bv3u2MHDnSiY2Ndbxer9O/f3/nwQcfdPx+v23j38HvAQEATLT6a0AAgPaJAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACb+HwnNjsX8THVuAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_dataset[0][0].squeeze())\n",
    "plt.title(f\"Label: {train_dataset[0][1]}\")\n",
    "print(f\":dimensions: {train_dataset[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6380c03-1427-4dea-974e-5a38621ea6c1",
   "metadata": {
    "id": "Guv5_hY63z0L"
   },
   "source": [
    "# A.1 - Linear features\n",
    "\n",
    "We start with a very simple model, linear with respect to pixel values.\n",
    "Use a `preprocess` function to downsample the image to 7x7 pixels, then flatten it and use a `torch.nn.Linear` model.\n",
    "\n",
    "The torch average-pooling function is `torch.nn.functional.avg_pool2d`, check the documentation to set the arguments properly.\n",
    "DO NOT use your implementation of average-pooling, it would take prohibitively long to train and you would not finish the practical.\n",
    "If the training takes too long, go back to the first section and lower the `NUM_EPOCH` constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bb8e5d-7d84-4a59-aa5d-e942ffa22aa8",
   "metadata": {},
   "source": [
    "Again, use matplotlib to visualize an example of downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ac111d5c-dfa2-44e2-9a57-f2f4c2caff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    x = torch.nn.functional.avg_pool2d(x, kernel_size=4)\n",
    "    x = x.view(x.size(0), -1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edc22bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([1, 28, 28])\n",
      "Downsampled shape: torch.Size([1, 7, 7])\n",
      "Flattened shape: torch.Size([1, 49])\n"
     ]
    }
   ],
   "source": [
    "img = train_dataset[0][0]  \n",
    "img_original = img.squeeze().numpy()\n",
    "img_downsampled = torch.nn.functional.avg_pool2d(img, kernel_size=4).squeeze().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_original)\n",
    "plt.title('Original Image (28x28)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_downsampled)\n",
    "plt.title('Downsampled Image (7x7)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Original shape: {img.shape}\")\n",
    "print(f\"Downsampled shape: {torch.nn.functional.avg_pool2d(img, kernel_size=4).shape}\")\n",
    "print(f\"Flattened shape: {preprocess(img.unsqueeze(0)).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6aa4adcb-be17-4f0d-ba9f-4da062227230",
   "metadata": {
    "id": "2v3GqEPU3z0L"
   },
   "outputs": [],
   "source": [
    "### YOUR ( MODEL / PREPROCESSING ) CODE HERE ###\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.linear = nn.Linear(49, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5becae4-e27f-43ed-a1c5-ced8c16f4cac",
   "metadata": {
    "id": "qeWZ7DeNMG20"
   },
   "source": [
    "## A.2 - Loss and optimizer\n",
    "Create a cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a85b789e",
   "metadata": {
    "id": "a85b789e"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = LinearModel().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aec31b-3d2b-4b29-ad85-e88a6e25660a",
   "metadata": {
    "id": "ZCnlsh9iMhx_"
   },
   "source": [
    "## A.3 - Training and testing loops\n",
    "Finally, create the functions `train(model, epoch, preprocess, optimizer)` and `test(model)` to train (one epoch with SGD and a learning rate of $10^{-3}$) and test your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "521e5485-b676-4f73-bedc-d35c5fcfd394",
   "metadata": {
    "id": "iMXijrch3z0L"
   },
   "outputs": [],
   "source": [
    "def train(model, epoch, preprocess, optimizer):\n",
    "    ### YOUR CODE HERE ###\n",
    "    optimizer, train_accuracy = None, None \n",
    "    return optimizer, train_accuracy\n",
    "\n",
    "def test(model, preprocess):\n",
    "    ### YOUR CODE HERE ###\n",
    "    accuracy = None\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e1539b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, preprocess, optimizer):\n",
    "    model.train()  \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        data = preprocess(data)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        \n",
    "        if batch_idx % 100 == 99:\n",
    "            print(f'Epoch: {epoch}, Batch: {batch_idx+1}, Loss: {running_loss/100:.3f}, Accuracy: {100*correct/total:.2f}%')\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    train_accuracy = 100 * correct / total\n",
    "    print(f'Train Accuracy: {train_accuracy:.2f}%')\n",
    "    \n",
    "    return optimizer, train_accuracy\n",
    "\n",
    "\n",
    "def test(model, preprocess):\n",
    "    model.eval()  \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            data = preprocess(data)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3caf21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 100, Loss: 2.297, Accuracy: 10.12%\n",
      "Epoch: 1, Batch: 200, Loss: 2.229, Accuracy: 11.31%\n",
      "Epoch: 1, Batch: 300, Loss: 2.186, Accuracy: 13.33%\n",
      "Epoch: 1, Batch: 400, Loss: 2.135, Accuracy: 15.19%\n",
      "Epoch: 1, Batch: 500, Loss: 2.084, Accuracy: 17.30%\n",
      "Epoch: 1, Batch: 600, Loss: 2.035, Accuracy: 19.71%\n",
      "Epoch: 1, Batch: 700, Loss: 2.025, Accuracy: 22.25%\n",
      "Epoch: 1, Batch: 800, Loss: 1.953, Accuracy: 25.20%\n",
      "Epoch: 1, Batch: 900, Loss: 1.935, Accuracy: 27.92%\n",
      "Epoch: 1, Batch: 1000, Loss: 1.917, Accuracy: 29.94%\n",
      "Epoch: 1, Batch: 1100, Loss: 1.878, Accuracy: 31.94%\n",
      "Epoch: 1, Batch: 1200, Loss: 1.850, Accuracy: 33.78%\n",
      "Epoch: 1, Batch: 1300, Loss: 1.816, Accuracy: 35.47%\n",
      "Epoch: 1, Batch: 1400, Loss: 1.786, Accuracy: 36.90%\n",
      "Epoch: 1, Batch: 1500, Loss: 1.783, Accuracy: 38.21%\n",
      "Epoch: 1, Batch: 1600, Loss: 1.718, Accuracy: 39.59%\n",
      "Epoch: 1, Batch: 1700, Loss: 1.748, Accuracy: 40.47%\n",
      "Epoch: 1, Batch: 1800, Loss: 1.677, Accuracy: 41.72%\n",
      "Epoch: 1, Batch: 1900, Loss: 1.648, Accuracy: 42.92%\n",
      "Epoch: 1, Batch: 2000, Loss: 1.646, Accuracy: 43.91%\n",
      "Epoch: 1, Batch: 2100, Loss: 1.627, Accuracy: 44.80%\n",
      "Epoch: 1, Batch: 2200, Loss: 1.626, Accuracy: 45.53%\n",
      "Epoch: 1, Batch: 2300, Loss: 1.592, Accuracy: 46.33%\n",
      "Epoch: 1, Batch: 2400, Loss: 1.575, Accuracy: 47.13%\n",
      "Epoch: 1, Batch: 2500, Loss: 1.556, Accuracy: 47.97%\n",
      "Epoch: 1, Batch: 2600, Loss: 1.549, Accuracy: 48.68%\n",
      "Epoch: 1, Batch: 2700, Loss: 1.508, Accuracy: 49.37%\n",
      "Epoch: 1, Batch: 2800, Loss: 1.463, Accuracy: 50.05%\n",
      "Epoch: 1, Batch: 2900, Loss: 1.478, Accuracy: 50.69%\n",
      "Epoch: 1, Batch: 3000, Loss: 1.462, Accuracy: 51.26%\n",
      "Epoch: 1, Batch: 3100, Loss: 1.410, Accuracy: 51.89%\n",
      "Epoch: 1, Batch: 3200, Loss: 1.432, Accuracy: 52.43%\n",
      "Epoch: 1, Batch: 3300, Loss: 1.404, Accuracy: 52.98%\n",
      "Epoch: 1, Batch: 3400, Loss: 1.441, Accuracy: 53.39%\n",
      "Epoch: 1, Batch: 3500, Loss: 1.387, Accuracy: 53.77%\n",
      "Epoch: 1, Batch: 3600, Loss: 1.383, Accuracy: 54.21%\n",
      "Epoch: 1, Batch: 3700, Loss: 1.349, Accuracy: 54.66%\n",
      "Epoch: 1, Batch: 3800, Loss: 1.322, Accuracy: 55.12%\n",
      "Epoch: 1, Batch: 3900, Loss: 1.352, Accuracy: 55.50%\n",
      "Epoch: 1, Batch: 4000, Loss: 1.317, Accuracy: 55.90%\n",
      "Epoch: 1, Batch: 4100, Loss: 1.264, Accuracy: 56.36%\n",
      "Epoch: 1, Batch: 4200, Loss: 1.303, Accuracy: 56.74%\n",
      "Epoch: 1, Batch: 4300, Loss: 1.271, Accuracy: 57.15%\n",
      "Epoch: 1, Batch: 4400, Loss: 1.265, Accuracy: 57.49%\n",
      "Epoch: 1, Batch: 4500, Loss: 1.258, Accuracy: 57.83%\n",
      "Epoch: 1, Batch: 4600, Loss: 1.296, Accuracy: 58.08%\n",
      "Epoch: 1, Batch: 4700, Loss: 1.237, Accuracy: 58.40%\n",
      "Epoch: 1, Batch: 4800, Loss: 1.214, Accuracy: 58.73%\n",
      "Epoch: 1, Batch: 4900, Loss: 1.249, Accuracy: 59.06%\n",
      "Epoch: 1, Batch: 5000, Loss: 1.205, Accuracy: 59.39%\n",
      "Epoch: 1, Batch: 5100, Loss: 1.190, Accuracy: 59.69%\n",
      "Epoch: 1, Batch: 5200, Loss: 1.182, Accuracy: 60.03%\n",
      "Epoch: 1, Batch: 5300, Loss: 1.220, Accuracy: 60.25%\n",
      "Epoch: 1, Batch: 5400, Loss: 1.181, Accuracy: 60.57%\n",
      "Epoch: 1, Batch: 5500, Loss: 1.210, Accuracy: 60.82%\n",
      "Epoch: 1, Batch: 5600, Loss: 1.156, Accuracy: 61.08%\n",
      "Epoch: 1, Batch: 5700, Loss: 1.141, Accuracy: 61.36%\n",
      "Epoch: 1, Batch: 5800, Loss: 1.155, Accuracy: 61.61%\n",
      "Epoch: 1, Batch: 5900, Loss: 1.143, Accuracy: 61.83%\n",
      "Epoch: 1, Batch: 6000, Loss: 1.131, Accuracy: 62.08%\n",
      "Epoch: 1, Batch: 6100, Loss: 1.127, Accuracy: 62.33%\n",
      "Epoch: 1, Batch: 6200, Loss: 1.122, Accuracy: 62.56%\n",
      "Epoch: 1, Batch: 6300, Loss: 1.100, Accuracy: 62.75%\n",
      "Epoch: 1, Batch: 6400, Loss: 1.107, Accuracy: 62.94%\n",
      "Epoch: 1, Batch: 6500, Loss: 1.101, Accuracy: 63.13%\n",
      "Epoch: 1, Batch: 6600, Loss: 1.118, Accuracy: 63.31%\n",
      "Epoch: 1, Batch: 6700, Loss: 1.066, Accuracy: 63.53%\n",
      "Epoch: 1, Batch: 6800, Loss: 1.102, Accuracy: 63.71%\n",
      "Epoch: 1, Batch: 6900, Loss: 1.094, Accuracy: 63.88%\n",
      "Epoch: 1, Batch: 7000, Loss: 1.094, Accuracy: 64.07%\n",
      "Epoch: 1, Batch: 7100, Loss: 1.062, Accuracy: 64.26%\n",
      "Epoch: 1, Batch: 7200, Loss: 1.064, Accuracy: 64.43%\n",
      "Epoch: 1, Batch: 7300, Loss: 1.010, Accuracy: 64.63%\n",
      "Epoch: 1, Batch: 7400, Loss: 1.015, Accuracy: 64.80%\n",
      "Epoch: 1, Batch: 7500, Loss: 1.068, Accuracy: 64.96%\n",
      "Train Accuracy: 64.96%\n",
      "Test Accuracy: 78.43%\n",
      "Epoch: 2, Batch: 100, Loss: 1.055, Accuracy: 75.88%\n",
      "Epoch: 2, Batch: 200, Loss: 1.058, Accuracy: 75.62%\n",
      "Epoch: 2, Batch: 300, Loss: 1.040, Accuracy: 76.92%\n",
      "Epoch: 2, Batch: 400, Loss: 1.007, Accuracy: 77.34%\n",
      "Epoch: 2, Batch: 500, Loss: 0.988, Accuracy: 77.95%\n",
      "Epoch: 2, Batch: 600, Loss: 0.988, Accuracy: 78.33%\n",
      "Epoch: 2, Batch: 700, Loss: 0.989, Accuracy: 78.48%\n",
      "Epoch: 2, Batch: 800, Loss: 1.005, Accuracy: 78.47%\n",
      "Epoch: 2, Batch: 900, Loss: 1.010, Accuracy: 78.35%\n",
      "Epoch: 2, Batch: 1000, Loss: 0.991, Accuracy: 78.36%\n",
      "Epoch: 2, Batch: 1100, Loss: 0.997, Accuracy: 78.32%\n",
      "Epoch: 2, Batch: 1200, Loss: 0.994, Accuracy: 78.39%\n",
      "Epoch: 2, Batch: 1300, Loss: 0.984, Accuracy: 78.31%\n",
      "Epoch: 2, Batch: 1400, Loss: 0.974, Accuracy: 78.37%\n",
      "Epoch: 2, Batch: 1500, Loss: 0.992, Accuracy: 78.26%\n",
      "Epoch: 2, Batch: 1600, Loss: 0.983, Accuracy: 78.26%\n",
      "Epoch: 2, Batch: 1700, Loss: 0.997, Accuracy: 78.26%\n",
      "Epoch: 2, Batch: 1800, Loss: 0.938, Accuracy: 78.32%\n",
      "Epoch: 2, Batch: 1900, Loss: 0.970, Accuracy: 78.36%\n",
      "Epoch: 2, Batch: 2000, Loss: 0.942, Accuracy: 78.42%\n",
      "Epoch: 2, Batch: 2100, Loss: 0.956, Accuracy: 78.50%\n",
      "Epoch: 2, Batch: 2200, Loss: 0.950, Accuracy: 78.56%\n",
      "Epoch: 2, Batch: 2300, Loss: 0.924, Accuracy: 78.65%\n",
      "Epoch: 2, Batch: 2400, Loss: 0.958, Accuracy: 78.61%\n",
      "Epoch: 2, Batch: 2500, Loss: 0.931, Accuracy: 78.63%\n",
      "Epoch: 2, Batch: 2600, Loss: 0.917, Accuracy: 78.72%\n",
      "Epoch: 2, Batch: 2700, Loss: 0.897, Accuracy: 78.79%\n",
      "Epoch: 2, Batch: 2800, Loss: 0.930, Accuracy: 78.79%\n",
      "Epoch: 2, Batch: 2900, Loss: 0.900, Accuracy: 78.81%\n",
      "Epoch: 2, Batch: 3000, Loss: 0.910, Accuracy: 78.87%\n",
      "Epoch: 2, Batch: 3100, Loss: 0.893, Accuracy: 78.86%\n",
      "Epoch: 2, Batch: 3200, Loss: 0.882, Accuracy: 78.93%\n",
      "Epoch: 2, Batch: 3300, Loss: 0.905, Accuracy: 78.98%\n",
      "Epoch: 2, Batch: 3400, Loss: 0.919, Accuracy: 79.05%\n",
      "Epoch: 2, Batch: 3500, Loss: 0.929, Accuracy: 79.02%\n",
      "Epoch: 2, Batch: 3600, Loss: 0.891, Accuracy: 79.02%\n",
      "Epoch: 2, Batch: 3700, Loss: 0.894, Accuracy: 79.06%\n",
      "Epoch: 2, Batch: 3800, Loss: 0.879, Accuracy: 79.13%\n",
      "Epoch: 2, Batch: 3900, Loss: 0.846, Accuracy: 79.22%\n",
      "Epoch: 2, Batch: 4000, Loss: 0.866, Accuracy: 79.24%\n",
      "Epoch: 2, Batch: 4100, Loss: 0.904, Accuracy: 79.20%\n",
      "Epoch: 2, Batch: 4200, Loss: 0.891, Accuracy: 79.25%\n",
      "Epoch: 2, Batch: 4300, Loss: 0.860, Accuracy: 79.26%\n",
      "Epoch: 2, Batch: 4400, Loss: 0.855, Accuracy: 79.32%\n",
      "Epoch: 2, Batch: 4500, Loss: 0.866, Accuracy: 79.36%\n",
      "Epoch: 2, Batch: 4600, Loss: 0.853, Accuracy: 79.40%\n",
      "Epoch: 2, Batch: 4700, Loss: 0.860, Accuracy: 79.41%\n",
      "Epoch: 2, Batch: 4800, Loss: 0.849, Accuracy: 79.42%\n",
      "Epoch: 2, Batch: 4900, Loss: 0.877, Accuracy: 79.43%\n",
      "Epoch: 2, Batch: 5000, Loss: 0.824, Accuracy: 79.50%\n",
      "Epoch: 2, Batch: 5100, Loss: 0.870, Accuracy: 79.48%\n",
      "Epoch: 2, Batch: 5200, Loss: 0.864, Accuracy: 79.52%\n",
      "Epoch: 2, Batch: 5300, Loss: 0.843, Accuracy: 79.56%\n",
      "Epoch: 2, Batch: 5400, Loss: 0.832, Accuracy: 79.60%\n",
      "Epoch: 2, Batch: 5500, Loss: 0.852, Accuracy: 79.65%\n",
      "Epoch: 2, Batch: 5600, Loss: 0.842, Accuracy: 79.69%\n",
      "Epoch: 2, Batch: 5700, Loss: 0.814, Accuracy: 79.73%\n",
      "Epoch: 2, Batch: 5800, Loss: 0.801, Accuracy: 79.79%\n",
      "Epoch: 2, Batch: 5900, Loss: 0.841, Accuracy: 79.81%\n",
      "Epoch: 2, Batch: 6000, Loss: 0.821, Accuracy: 79.84%\n",
      "Epoch: 2, Batch: 6100, Loss: 0.835, Accuracy: 79.86%\n",
      "Epoch: 2, Batch: 6200, Loss: 0.835, Accuracy: 79.90%\n",
      "Epoch: 2, Batch: 6300, Loss: 0.791, Accuracy: 79.94%\n",
      "Epoch: 2, Batch: 6400, Loss: 0.774, Accuracy: 80.01%\n",
      "Epoch: 2, Batch: 6500, Loss: 0.825, Accuracy: 80.04%\n",
      "Epoch: 2, Batch: 6600, Loss: 0.819, Accuracy: 80.05%\n",
      "Epoch: 2, Batch: 6700, Loss: 0.839, Accuracy: 80.03%\n",
      "Epoch: 2, Batch: 6800, Loss: 0.792, Accuracy: 80.06%\n",
      "Epoch: 2, Batch: 6900, Loss: 0.825, Accuracy: 80.06%\n",
      "Epoch: 2, Batch: 7000, Loss: 0.818, Accuracy: 80.08%\n",
      "Epoch: 2, Batch: 7100, Loss: 0.798, Accuracy: 80.10%\n",
      "Epoch: 2, Batch: 7200, Loss: 0.802, Accuracy: 80.11%\n",
      "Epoch: 2, Batch: 7300, Loss: 0.797, Accuracy: 80.14%\n",
      "Epoch: 2, Batch: 7400, Loss: 0.816, Accuracy: 80.17%\n",
      "Epoch: 2, Batch: 7500, Loss: 0.816, Accuracy: 80.18%\n",
      "Train Accuracy: 80.18%\n",
      "Test Accuracy: 82.49%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, NUM_EPOCH + 1):\n",
    "    optimizer, train_acc = train(model, epoch, preprocess, optimizer)\n",
    "    test_acc = test(model, preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa359382-2580-44ae-bcdb-3f18cf1f4c61",
   "metadata": {
    "id": "_t4SiXk33z0L"
   },
   "source": [
    "You should get at least 85\\% test accuracy even with only 2 epochs. We will be aiming for around 95\\% test accuracy and above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf28bb4e-7178-4340-9247-f69591e86dcf",
   "metadata": {
    "id": "RrwYAMMBEUPN"
   },
   "source": [
    "## A.4 - Multi-layer perceptron (MLP)\n",
    "\n",
    "Create a class MLP that creates an MLP of given width and depth, and use it to create a 3-layer MLP of width $100$. We will assume that `width > 0` and `depth > 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cb6479-d475-4f0e-b0f7-fdd107d9e835",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8353cd9",
    "outputId": "c7f5eeaf-0638-45c3-842e-4372d21ff712"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, width, depth):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = [nn.Linear(input_dim, width), nn.ReLU()]\n",
    "        for _ in range(depth - 1):\n",
    "            layers.append(nn.Linear(width, width))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        layers.append(nn.Linear(width, output_dim))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92a238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=49, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch: 1, Batch: 100, Loss: 2.309, Accuracy: 14.12%\n",
      "Epoch: 1, Batch: 200, Loss: 2.308, Accuracy: 12.69%\n",
      "Epoch: 1, Batch: 300, Loss: 2.303, Accuracy: 13.21%\n",
      "Epoch: 1, Batch: 400, Loss: 2.294, Accuracy: 13.28%\n",
      "Epoch: 1, Batch: 500, Loss: 2.295, Accuracy: 13.82%\n",
      "Epoch: 1, Batch: 600, Loss: 2.289, Accuracy: 14.35%\n",
      "Epoch: 1, Batch: 700, Loss: 2.285, Accuracy: 14.88%\n",
      "Epoch: 1, Batch: 800, Loss: 2.276, Accuracy: 15.64%\n",
      "Epoch: 1, Batch: 900, Loss: 2.273, Accuracy: 16.29%\n",
      "Epoch: 1, Batch: 1000, Loss: 2.269, Accuracy: 16.91%\n",
      "Epoch: 1, Batch: 1100, Loss: 2.258, Accuracy: 17.83%\n",
      "Epoch: 1, Batch: 1200, Loss: 2.260, Accuracy: 18.54%\n",
      "Epoch: 1, Batch: 1300, Loss: 2.256, Accuracy: 19.23%\n",
      "Epoch: 1, Batch: 1400, Loss: 2.258, Accuracy: 19.79%\n",
      "Epoch: 1, Batch: 1500, Loss: 2.248, Accuracy: 20.53%\n",
      "Epoch: 1, Batch: 1600, Loss: 2.246, Accuracy: 21.33%\n",
      "Epoch: 1, Batch: 1700, Loss: 2.241, Accuracy: 22.02%\n",
      "Epoch: 1, Batch: 1800, Loss: 2.236, Accuracy: 22.82%\n",
      "Epoch: 1, Batch: 1900, Loss: 2.229, Accuracy: 23.63%\n",
      "Epoch: 1, Batch: 2000, Loss: 2.226, Accuracy: 24.43%\n",
      "Epoch: 1, Batch: 2100, Loss: 2.210, Accuracy: 25.29%\n",
      "Epoch: 1, Batch: 2200, Loss: 2.217, Accuracy: 26.05%\n",
      "Epoch: 1, Batch: 2300, Loss: 2.209, Accuracy: 26.73%\n",
      "Epoch: 1, Batch: 2400, Loss: 2.206, Accuracy: 27.38%\n",
      "Epoch: 1, Batch: 2500, Loss: 2.187, Accuracy: 28.13%\n",
      "Epoch: 1, Batch: 2600, Loss: 2.191, Accuracy: 28.83%\n",
      "Epoch: 1, Batch: 2700, Loss: 2.183, Accuracy: 29.54%\n",
      "Epoch: 1, Batch: 2800, Loss: 2.175, Accuracy: 30.22%\n",
      "Epoch: 1, Batch: 2900, Loss: 2.164, Accuracy: 30.97%\n",
      "Epoch: 1, Batch: 3000, Loss: 2.153, Accuracy: 31.71%\n",
      "Epoch: 1, Batch: 3100, Loss: 2.145, Accuracy: 32.38%\n",
      "Epoch: 1, Batch: 3200, Loss: 2.145, Accuracy: 32.93%\n",
      "Epoch: 1, Batch: 3300, Loss: 2.131, Accuracy: 33.56%\n",
      "Epoch: 1, Batch: 3400, Loss: 2.129, Accuracy: 34.13%\n",
      "Epoch: 1, Batch: 3500, Loss: 2.114, Accuracy: 34.68%\n",
      "Epoch: 1, Batch: 3600, Loss: 2.101, Accuracy: 35.25%\n",
      "Epoch: 1, Batch: 3700, Loss: 2.090, Accuracy: 35.84%\n",
      "Epoch: 1, Batch: 3800, Loss: 2.074, Accuracy: 36.37%\n",
      "Epoch: 1, Batch: 3900, Loss: 2.070, Accuracy: 36.88%\n",
      "Epoch: 1, Batch: 4000, Loss: 2.056, Accuracy: 37.43%\n",
      "Epoch: 1, Batch: 4100, Loss: 2.035, Accuracy: 38.02%\n",
      "Epoch: 1, Batch: 4200, Loss: 2.033, Accuracy: 38.54%\n",
      "Epoch: 1, Batch: 4300, Loss: 2.025, Accuracy: 39.01%\n",
      "Epoch: 1, Batch: 4400, Loss: 2.000, Accuracy: 39.46%\n",
      "Epoch: 1, Batch: 4500, Loss: 2.004, Accuracy: 39.83%\n",
      "Epoch: 1, Batch: 4600, Loss: 1.978, Accuracy: 40.25%\n",
      "Epoch: 1, Batch: 4700, Loss: 1.968, Accuracy: 40.66%\n",
      "Epoch: 1, Batch: 4800, Loss: 1.951, Accuracy: 41.05%\n",
      "Epoch: 1, Batch: 4900, Loss: 1.917, Accuracy: 41.47%\n",
      "Epoch: 1, Batch: 5000, Loss: 1.906, Accuracy: 41.83%\n",
      "Epoch: 1, Batch: 5100, Loss: 1.896, Accuracy: 42.20%\n",
      "Epoch: 1, Batch: 5200, Loss: 1.877, Accuracy: 42.54%\n",
      "Epoch: 1, Batch: 5300, Loss: 1.827, Accuracy: 42.95%\n",
      "Epoch: 1, Batch: 5400, Loss: 1.829, Accuracy: 43.30%\n",
      "Epoch: 1, Batch: 5500, Loss: 1.805, Accuracy: 43.66%\n",
      "Epoch: 1, Batch: 5600, Loss: 1.789, Accuracy: 44.01%\n",
      "Epoch: 1, Batch: 5700, Loss: 1.742, Accuracy: 44.35%\n",
      "Epoch: 1, Batch: 5800, Loss: 1.724, Accuracy: 44.68%\n",
      "Epoch: 1, Batch: 5900, Loss: 1.738, Accuracy: 44.91%\n",
      "Epoch: 1, Batch: 6000, Loss: 1.703, Accuracy: 45.18%\n",
      "Epoch: 1, Batch: 6100, Loss: 1.685, Accuracy: 45.45%\n",
      "Epoch: 1, Batch: 6200, Loss: 1.675, Accuracy: 45.72%\n",
      "Epoch: 1, Batch: 6300, Loss: 1.645, Accuracy: 45.99%\n",
      "Epoch: 1, Batch: 6400, Loss: 1.620, Accuracy: 46.27%\n",
      "Epoch: 1, Batch: 6500, Loss: 1.584, Accuracy: 46.59%\n",
      "Epoch: 1, Batch: 6600, Loss: 1.554, Accuracy: 46.87%\n",
      "Epoch: 1, Batch: 6700, Loss: 1.510, Accuracy: 47.14%\n",
      "Epoch: 1, Batch: 6800, Loss: 1.514, Accuracy: 47.38%\n",
      "Epoch: 1, Batch: 6900, Loss: 1.493, Accuracy: 47.66%\n",
      "Epoch: 1, Batch: 7000, Loss: 1.454, Accuracy: 47.94%\n",
      "Epoch: 1, Batch: 7100, Loss: 1.431, Accuracy: 48.20%\n",
      "Epoch: 1, Batch: 7200, Loss: 1.427, Accuracy: 48.43%\n",
      "Epoch: 1, Batch: 7300, Loss: 1.405, Accuracy: 48.68%\n",
      "Epoch: 1, Batch: 7400, Loss: 1.387, Accuracy: 48.93%\n",
      "Epoch: 1, Batch: 7500, Loss: 1.341, Accuracy: 49.18%\n",
      "Train Accuracy: 49.18%\n",
      "Test Accuracy: 67.97%\n",
      "Epoch: 2, Batch: 100, Loss: 1.333, Accuracy: 68.12%\n",
      "Epoch: 2, Batch: 200, Loss: 1.312, Accuracy: 68.38%\n",
      "Epoch: 2, Batch: 300, Loss: 1.308, Accuracy: 68.29%\n",
      "Epoch: 2, Batch: 400, Loss: 1.284, Accuracy: 68.34%\n",
      "Epoch: 2, Batch: 500, Loss: 1.299, Accuracy: 68.67%\n",
      "Epoch: 2, Batch: 600, Loss: 1.227, Accuracy: 68.90%\n",
      "Epoch: 2, Batch: 700, Loss: 1.203, Accuracy: 69.27%\n",
      "Epoch: 2, Batch: 800, Loss: 1.178, Accuracy: 69.73%\n",
      "Epoch: 2, Batch: 900, Loss: 1.232, Accuracy: 69.54%\n",
      "Epoch: 2, Batch: 1000, Loss: 1.141, Accuracy: 69.75%\n",
      "Epoch: 2, Batch: 1100, Loss: 1.160, Accuracy: 69.83%\n",
      "Epoch: 2, Batch: 1200, Loss: 1.111, Accuracy: 70.29%\n",
      "Epoch: 2, Batch: 1300, Loss: 1.140, Accuracy: 70.28%\n",
      "Epoch: 2, Batch: 1400, Loss: 1.136, Accuracy: 70.44%\n",
      "Epoch: 2, Batch: 1500, Loss: 1.093, Accuracy: 70.47%\n",
      "Epoch: 2, Batch: 1600, Loss: 1.065, Accuracy: 70.67%\n",
      "Epoch: 2, Batch: 1700, Loss: 1.090, Accuracy: 70.79%\n",
      "Epoch: 2, Batch: 1800, Loss: 1.043, Accuracy: 71.01%\n",
      "Epoch: 2, Batch: 1900, Loss: 1.028, Accuracy: 71.13%\n",
      "Epoch: 2, Batch: 2000, Loss: 0.994, Accuracy: 71.42%\n",
      "Epoch: 2, Batch: 2100, Loss: 0.989, Accuracy: 71.60%\n",
      "Epoch: 2, Batch: 2200, Loss: 1.010, Accuracy: 71.62%\n",
      "Epoch: 2, Batch: 2300, Loss: 1.033, Accuracy: 71.72%\n",
      "Epoch: 2, Batch: 2400, Loss: 0.987, Accuracy: 71.85%\n",
      "Epoch: 2, Batch: 2500, Loss: 0.932, Accuracy: 72.03%\n",
      "Epoch: 2, Batch: 2600, Loss: 0.953, Accuracy: 72.14%\n",
      "Epoch: 2, Batch: 2700, Loss: 0.941, Accuracy: 72.19%\n",
      "Epoch: 2, Batch: 2800, Loss: 0.933, Accuracy: 72.35%\n",
      "Epoch: 2, Batch: 2900, Loss: 0.931, Accuracy: 72.49%\n",
      "Epoch: 2, Batch: 3000, Loss: 0.910, Accuracy: 72.59%\n",
      "Epoch: 2, Batch: 3100, Loss: 0.919, Accuracy: 72.69%\n",
      "Epoch: 2, Batch: 3200, Loss: 0.912, Accuracy: 72.90%\n",
      "Epoch: 2, Batch: 3300, Loss: 0.912, Accuracy: 72.98%\n",
      "Epoch: 2, Batch: 3400, Loss: 0.931, Accuracy: 73.01%\n",
      "Epoch: 2, Batch: 3500, Loss: 0.849, Accuracy: 73.15%\n",
      "Epoch: 2, Batch: 3600, Loss: 0.915, Accuracy: 73.19%\n",
      "Epoch: 2, Batch: 3700, Loss: 0.868, Accuracy: 73.31%\n",
      "Epoch: 2, Batch: 3800, Loss: 0.890, Accuracy: 73.36%\n",
      "Epoch: 2, Batch: 3900, Loss: 0.812, Accuracy: 73.46%\n",
      "Epoch: 2, Batch: 4000, Loss: 0.848, Accuracy: 73.58%\n",
      "Epoch: 2, Batch: 4100, Loss: 0.832, Accuracy: 73.67%\n",
      "Epoch: 2, Batch: 4200, Loss: 0.838, Accuracy: 73.71%\n",
      "Epoch: 2, Batch: 4300, Loss: 0.852, Accuracy: 73.77%\n",
      "Epoch: 2, Batch: 4400, Loss: 0.844, Accuracy: 73.87%\n",
      "Epoch: 2, Batch: 4500, Loss: 0.810, Accuracy: 73.97%\n",
      "Epoch: 2, Batch: 4600, Loss: 0.789, Accuracy: 74.11%\n",
      "Epoch: 2, Batch: 4700, Loss: 0.817, Accuracy: 74.18%\n",
      "Epoch: 2, Batch: 4800, Loss: 0.766, Accuracy: 74.32%\n",
      "Epoch: 2, Batch: 4900, Loss: 0.783, Accuracy: 74.40%\n",
      "Epoch: 2, Batch: 5000, Loss: 0.749, Accuracy: 74.49%\n",
      "Epoch: 2, Batch: 5100, Loss: 0.741, Accuracy: 74.61%\n",
      "Epoch: 2, Batch: 5200, Loss: 0.732, Accuracy: 74.72%\n",
      "Epoch: 2, Batch: 5300, Loss: 0.735, Accuracy: 74.83%\n",
      "Epoch: 2, Batch: 5400, Loss: 0.775, Accuracy: 74.86%\n",
      "Epoch: 2, Batch: 5500, Loss: 0.755, Accuracy: 74.96%\n",
      "Epoch: 2, Batch: 5600, Loss: 0.742, Accuracy: 75.02%\n",
      "Epoch: 2, Batch: 5700, Loss: 0.712, Accuracy: 75.13%\n",
      "Epoch: 2, Batch: 5800, Loss: 0.739, Accuracy: 75.20%\n",
      "Epoch: 2, Batch: 5900, Loss: 0.735, Accuracy: 75.29%\n",
      "Epoch: 2, Batch: 6000, Loss: 0.713, Accuracy: 75.36%\n",
      "Epoch: 2, Batch: 6100, Loss: 0.736, Accuracy: 75.41%\n",
      "Epoch: 2, Batch: 6200, Loss: 0.717, Accuracy: 75.48%\n",
      "Epoch: 2, Batch: 6300, Loss: 0.733, Accuracy: 75.56%\n",
      "Epoch: 2, Batch: 6400, Loss: 0.717, Accuracy: 75.65%\n",
      "Epoch: 2, Batch: 6500, Loss: 0.699, Accuracy: 75.73%\n",
      "Epoch: 2, Batch: 6600, Loss: 0.732, Accuracy: 75.79%\n",
      "Epoch: 2, Batch: 6700, Loss: 0.680, Accuracy: 75.88%\n",
      "Epoch: 2, Batch: 6800, Loss: 0.668, Accuracy: 75.98%\n",
      "Epoch: 2, Batch: 6900, Loss: 0.697, Accuracy: 76.05%\n",
      "Epoch: 2, Batch: 7000, Loss: 0.686, Accuracy: 76.11%\n",
      "Epoch: 2, Batch: 7100, Loss: 0.700, Accuracy: 76.17%\n",
      "Epoch: 2, Batch: 7200, Loss: 0.692, Accuracy: 76.23%\n",
      "Epoch: 2, Batch: 7300, Loss: 0.676, Accuracy: 76.29%\n",
      "Epoch: 2, Batch: 7400, Loss: 0.677, Accuracy: 76.35%\n",
      "Epoch: 2, Batch: 7500, Loss: 0.676, Accuracy: 76.42%\n",
      "Train Accuracy: 76.42%\n",
      "Test Accuracy: 82.19%\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, width, depth):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "    \n",
    "        layers = []\n",
    "        \n",
    "        layers.append(nn.Linear(input_dim, width))\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "        for i in range(depth - 2):\n",
    "            layers.append(nn.Linear(width, width))\n",
    "            layers.append(nn.ReLU())\n",
    "        \n",
    "        layers.append(nn.Linear(width, output_dim))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "model_mlp = MLP(input_dim=49, output_dim=10, width=100, depth=3).to(device)\n",
    "\n",
    "\n",
    "print(model_mlp)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_mlp = torch.optim.SGD(model_mlp.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCH + 1):\n",
    "    optimizer_mlp, train_acc = train(model_mlp, epoch, preprocess, optimizer_mlp)\n",
    "    test_acc = test(model_mlp, preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ca5a11-93e4-47ab-81f1-e4ee3cae45c9",
   "metadata": {
    "id": "v1czyC9R3z0R"
   },
   "source": [
    "# A.5 - Deep convolutional model\n",
    "\n",
    "Write a convolutional model, with learned features.\n",
    "Use two layers, one convolutional with 8 filters of size 3x3, then take a relu and max-pool with kernel size 2, and finally flatten and add a Linear layer. You can use the identity as pre-processing function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4933e318-5521-4bf8-b011-bdb95ed0d8b0",
   "metadata": {},
   "source": [
    "\n",
    "Here is a little animation to remind you of the sliding window principle of convolutions.\n",
    "\n",
    "![conv](https://github.com//vdumoulin/conv_arithmetic/raw/master/gif/no_padding_no_strides.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7808152a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 100, Loss: 1.098, Accuracy: 66.88%\n",
      "Epoch: 1, Batch: 200, Loss: 0.496, Accuracy: 76.06%\n",
      "Epoch: 1, Batch: 300, Loss: 0.453, Accuracy: 79.50%\n",
      "Epoch: 1, Batch: 400, Loss: 0.365, Accuracy: 82.03%\n",
      "Epoch: 1, Batch: 500, Loss: 0.399, Accuracy: 83.45%\n",
      "Epoch: 1, Batch: 600, Loss: 0.362, Accuracy: 84.35%\n",
      "Epoch: 1, Batch: 700, Loss: 0.285, Accuracy: 85.50%\n",
      "Epoch: 1, Batch: 800, Loss: 0.311, Accuracy: 86.06%\n",
      "Epoch: 1, Batch: 900, Loss: 0.301, Accuracy: 86.61%\n",
      "Epoch: 1, Batch: 1000, Loss: 0.258, Accuracy: 87.20%\n",
      "Epoch: 1, Batch: 1100, Loss: 0.331, Accuracy: 87.47%\n",
      "Epoch: 1, Batch: 1200, Loss: 0.262, Accuracy: 87.92%\n",
      "Epoch: 1, Batch: 1300, Loss: 0.238, Accuracy: 88.31%\n",
      "Epoch: 1, Batch: 1400, Loss: 0.243, Accuracy: 88.57%\n",
      "Epoch: 1, Batch: 1500, Loss: 0.228, Accuracy: 88.92%\n",
      "Epoch: 1, Batch: 1600, Loss: 0.212, Accuracy: 89.23%\n",
      "Epoch: 1, Batch: 1700, Loss: 0.238, Accuracy: 89.42%\n",
      "Epoch: 1, Batch: 1800, Loss: 0.191, Accuracy: 89.70%\n",
      "Epoch: 1, Batch: 1900, Loss: 0.198, Accuracy: 89.96%\n",
      "Epoch: 1, Batch: 2000, Loss: 0.191, Accuracy: 90.17%\n",
      "Epoch: 1, Batch: 2100, Loss: 0.181, Accuracy: 90.36%\n",
      "Epoch: 1, Batch: 2200, Loss: 0.182, Accuracy: 90.55%\n",
      "Epoch: 1, Batch: 2300, Loss: 0.197, Accuracy: 90.70%\n",
      "Epoch: 1, Batch: 2400, Loss: 0.222, Accuracy: 90.79%\n",
      "Epoch: 1, Batch: 2500, Loss: 0.169, Accuracy: 90.97%\n",
      "Epoch: 1, Batch: 2600, Loss: 0.167, Accuracy: 91.14%\n",
      "Epoch: 1, Batch: 2700, Loss: 0.178, Accuracy: 91.29%\n",
      "Epoch: 1, Batch: 2800, Loss: 0.184, Accuracy: 91.40%\n",
      "Epoch: 1, Batch: 2900, Loss: 0.148, Accuracy: 91.55%\n",
      "Epoch: 1, Batch: 3000, Loss: 0.144, Accuracy: 91.68%\n",
      "Epoch: 1, Batch: 3100, Loss: 0.147, Accuracy: 91.81%\n",
      "Epoch: 1, Batch: 3200, Loss: 0.161, Accuracy: 91.89%\n",
      "Epoch: 1, Batch: 3300, Loss: 0.116, Accuracy: 92.02%\n",
      "Epoch: 1, Batch: 3400, Loss: 0.112, Accuracy: 92.17%\n",
      "Epoch: 1, Batch: 3500, Loss: 0.162, Accuracy: 92.22%\n",
      "Epoch: 1, Batch: 3600, Loss: 0.139, Accuracy: 92.32%\n",
      "Epoch: 1, Batch: 3700, Loss: 0.173, Accuracy: 92.40%\n",
      "Epoch: 1, Batch: 3800, Loss: 0.145, Accuracy: 92.47%\n",
      "Epoch: 1, Batch: 3900, Loss: 0.190, Accuracy: 92.53%\n",
      "Epoch: 1, Batch: 4000, Loss: 0.113, Accuracy: 92.63%\n",
      "Epoch: 1, Batch: 4100, Loss: 0.125, Accuracy: 92.72%\n",
      "Epoch: 1, Batch: 4200, Loss: 0.161, Accuracy: 92.79%\n",
      "Epoch: 1, Batch: 4300, Loss: 0.114, Accuracy: 92.87%\n",
      "Epoch: 1, Batch: 4400, Loss: 0.139, Accuracy: 92.94%\n",
      "Epoch: 1, Batch: 4500, Loss: 0.125, Accuracy: 93.03%\n",
      "Epoch: 1, Batch: 4600, Loss: 0.118, Accuracy: 93.10%\n",
      "Epoch: 1, Batch: 4700, Loss: 0.153, Accuracy: 93.13%\n",
      "Epoch: 1, Batch: 4800, Loss: 0.134, Accuracy: 93.20%\n",
      "Epoch: 1, Batch: 4900, Loss: 0.170, Accuracy: 93.24%\n",
      "Epoch: 1, Batch: 5000, Loss: 0.127, Accuracy: 93.29%\n",
      "Epoch: 1, Batch: 5100, Loss: 0.116, Accuracy: 93.35%\n",
      "Epoch: 1, Batch: 5200, Loss: 0.149, Accuracy: 93.40%\n",
      "Epoch: 1, Batch: 5300, Loss: 0.133, Accuracy: 93.45%\n",
      "Epoch: 1, Batch: 5400, Loss: 0.121, Accuracy: 93.50%\n",
      "Epoch: 1, Batch: 5500, Loss: 0.164, Accuracy: 93.54%\n",
      "Epoch: 1, Batch: 5600, Loss: 0.106, Accuracy: 93.59%\n",
      "Epoch: 1, Batch: 5700, Loss: 0.118, Accuracy: 93.64%\n",
      "Epoch: 1, Batch: 5800, Loss: 0.089, Accuracy: 93.70%\n",
      "Epoch: 1, Batch: 5900, Loss: 0.100, Accuracy: 93.76%\n",
      "Epoch: 1, Batch: 6000, Loss: 0.099, Accuracy: 93.81%\n",
      "Epoch: 1, Batch: 6100, Loss: 0.143, Accuracy: 93.84%\n",
      "Epoch: 1, Batch: 6200, Loss: 0.120, Accuracy: 93.89%\n",
      "Epoch: 1, Batch: 6300, Loss: 0.142, Accuracy: 93.91%\n",
      "Epoch: 1, Batch: 6400, Loss: 0.118, Accuracy: 93.94%\n",
      "Epoch: 1, Batch: 6500, Loss: 0.095, Accuracy: 93.99%\n",
      "Epoch: 1, Batch: 6600, Loss: 0.125, Accuracy: 94.04%\n",
      "Epoch: 1, Batch: 6700, Loss: 0.121, Accuracy: 94.07%\n",
      "Epoch: 1, Batch: 6800, Loss: 0.116, Accuracy: 94.10%\n",
      "Epoch: 1, Batch: 6900, Loss: 0.102, Accuracy: 94.15%\n",
      "Epoch: 1, Batch: 7000, Loss: 0.117, Accuracy: 94.18%\n",
      "Epoch: 1, Batch: 7100, Loss: 0.078, Accuracy: 94.23%\n",
      "Epoch: 1, Batch: 7200, Loss: 0.108, Accuracy: 94.26%\n",
      "Epoch: 1, Batch: 7300, Loss: 0.113, Accuracy: 94.29%\n",
      "Epoch: 1, Batch: 7400, Loss: 0.097, Accuracy: 94.33%\n",
      "Epoch: 1, Batch: 7500, Loss: 0.136, Accuracy: 94.36%\n",
      "Train Accuracy: 94.36%\n",
      "Test Accuracy: 97.02%\n",
      "Epoch: 2, Batch: 100, Loss: 0.073, Accuracy: 98.00%\n",
      "Epoch: 2, Batch: 200, Loss: 0.064, Accuracy: 98.25%\n",
      "Epoch: 2, Batch: 300, Loss: 0.107, Accuracy: 97.92%\n",
      "Epoch: 2, Batch: 400, Loss: 0.114, Accuracy: 97.59%\n",
      "Epoch: 2, Batch: 500, Loss: 0.101, Accuracy: 97.53%\n",
      "Epoch: 2, Batch: 600, Loss: 0.104, Accuracy: 97.42%\n",
      "Epoch: 2, Batch: 700, Loss: 0.090, Accuracy: 97.45%\n",
      "Epoch: 2, Batch: 800, Loss: 0.076, Accuracy: 97.47%\n",
      "Epoch: 2, Batch: 900, Loss: 0.095, Accuracy: 97.42%\n",
      "Epoch: 2, Batch: 1000, Loss: 0.097, Accuracy: 97.40%\n",
      "Epoch: 2, Batch: 1100, Loss: 0.079, Accuracy: 97.44%\n",
      "Epoch: 2, Batch: 1200, Loss: 0.066, Accuracy: 97.48%\n",
      "Epoch: 2, Batch: 1300, Loss: 0.065, Accuracy: 97.54%\n",
      "Epoch: 2, Batch: 1400, Loss: 0.098, Accuracy: 97.52%\n",
      "Epoch: 2, Batch: 1500, Loss: 0.091, Accuracy: 97.52%\n",
      "Epoch: 2, Batch: 1600, Loss: 0.068, Accuracy: 97.55%\n",
      "Epoch: 2, Batch: 1700, Loss: 0.080, Accuracy: 97.57%\n",
      "Epoch: 2, Batch: 1800, Loss: 0.114, Accuracy: 97.55%\n",
      "Epoch: 2, Batch: 1900, Loss: 0.089, Accuracy: 97.53%\n",
      "Epoch: 2, Batch: 2000, Loss: 0.122, Accuracy: 97.47%\n",
      "Epoch: 2, Batch: 2100, Loss: 0.083, Accuracy: 97.46%\n",
      "Epoch: 2, Batch: 2200, Loss: 0.078, Accuracy: 97.46%\n",
      "Epoch: 2, Batch: 2300, Loss: 0.104, Accuracy: 97.44%\n",
      "Epoch: 2, Batch: 2400, Loss: 0.078, Accuracy: 97.46%\n",
      "Epoch: 2, Batch: 2500, Loss: 0.074, Accuracy: 97.49%\n",
      "Epoch: 2, Batch: 2600, Loss: 0.082, Accuracy: 97.50%\n",
      "Epoch: 2, Batch: 2700, Loss: 0.082, Accuracy: 97.50%\n",
      "Epoch: 2, Batch: 2800, Loss: 0.067, Accuracy: 97.50%\n",
      "Epoch: 2, Batch: 2900, Loss: 0.070, Accuracy: 97.52%\n",
      "Epoch: 2, Batch: 3000, Loss: 0.049, Accuracy: 97.53%\n",
      "Epoch: 2, Batch: 3100, Loss: 0.073, Accuracy: 97.54%\n",
      "Epoch: 2, Batch: 3200, Loss: 0.043, Accuracy: 97.57%\n",
      "Epoch: 2, Batch: 3300, Loss: 0.070, Accuracy: 97.60%\n",
      "Epoch: 2, Batch: 3400, Loss: 0.069, Accuracy: 97.61%\n",
      "Epoch: 2, Batch: 3500, Loss: 0.111, Accuracy: 97.58%\n",
      "Epoch: 2, Batch: 3600, Loss: 0.077, Accuracy: 97.56%\n",
      "Epoch: 2, Batch: 3700, Loss: 0.091, Accuracy: 97.55%\n",
      "Epoch: 2, Batch: 3800, Loss: 0.090, Accuracy: 97.53%\n",
      "Epoch: 2, Batch: 3900, Loss: 0.067, Accuracy: 97.54%\n",
      "Epoch: 2, Batch: 4000, Loss: 0.107, Accuracy: 97.51%\n",
      "Epoch: 2, Batch: 4100, Loss: 0.079, Accuracy: 97.52%\n",
      "Epoch: 2, Batch: 4200, Loss: 0.075, Accuracy: 97.53%\n",
      "Epoch: 2, Batch: 4300, Loss: 0.064, Accuracy: 97.52%\n",
      "Epoch: 2, Batch: 4400, Loss: 0.089, Accuracy: 97.53%\n",
      "Epoch: 2, Batch: 4500, Loss: 0.089, Accuracy: 97.53%\n",
      "Epoch: 2, Batch: 4600, Loss: 0.108, Accuracy: 97.53%\n",
      "Epoch: 2, Batch: 4700, Loss: 0.088, Accuracy: 97.52%\n",
      "Epoch: 2, Batch: 4800, Loss: 0.091, Accuracy: 97.52%\n",
      "Epoch: 2, Batch: 4900, Loss: 0.061, Accuracy: 97.53%\n",
      "Epoch: 2, Batch: 5000, Loss: 0.064, Accuracy: 97.54%\n",
      "Epoch: 2, Batch: 5100, Loss: 0.071, Accuracy: 97.54%\n",
      "Epoch: 2, Batch: 5200, Loss: 0.085, Accuracy: 97.54%\n",
      "Epoch: 2, Batch: 5300, Loss: 0.082, Accuracy: 97.53%\n",
      "Epoch: 2, Batch: 5400, Loss: 0.117, Accuracy: 97.50%\n",
      "Epoch: 2, Batch: 5500, Loss: 0.077, Accuracy: 97.50%\n",
      "Epoch: 2, Batch: 5600, Loss: 0.085, Accuracy: 97.50%\n",
      "Epoch: 2, Batch: 5700, Loss: 0.103, Accuracy: 97.50%\n",
      "Epoch: 2, Batch: 5800, Loss: 0.076, Accuracy: 97.51%\n",
      "Epoch: 2, Batch: 5900, Loss: 0.073, Accuracy: 97.51%\n",
      "Epoch: 2, Batch: 6000, Loss: 0.120, Accuracy: 97.49%\n",
      "Epoch: 2, Batch: 6100, Loss: 0.048, Accuracy: 97.50%\n",
      "Epoch: 2, Batch: 6200, Loss: 0.083, Accuracy: 97.52%\n",
      "Epoch: 2, Batch: 6300, Loss: 0.071, Accuracy: 97.52%\n",
      "Epoch: 2, Batch: 6400, Loss: 0.098, Accuracy: 97.51%\n",
      "Epoch: 2, Batch: 6500, Loss: 0.122, Accuracy: 97.49%\n",
      "Epoch: 2, Batch: 6600, Loss: 0.116, Accuracy: 97.47%\n",
      "Epoch: 2, Batch: 6700, Loss: 0.078, Accuracy: 97.47%\n",
      "Epoch: 2, Batch: 6800, Loss: 0.081, Accuracy: 97.47%\n",
      "Epoch: 2, Batch: 6900, Loss: 0.054, Accuracy: 97.48%\n",
      "Epoch: 2, Batch: 7000, Loss: 0.075, Accuracy: 97.48%\n",
      "Epoch: 2, Batch: 7100, Loss: 0.070, Accuracy: 97.49%\n",
      "Epoch: 2, Batch: 7200, Loss: 0.128, Accuracy: 97.48%\n",
      "Epoch: 2, Batch: 7300, Loss: 0.106, Accuracy: 97.47%\n",
      "Epoch: 2, Batch: 7400, Loss: 0.064, Accuracy: 97.48%\n",
      "Epoch: 2, Batch: 7500, Loss: 0.072, Accuracy: 97.49%\n",
      "Train Accuracy: 97.49%\n",
      "Test Accuracy: 97.57%\n",
      "Epoch: 3, Batch: 100, Loss: 0.066, Accuracy: 98.38%\n",
      "Epoch: 3, Batch: 200, Loss: 0.064, Accuracy: 97.88%\n",
      "Epoch: 3, Batch: 300, Loss: 0.056, Accuracy: 97.92%\n",
      "Epoch: 3, Batch: 400, Loss: 0.031, Accuracy: 98.19%\n",
      "Epoch: 3, Batch: 500, Loss: 0.074, Accuracy: 98.20%\n",
      "Epoch: 3, Batch: 600, Loss: 0.048, Accuracy: 98.29%\n",
      "Epoch: 3, Batch: 700, Loss: 0.073, Accuracy: 98.23%\n",
      "Epoch: 3, Batch: 800, Loss: 0.048, Accuracy: 98.33%\n",
      "Epoch: 3, Batch: 900, Loss: 0.065, Accuracy: 98.32%\n",
      "Epoch: 3, Batch: 1000, Loss: 0.082, Accuracy: 98.25%\n",
      "Epoch: 3, Batch: 1100, Loss: 0.075, Accuracy: 98.22%\n",
      "Epoch: 3, Batch: 1200, Loss: 0.061, Accuracy: 98.23%\n",
      "Epoch: 3, Batch: 1300, Loss: 0.061, Accuracy: 98.18%\n",
      "Epoch: 3, Batch: 1400, Loss: 0.083, Accuracy: 98.13%\n",
      "Epoch: 3, Batch: 1500, Loss: 0.047, Accuracy: 98.14%\n",
      "Epoch: 3, Batch: 1600, Loss: 0.058, Accuracy: 98.16%\n",
      "Epoch: 3, Batch: 1700, Loss: 0.065, Accuracy: 98.11%\n",
      "Epoch: 3, Batch: 1800, Loss: 0.054, Accuracy: 98.14%\n",
      "Epoch: 3, Batch: 1900, Loss: 0.078, Accuracy: 98.12%\n",
      "Epoch: 3, Batch: 2000, Loss: 0.074, Accuracy: 98.11%\n",
      "Epoch: 3, Batch: 2100, Loss: 0.062, Accuracy: 98.09%\n",
      "Epoch: 3, Batch: 2200, Loss: 0.066, Accuracy: 98.08%\n",
      "Epoch: 3, Batch: 2300, Loss: 0.075, Accuracy: 98.04%\n",
      "Epoch: 3, Batch: 2400, Loss: 0.046, Accuracy: 98.05%\n",
      "Epoch: 3, Batch: 2500, Loss: 0.065, Accuracy: 98.05%\n",
      "Epoch: 3, Batch: 2600, Loss: 0.067, Accuracy: 98.02%\n",
      "Epoch: 3, Batch: 2700, Loss: 0.057, Accuracy: 98.06%\n",
      "Epoch: 3, Batch: 2800, Loss: 0.056, Accuracy: 98.07%\n",
      "Epoch: 3, Batch: 2900, Loss: 0.086, Accuracy: 98.06%\n",
      "Epoch: 3, Batch: 3000, Loss: 0.064, Accuracy: 98.05%\n",
      "Epoch: 3, Batch: 3100, Loss: 0.064, Accuracy: 98.06%\n",
      "Epoch: 3, Batch: 3200, Loss: 0.051, Accuracy: 98.07%\n",
      "Epoch: 3, Batch: 3300, Loss: 0.060, Accuracy: 98.08%\n",
      "Epoch: 3, Batch: 3400, Loss: 0.075, Accuracy: 98.08%\n",
      "Epoch: 3, Batch: 3500, Loss: 0.071, Accuracy: 98.07%\n",
      "Epoch: 3, Batch: 3600, Loss: 0.053, Accuracy: 98.04%\n",
      "Epoch: 3, Batch: 3700, Loss: 0.094, Accuracy: 98.03%\n",
      "Epoch: 3, Batch: 3800, Loss: 0.079, Accuracy: 98.02%\n",
      "Epoch: 3, Batch: 3900, Loss: 0.080, Accuracy: 98.01%\n",
      "Epoch: 3, Batch: 4000, Loss: 0.040, Accuracy: 98.04%\n",
      "Epoch: 3, Batch: 4100, Loss: 0.069, Accuracy: 98.04%\n",
      "Epoch: 3, Batch: 4200, Loss: 0.045, Accuracy: 98.04%\n",
      "Epoch: 3, Batch: 4300, Loss: 0.059, Accuracy: 98.05%\n",
      "Epoch: 3, Batch: 4400, Loss: 0.074, Accuracy: 98.04%\n",
      "Epoch: 3, Batch: 4500, Loss: 0.055, Accuracy: 98.05%\n",
      "Epoch: 3, Batch: 4600, Loss: 0.063, Accuracy: 98.04%\n",
      "Epoch: 3, Batch: 4700, Loss: 0.089, Accuracy: 98.03%\n",
      "Epoch: 3, Batch: 4800, Loss: 0.089, Accuracy: 98.03%\n",
      "Epoch: 3, Batch: 4900, Loss: 0.089, Accuracy: 98.02%\n",
      "Epoch: 3, Batch: 5000, Loss: 0.052, Accuracy: 98.03%\n",
      "Epoch: 3, Batch: 5100, Loss: 0.056, Accuracy: 98.03%\n",
      "Epoch: 3, Batch: 5200, Loss: 0.062, Accuracy: 98.03%\n",
      "Epoch: 3, Batch: 5300, Loss: 0.094, Accuracy: 98.01%\n",
      "Epoch: 3, Batch: 5400, Loss: 0.055, Accuracy: 98.02%\n",
      "Epoch: 3, Batch: 5500, Loss: 0.051, Accuracy: 98.03%\n",
      "Epoch: 3, Batch: 5600, Loss: 0.059, Accuracy: 98.04%\n",
      "Epoch: 3, Batch: 5700, Loss: 0.112, Accuracy: 98.02%\n",
      "Epoch: 3, Batch: 5800, Loss: 0.064, Accuracy: 98.01%\n",
      "Epoch: 3, Batch: 5900, Loss: 0.084, Accuracy: 98.00%\n",
      "Epoch: 3, Batch: 6000, Loss: 0.041, Accuracy: 98.01%\n",
      "Epoch: 3, Batch: 6100, Loss: 0.057, Accuracy: 98.01%\n",
      "Epoch: 3, Batch: 6200, Loss: 0.067, Accuracy: 98.01%\n",
      "Epoch: 3, Batch: 6300, Loss: 0.040, Accuracy: 98.02%\n",
      "Epoch: 3, Batch: 6400, Loss: 0.068, Accuracy: 98.02%\n",
      "Epoch: 3, Batch: 6500, Loss: 0.057, Accuracy: 98.02%\n",
      "Epoch: 3, Batch: 6600, Loss: 0.074, Accuracy: 98.02%\n",
      "Epoch: 3, Batch: 6700, Loss: 0.074, Accuracy: 98.02%\n",
      "Epoch: 3, Batch: 6800, Loss: 0.053, Accuracy: 98.02%\n",
      "Epoch: 3, Batch: 6900, Loss: 0.069, Accuracy: 98.02%\n",
      "Epoch: 3, Batch: 7000, Loss: 0.050, Accuracy: 98.03%\n",
      "Epoch: 3, Batch: 7100, Loss: 0.069, Accuracy: 98.02%\n",
      "Epoch: 3, Batch: 7200, Loss: 0.068, Accuracy: 98.01%\n",
      "Epoch: 3, Batch: 7300, Loss: 0.069, Accuracy: 98.01%\n",
      "Epoch: 3, Batch: 7400, Loss: 0.047, Accuracy: 98.01%\n",
      "Epoch: 3, Batch: 7500, Loss: 0.034, Accuracy: 98.03%\n",
      "Train Accuracy: 98.03%\n",
      "Test Accuracy: 97.87%\n"
     ]
    }
   ],
   "source": [
    "class ConvModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvModel, self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.flat_features = 1352\n",
    "        self.fc = torch.nn.Linear(self.flat_features, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x) \n",
    "        x = self.relu(x)  \n",
    "        x = self.pool(x)  \n",
    "        x = x.view(-1, self.flat_features)  \n",
    "        x = self.fc(x)  \n",
    "        return x\n",
    "\n",
    "\n",
    "model_conv = ConvModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_conv = torch.optim.Adam(model_conv.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "def identity_preprocess(x):\n",
    "    return x\n",
    "\n",
    "for epoch in range(1, NUM_EPOCH + 2):\n",
    "    optimizer_conv, train_acc = train(model_conv, epoch, identity_preprocess, optimizer_conv)\n",
    "    test_acc = test(model_conv, identity_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0313eed-03ad-461d-9ddb-bb690c631149",
   "metadata": {
    "id": "pbQ1LUqf3z0R"
   },
   "source": [
    "You should be able to get around 97\\% to 98\\% accuracy with this model. Try increasing the NUM_EPOCH constant and watch what happens to test accuracy and train accuracy as training progresses further.\n",
    "\n",
    "Write a deeper convolutional model, with one convolutional layer as previously, but three linear layers with relu activations after that.\n",
    "Use `h = 100` hidden neurons. How does the test accuracy compare with the previous two-layer network ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46285c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 100, Loss: 1.298, Accuracy: 59.88%\n",
      "Epoch: 1, Batch: 200, Loss: 0.562, Accuracy: 71.06%\n",
      "Epoch: 1, Batch: 300, Loss: 0.415, Accuracy: 76.33%\n",
      "Epoch: 1, Batch: 400, Loss: 0.469, Accuracy: 78.69%\n",
      "Epoch: 1, Batch: 500, Loss: 0.428, Accuracy: 80.42%\n",
      "Epoch: 1, Batch: 600, Loss: 0.329, Accuracy: 81.98%\n",
      "Epoch: 1, Batch: 700, Loss: 0.312, Accuracy: 83.20%\n",
      "Epoch: 1, Batch: 800, Loss: 0.224, Accuracy: 84.47%\n",
      "Epoch: 1, Batch: 900, Loss: 0.337, Accuracy: 84.99%\n",
      "Epoch: 1, Batch: 1000, Loss: 0.235, Accuracy: 85.66%\n",
      "Epoch: 1, Batch: 1100, Loss: 0.218, Accuracy: 86.34%\n",
      "Epoch: 1, Batch: 1200, Loss: 0.248, Accuracy: 86.81%\n",
      "Epoch: 1, Batch: 1300, Loss: 0.295, Accuracy: 87.11%\n",
      "Epoch: 1, Batch: 1400, Loss: 0.219, Accuracy: 87.49%\n",
      "Epoch: 1, Batch: 1500, Loss: 0.217, Accuracy: 87.83%\n",
      "Epoch: 1, Batch: 1600, Loss: 0.193, Accuracy: 88.14%\n",
      "Epoch: 1, Batch: 1700, Loss: 0.164, Accuracy: 88.52%\n",
      "Epoch: 1, Batch: 1800, Loss: 0.235, Accuracy: 88.78%\n",
      "Epoch: 1, Batch: 1900, Loss: 0.151, Accuracy: 89.12%\n",
      "Epoch: 1, Batch: 2000, Loss: 0.142, Accuracy: 89.46%\n",
      "Epoch: 1, Batch: 2100, Loss: 0.199, Accuracy: 89.68%\n",
      "Epoch: 1, Batch: 2200, Loss: 0.178, Accuracy: 89.90%\n",
      "Epoch: 1, Batch: 2300, Loss: 0.164, Accuracy: 90.14%\n",
      "Epoch: 1, Batch: 2400, Loss: 0.137, Accuracy: 90.40%\n",
      "Epoch: 1, Batch: 2500, Loss: 0.177, Accuracy: 90.56%\n",
      "Epoch: 1, Batch: 2600, Loss: 0.164, Accuracy: 90.74%\n",
      "Epoch: 1, Batch: 2700, Loss: 0.160, Accuracy: 90.86%\n",
      "Epoch: 1, Batch: 2800, Loss: 0.169, Accuracy: 91.01%\n",
      "Epoch: 1, Batch: 2900, Loss: 0.134, Accuracy: 91.18%\n",
      "Epoch: 1, Batch: 3000, Loss: 0.233, Accuracy: 91.23%\n",
      "Epoch: 1, Batch: 3100, Loss: 0.149, Accuracy: 91.36%\n",
      "Epoch: 1, Batch: 3200, Loss: 0.127, Accuracy: 91.49%\n",
      "Epoch: 1, Batch: 3300, Loss: 0.142, Accuracy: 91.62%\n",
      "Epoch: 1, Batch: 3400, Loss: 0.097, Accuracy: 91.76%\n",
      "Epoch: 1, Batch: 3500, Loss: 0.145, Accuracy: 91.87%\n",
      "Epoch: 1, Batch: 3600, Loss: 0.140, Accuracy: 91.98%\n",
      "Epoch: 1, Batch: 3700, Loss: 0.094, Accuracy: 92.11%\n",
      "Epoch: 1, Batch: 3800, Loss: 0.108, Accuracy: 92.26%\n",
      "Epoch: 1, Batch: 3900, Loss: 0.110, Accuracy: 92.36%\n",
      "Epoch: 1, Batch: 4000, Loss: 0.112, Accuracy: 92.45%\n",
      "Epoch: 1, Batch: 4100, Loss: 0.099, Accuracy: 92.55%\n",
      "Epoch: 1, Batch: 4200, Loss: 0.097, Accuracy: 92.65%\n",
      "Epoch: 1, Batch: 4300, Loss: 0.095, Accuracy: 92.75%\n",
      "Epoch: 1, Batch: 4400, Loss: 0.100, Accuracy: 92.85%\n",
      "Epoch: 1, Batch: 4500, Loss: 0.118, Accuracy: 92.93%\n",
      "Epoch: 1, Batch: 4600, Loss: 0.109, Accuracy: 93.01%\n",
      "Epoch: 1, Batch: 4700, Loss: 0.122, Accuracy: 93.06%\n",
      "Epoch: 1, Batch: 4800, Loss: 0.114, Accuracy: 93.13%\n",
      "Epoch: 1, Batch: 4900, Loss: 0.171, Accuracy: 93.17%\n",
      "Epoch: 1, Batch: 5000, Loss: 0.090, Accuracy: 93.25%\n",
      "Epoch: 1, Batch: 5100, Loss: 0.083, Accuracy: 93.34%\n",
      "Epoch: 1, Batch: 5200, Loss: 0.092, Accuracy: 93.40%\n",
      "Epoch: 1, Batch: 5300, Loss: 0.116, Accuracy: 93.48%\n",
      "Epoch: 1, Batch: 5400, Loss: 0.076, Accuracy: 93.56%\n",
      "Epoch: 1, Batch: 5500, Loss: 0.118, Accuracy: 93.60%\n",
      "Epoch: 1, Batch: 5600, Loss: 0.110, Accuracy: 93.66%\n",
      "Epoch: 1, Batch: 5700, Loss: 0.118, Accuracy: 93.73%\n",
      "Epoch: 1, Batch: 5800, Loss: 0.115, Accuracy: 93.77%\n",
      "Epoch: 1, Batch: 5900, Loss: 0.069, Accuracy: 93.83%\n",
      "Epoch: 1, Batch: 6000, Loss: 0.105, Accuracy: 93.88%\n",
      "Epoch: 1, Batch: 6100, Loss: 0.110, Accuracy: 93.92%\n",
      "Epoch: 1, Batch: 6200, Loss: 0.100, Accuracy: 93.97%\n",
      "Epoch: 1, Batch: 6300, Loss: 0.117, Accuracy: 94.01%\n",
      "Epoch: 1, Batch: 6400, Loss: 0.084, Accuracy: 94.06%\n",
      "Epoch: 1, Batch: 6500, Loss: 0.081, Accuracy: 94.11%\n",
      "Epoch: 1, Batch: 6600, Loss: 0.106, Accuracy: 94.15%\n",
      "Epoch: 1, Batch: 6700, Loss: 0.105, Accuracy: 94.19%\n",
      "Epoch: 1, Batch: 6800, Loss: 0.074, Accuracy: 94.25%\n",
      "Epoch: 1, Batch: 6900, Loss: 0.091, Accuracy: 94.29%\n",
      "Epoch: 1, Batch: 7000, Loss: 0.085, Accuracy: 94.34%\n",
      "Epoch: 1, Batch: 7100, Loss: 0.095, Accuracy: 94.38%\n",
      "Epoch: 1, Batch: 7200, Loss: 0.079, Accuracy: 94.43%\n",
      "Epoch: 1, Batch: 7300, Loss: 0.094, Accuracy: 94.45%\n",
      "Epoch: 1, Batch: 7400, Loss: 0.108, Accuracy: 94.49%\n",
      "Epoch: 1, Batch: 7500, Loss: 0.078, Accuracy: 94.53%\n",
      "Train Accuracy: 94.53%\n",
      "Test Accuracy: 97.49%\n",
      "Epoch: 2, Batch: 100, Loss: 0.074, Accuracy: 97.75%\n",
      "Epoch: 2, Batch: 200, Loss: 0.086, Accuracy: 97.38%\n",
      "Epoch: 2, Batch: 300, Loss: 0.054, Accuracy: 97.71%\n",
      "Epoch: 2, Batch: 400, Loss: 0.099, Accuracy: 97.59%\n",
      "Epoch: 2, Batch: 500, Loss: 0.061, Accuracy: 97.85%\n",
      "Epoch: 2, Batch: 600, Loss: 0.032, Accuracy: 98.04%\n",
      "Epoch: 2, Batch: 700, Loss: 0.079, Accuracy: 98.04%\n",
      "Epoch: 2, Batch: 800, Loss: 0.084, Accuracy: 97.97%\n",
      "Epoch: 2, Batch: 900, Loss: 0.082, Accuracy: 97.92%\n",
      "Epoch: 2, Batch: 1000, Loss: 0.048, Accuracy: 98.01%\n",
      "Epoch: 2, Batch: 1100, Loss: 0.073, Accuracy: 97.94%\n",
      "Epoch: 2, Batch: 1200, Loss: 0.062, Accuracy: 98.02%\n",
      "Epoch: 2, Batch: 1300, Loss: 0.055, Accuracy: 98.06%\n",
      "Epoch: 2, Batch: 1400, Loss: 0.072, Accuracy: 98.01%\n",
      "Epoch: 2, Batch: 1500, Loss: 0.053, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 1600, Loss: 0.079, Accuracy: 97.96%\n",
      "Epoch: 2, Batch: 1700, Loss: 0.093, Accuracy: 97.97%\n",
      "Epoch: 2, Batch: 1800, Loss: 0.052, Accuracy: 97.97%\n",
      "Epoch: 2, Batch: 1900, Loss: 0.080, Accuracy: 97.95%\n",
      "Epoch: 2, Batch: 2000, Loss: 0.091, Accuracy: 97.94%\n",
      "Epoch: 2, Batch: 2100, Loss: 0.098, Accuracy: 97.92%\n",
      "Epoch: 2, Batch: 2200, Loss: 0.098, Accuracy: 97.90%\n",
      "Epoch: 2, Batch: 2300, Loss: 0.076, Accuracy: 97.90%\n",
      "Epoch: 2, Batch: 2400, Loss: 0.052, Accuracy: 97.93%\n",
      "Epoch: 2, Batch: 2500, Loss: 0.047, Accuracy: 97.97%\n",
      "Epoch: 2, Batch: 2600, Loss: 0.072, Accuracy: 97.96%\n",
      "Epoch: 2, Batch: 2700, Loss: 0.090, Accuracy: 97.95%\n",
      "Epoch: 2, Batch: 2800, Loss: 0.072, Accuracy: 97.95%\n",
      "Epoch: 2, Batch: 2900, Loss: 0.062, Accuracy: 97.96%\n",
      "Epoch: 2, Batch: 3000, Loss: 0.068, Accuracy: 97.97%\n",
      "Epoch: 2, Batch: 3100, Loss: 0.074, Accuracy: 97.96%\n",
      "Epoch: 2, Batch: 3200, Loss: 0.058, Accuracy: 97.98%\n",
      "Epoch: 2, Batch: 3300, Loss: 0.048, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 3400, Loss: 0.060, Accuracy: 98.00%\n",
      "Epoch: 2, Batch: 3500, Loss: 0.067, Accuracy: 98.01%\n",
      "Epoch: 2, Batch: 3600, Loss: 0.056, Accuracy: 98.01%\n",
      "Epoch: 2, Batch: 3700, Loss: 0.074, Accuracy: 98.00%\n",
      "Epoch: 2, Batch: 3800, Loss: 0.065, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 3900, Loss: 0.066, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 4000, Loss: 0.048, Accuracy: 98.01%\n",
      "Epoch: 2, Batch: 4100, Loss: 0.056, Accuracy: 98.01%\n",
      "Epoch: 2, Batch: 4200, Loss: 0.080, Accuracy: 98.01%\n",
      "Epoch: 2, Batch: 4300, Loss: 0.072, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 4400, Loss: 0.063, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 4500, Loss: 0.062, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 4600, Loss: 0.054, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 4700, Loss: 0.074, Accuracy: 98.00%\n",
      "Epoch: 2, Batch: 4800, Loss: 0.067, Accuracy: 98.01%\n",
      "Epoch: 2, Batch: 4900, Loss: 0.083, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 5000, Loss: 0.074, Accuracy: 97.98%\n",
      "Epoch: 2, Batch: 5100, Loss: 0.047, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 5200, Loss: 0.087, Accuracy: 97.97%\n",
      "Epoch: 2, Batch: 5300, Loss: 0.069, Accuracy: 97.98%\n",
      "Epoch: 2, Batch: 5400, Loss: 0.054, Accuracy: 97.98%\n",
      "Epoch: 2, Batch: 5500, Loss: 0.082, Accuracy: 97.97%\n",
      "Epoch: 2, Batch: 5600, Loss: 0.072, Accuracy: 97.98%\n",
      "Epoch: 2, Batch: 5700, Loss: 0.080, Accuracy: 97.98%\n",
      "Epoch: 2, Batch: 5800, Loss: 0.050, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 5900, Loss: 0.060, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 6000, Loss: 0.072, Accuracy: 97.98%\n",
      "Epoch: 2, Batch: 6100, Loss: 0.079, Accuracy: 97.97%\n",
      "Epoch: 2, Batch: 6200, Loss: 0.043, Accuracy: 97.98%\n",
      "Epoch: 2, Batch: 6300, Loss: 0.084, Accuracy: 97.98%\n",
      "Epoch: 2, Batch: 6400, Loss: 0.047, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 6500, Loss: 0.061, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 6600, Loss: 0.053, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 6700, Loss: 0.046, Accuracy: 98.00%\n",
      "Epoch: 2, Batch: 6800, Loss: 0.077, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 6900, Loss: 0.082, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 7000, Loss: 0.068, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 7100, Loss: 0.053, Accuracy: 98.00%\n",
      "Epoch: 2, Batch: 7200, Loss: 0.056, Accuracy: 98.01%\n",
      "Epoch: 2, Batch: 7300, Loss: 0.058, Accuracy: 98.01%\n",
      "Epoch: 2, Batch: 7400, Loss: 0.049, Accuracy: 98.02%\n",
      "Epoch: 2, Batch: 7500, Loss: 0.035, Accuracy: 98.03%\n",
      "Train Accuracy: 98.03%\n",
      "Test Accuracy: 98.05%\n",
      "ConvDeepModel a 146490 param√®tres\n",
      "ConvModel original a 13610 param√®tres\n"
     ]
    }
   ],
   "source": [
    "class ConvDeepModel(torch.nn.Module):\n",
    "    def __init__(self, h=100):\n",
    "        super(ConvDeepModel, self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.flat_features = 1352\n",
    "        self.fc1 = torch.nn.Linear(self.flat_features, h)\n",
    "        self.fc2 = torch.nn.Linear(h, h)\n",
    "        self.fc3 = torch.nn.Linear(h, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = x.view(-1, self.flat_features)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model_conv_deep = ConvDeepModel(h=100).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_conv_deep = torch.optim.Adam(model_conv_deep.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCH + 1):\n",
    "    optimizer_conv_deep, train_acc = train(model_conv_deep, epoch, identity_preprocess, optimizer_conv_deep)\n",
    "    test_acc = test(model_conv_deep, identity_preprocess)\n",
    "\n",
    "\n",
    "print(f\"ConvDeepModel a {sum(p.numel() for p in model_conv_deep.parameters())} param√®tres\")\n",
    "print(f\"ConvModel original a {sum(p.numel() for p in model_conv.parameters())} param√®tres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fd763b-b36a-461c-ad34-f472e62ce46d",
   "metadata": {},
   "source": [
    "## A.6 Visualisations of convolutions\n",
    "\n",
    "After training your model, let's see what features it has learned!\n",
    "\n",
    "Plot an image from the test set then plot all 8 feature maps extracted by the convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8f281d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_image_and_feature_maps(model, test_loader, device):\n",
    "    data_iter = iter(test_loader)  \n",
    "    image, label = next(data_iter)\n",
    "    image = image.to(device)\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image[0].cpu().numpy().squeeze())\n",
    "    plt.title(f'Label: {label[0].item()}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    conv_layer = model.conv\n",
    "    feature_maps = conv_layer(image) \n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(8):\n",
    "        plt.subplot(2, 4, i+1)\n",
    "        plt.imshow(feature_maps[0, i].cpu().detach().numpy())\n",
    "        plt.title(f'Feature map {i+1}')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plot_image_and_feature_maps(model_conv_deep, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc457ad1-3240-4ffb-a8f3-98c6554dfce5",
   "metadata": {
    "id": "riu_K1at3z0R"
   },
   "source": [
    "# Part B - Residual models\n",
    "\n",
    "## B.1 - Residual blocks\n",
    "\n",
    "Write a residual block with two linear layers to learn a function $\\mathbb{R}^d \\to \\mathbb{R}^d$ with $h < d$ hidden neurons.\n",
    "Write a convolutional residual block with the same idea. What hyperparameter acts as the number of hidden neurons in convolutional blocks ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aec298d4-4372-4a1f-be53-a278d051c0f6",
   "metadata": {
    "id": "gkCILVwd3z0R"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(torch.nn.Module):\n",
    "    def __init__(self, d, h):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(d, h)\n",
    "        self.linear2 = torch.nn.Linear(h, d)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = out + identity\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e92a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvResidualBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(ConvResidualBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.relu = nn.ReLU()    \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        x = self.conv1(x)  \n",
    "        x = self.relu(x)  \n",
    "        x = self.conv2(x)  \n",
    "        x += identity \n",
    "        x = self.relu(x)\n",
    "    \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d29a3b",
   "metadata": {},
   "source": [
    "Out_channels repr√©sente le nombre de filtres de sortie dans la couche convolutionnelle et ca repr√©sente aussi le nombre de neurones cach√©s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc0097d-269c-40f4-b182-bdc79bd5c512",
   "metadata": {
    "id": "huKWOvVc3z0S"
   },
   "source": [
    "## B.2 - Stacking residual blocks\n",
    "\n",
    "Use a single convolution layer, followed by a relu and max-pool, then an arbitrary number of residual blocks as defined above, and finish with a linear layer. Can you match the accuracy of the two-layer network ? Can you exceed it ? What happens when you increase the number of layers ? Look at the details of the ResNet architecture on the lecture's slides to get an idea of how to increase the number of hidden neurons and the number of layers. One of the strengths of ResNets was there relatively low number of parameters compared\n",
    "to a multi-layer architecture like that of the previous section, does this show in your experiments ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bf0d4de4-11e8-490c-8262-064b3e841fa5",
   "metadata": {
    "id": "U4gg9uWg3z0S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 100, Loss: 1.231, Accuracy: 59.25%\n",
      "Epoch: 1, Batch: 200, Loss: 0.485, Accuracy: 72.00%\n",
      "Epoch: 1, Batch: 300, Loss: 0.386, Accuracy: 76.75%\n",
      "Epoch: 1, Batch: 400, Loss: 0.405, Accuracy: 79.31%\n",
      "Epoch: 1, Batch: 500, Loss: 0.294, Accuracy: 81.50%\n",
      "Epoch: 1, Batch: 600, Loss: 0.327, Accuracy: 83.17%\n",
      "Epoch: 1, Batch: 700, Loss: 0.281, Accuracy: 84.39%\n",
      "Epoch: 1, Batch: 800, Loss: 0.221, Accuracy: 85.55%\n",
      "Epoch: 1, Batch: 900, Loss: 0.206, Accuracy: 86.47%\n",
      "Epoch: 1, Batch: 1000, Loss: 0.196, Accuracy: 87.24%\n",
      "Epoch: 1, Batch: 1100, Loss: 0.155, Accuracy: 87.98%\n",
      "Epoch: 1, Batch: 1200, Loss: 0.236, Accuracy: 88.33%\n",
      "Epoch: 1, Batch: 1300, Loss: 0.159, Accuracy: 88.86%\n",
      "Epoch: 1, Batch: 1400, Loss: 0.153, Accuracy: 89.29%\n",
      "Epoch: 1, Batch: 1500, Loss: 0.155, Accuracy: 89.72%\n",
      "Epoch: 1, Batch: 1600, Loss: 0.154, Accuracy: 90.08%\n",
      "Epoch: 1, Batch: 1700, Loss: 0.156, Accuracy: 90.45%\n",
      "Epoch: 1, Batch: 1800, Loss: 0.112, Accuracy: 90.80%\n",
      "Epoch: 1, Batch: 1900, Loss: 0.219, Accuracy: 90.99%\n",
      "Epoch: 1, Batch: 2000, Loss: 0.117, Accuracy: 91.26%\n",
      "Epoch: 1, Batch: 2100, Loss: 0.105, Accuracy: 91.49%\n",
      "Epoch: 1, Batch: 2200, Loss: 0.148, Accuracy: 91.68%\n",
      "Epoch: 1, Batch: 2300, Loss: 0.125, Accuracy: 91.89%\n",
      "Epoch: 1, Batch: 2400, Loss: 0.076, Accuracy: 92.13%\n",
      "Epoch: 1, Batch: 2500, Loss: 0.142, Accuracy: 92.27%\n",
      "Epoch: 1, Batch: 2600, Loss: 0.093, Accuracy: 92.47%\n",
      "Epoch: 1, Batch: 2700, Loss: 0.092, Accuracy: 92.63%\n",
      "Epoch: 1, Batch: 2800, Loss: 0.109, Accuracy: 92.81%\n",
      "Epoch: 1, Batch: 2900, Loss: 0.145, Accuracy: 92.94%\n",
      "Epoch: 1, Batch: 3000, Loss: 0.121, Accuracy: 93.05%\n",
      "Epoch: 1, Batch: 3100, Loss: 0.107, Accuracy: 93.18%\n",
      "Epoch: 1, Batch: 3200, Loss: 0.151, Accuracy: 93.23%\n",
      "Epoch: 1, Batch: 3300, Loss: 0.098, Accuracy: 93.35%\n",
      "Epoch: 1, Batch: 3400, Loss: 0.104, Accuracy: 93.45%\n",
      "Epoch: 1, Batch: 3500, Loss: 0.084, Accuracy: 93.56%\n",
      "Epoch: 1, Batch: 3600, Loss: 0.115, Accuracy: 93.65%\n",
      "Epoch: 1, Batch: 3700, Loss: 0.095, Accuracy: 93.74%\n",
      "Epoch: 1, Batch: 3800, Loss: 0.101, Accuracy: 93.82%\n",
      "Epoch: 1, Batch: 3900, Loss: 0.112, Accuracy: 93.90%\n",
      "Epoch: 1, Batch: 4000, Loss: 0.086, Accuracy: 93.98%\n",
      "Epoch: 1, Batch: 4100, Loss: 0.091, Accuracy: 94.05%\n",
      "Epoch: 1, Batch: 4200, Loss: 0.090, Accuracy: 94.13%\n",
      "Epoch: 1, Batch: 4300, Loss: 0.093, Accuracy: 94.20%\n",
      "Epoch: 1, Batch: 4400, Loss: 0.105, Accuracy: 94.27%\n",
      "Epoch: 1, Batch: 4500, Loss: 0.070, Accuracy: 94.36%\n",
      "Epoch: 1, Batch: 4600, Loss: 0.085, Accuracy: 94.43%\n",
      "Epoch: 1, Batch: 4700, Loss: 0.082, Accuracy: 94.49%\n",
      "Epoch: 1, Batch: 4800, Loss: 0.097, Accuracy: 94.56%\n",
      "Epoch: 1, Batch: 4900, Loss: 0.081, Accuracy: 94.62%\n",
      "Epoch: 1, Batch: 5000, Loss: 0.077, Accuracy: 94.66%\n",
      "Epoch: 1, Batch: 5100, Loss: 0.121, Accuracy: 94.69%\n",
      "Epoch: 1, Batch: 5200, Loss: 0.095, Accuracy: 94.72%\n",
      "Epoch: 1, Batch: 5300, Loss: 0.065, Accuracy: 94.79%\n",
      "Epoch: 1, Batch: 5400, Loss: 0.076, Accuracy: 94.84%\n",
      "Epoch: 1, Batch: 5500, Loss: 0.081, Accuracy: 94.88%\n",
      "Epoch: 1, Batch: 5600, Loss: 0.089, Accuracy: 94.92%\n",
      "Epoch: 1, Batch: 5700, Loss: 0.072, Accuracy: 94.96%\n",
      "Epoch: 1, Batch: 5800, Loss: 0.048, Accuracy: 95.02%\n",
      "Epoch: 1, Batch: 5900, Loss: 0.063, Accuracy: 95.07%\n",
      "Epoch: 1, Batch: 6000, Loss: 0.063, Accuracy: 95.12%\n",
      "Epoch: 1, Batch: 6100, Loss: 0.093, Accuracy: 95.14%\n",
      "Epoch: 1, Batch: 6200, Loss: 0.089, Accuracy: 95.18%\n",
      "Epoch: 1, Batch: 6300, Loss: 0.077, Accuracy: 95.21%\n",
      "Epoch: 1, Batch: 6400, Loss: 0.069, Accuracy: 95.25%\n",
      "Epoch: 1, Batch: 6500, Loss: 0.071, Accuracy: 95.29%\n",
      "Epoch: 1, Batch: 6600, Loss: 0.074, Accuracy: 95.32%\n",
      "Epoch: 1, Batch: 6700, Loss: 0.119, Accuracy: 95.34%\n",
      "Epoch: 1, Batch: 6800, Loss: 0.084, Accuracy: 95.37%\n",
      "Epoch: 1, Batch: 6900, Loss: 0.079, Accuracy: 95.40%\n",
      "Epoch: 1, Batch: 7000, Loss: 0.063, Accuracy: 95.44%\n",
      "Epoch: 1, Batch: 7100, Loss: 0.070, Accuracy: 95.47%\n",
      "Epoch: 1, Batch: 7200, Loss: 0.056, Accuracy: 95.52%\n",
      "Epoch: 1, Batch: 7300, Loss: 0.085, Accuracy: 95.55%\n",
      "Epoch: 1, Batch: 7400, Loss: 0.074, Accuracy: 95.58%\n",
      "Epoch: 1, Batch: 7500, Loss: 0.083, Accuracy: 95.59%\n",
      "Train Accuracy: 95.59%\n",
      "Test Accuracy: 97.53%\n",
      "Epoch: 2, Batch: 100, Loss: 0.040, Accuracy: 99.00%\n",
      "Epoch: 2, Batch: 200, Loss: 0.050, Accuracy: 98.62%\n",
      "Epoch: 2, Batch: 300, Loss: 0.065, Accuracy: 98.25%\n",
      "Epoch: 2, Batch: 400, Loss: 0.074, Accuracy: 98.06%\n",
      "Epoch: 2, Batch: 500, Loss: 0.065, Accuracy: 97.95%\n",
      "Epoch: 2, Batch: 600, Loss: 0.067, Accuracy: 98.02%\n",
      "Epoch: 2, Batch: 700, Loss: 0.053, Accuracy: 98.09%\n",
      "Epoch: 2, Batch: 800, Loss: 0.082, Accuracy: 98.06%\n",
      "Epoch: 2, Batch: 900, Loss: 0.068, Accuracy: 98.00%\n",
      "Epoch: 2, Batch: 1000, Loss: 0.059, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 1100, Loss: 0.048, Accuracy: 98.06%\n",
      "Epoch: 2, Batch: 1200, Loss: 0.075, Accuracy: 98.05%\n",
      "Epoch: 2, Batch: 1300, Loss: 0.051, Accuracy: 98.10%\n",
      "Epoch: 2, Batch: 1400, Loss: 0.076, Accuracy: 98.06%\n",
      "Epoch: 2, Batch: 1500, Loss: 0.095, Accuracy: 98.01%\n",
      "Epoch: 2, Batch: 1600, Loss: 0.050, Accuracy: 98.05%\n",
      "Epoch: 2, Batch: 1700, Loss: 0.135, Accuracy: 97.97%\n",
      "Epoch: 2, Batch: 1800, Loss: 0.046, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 1900, Loss: 0.065, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 2000, Loss: 0.083, Accuracy: 97.97%\n",
      "Epoch: 2, Batch: 2100, Loss: 0.074, Accuracy: 97.98%\n",
      "Epoch: 2, Batch: 2200, Loss: 0.073, Accuracy: 97.98%\n",
      "Epoch: 2, Batch: 2300, Loss: 0.087, Accuracy: 97.93%\n",
      "Epoch: 2, Batch: 2400, Loss: 0.097, Accuracy: 97.89%\n",
      "Epoch: 2, Batch: 2500, Loss: 0.065, Accuracy: 97.89%\n",
      "Epoch: 2, Batch: 2600, Loss: 0.056, Accuracy: 97.89%\n",
      "Epoch: 2, Batch: 2700, Loss: 0.067, Accuracy: 97.90%\n",
      "Epoch: 2, Batch: 2800, Loss: 0.064, Accuracy: 97.88%\n",
      "Epoch: 2, Batch: 2900, Loss: 0.041, Accuracy: 97.90%\n",
      "Epoch: 2, Batch: 3000, Loss: 0.074, Accuracy: 97.90%\n",
      "Epoch: 2, Batch: 3100, Loss: 0.031, Accuracy: 97.94%\n",
      "Epoch: 2, Batch: 3200, Loss: 0.071, Accuracy: 97.94%\n",
      "Epoch: 2, Batch: 3300, Loss: 0.052, Accuracy: 97.93%\n",
      "Epoch: 2, Batch: 3400, Loss: 0.059, Accuracy: 97.94%\n",
      "Epoch: 2, Batch: 3500, Loss: 0.046, Accuracy: 97.96%\n",
      "Epoch: 2, Batch: 3600, Loss: 0.059, Accuracy: 97.98%\n",
      "Epoch: 2, Batch: 3700, Loss: 0.068, Accuracy: 97.96%\n",
      "Epoch: 2, Batch: 3800, Loss: 0.028, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 3900, Loss: 0.057, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 4000, Loss: 0.065, Accuracy: 97.97%\n",
      "Epoch: 2, Batch: 4100, Loss: 0.056, Accuracy: 97.97%\n",
      "Epoch: 2, Batch: 4200, Loss: 0.085, Accuracy: 97.96%\n",
      "Epoch: 2, Batch: 4300, Loss: 0.073, Accuracy: 97.97%\n",
      "Epoch: 2, Batch: 4400, Loss: 0.051, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 4500, Loss: 0.048, Accuracy: 98.00%\n",
      "Epoch: 2, Batch: 4600, Loss: 0.047, Accuracy: 98.00%\n",
      "Epoch: 2, Batch: 4700, Loss: 0.084, Accuracy: 98.00%\n",
      "Epoch: 2, Batch: 4800, Loss: 0.109, Accuracy: 97.99%\n",
      "Epoch: 2, Batch: 4900, Loss: 0.054, Accuracy: 98.01%\n",
      "Epoch: 2, Batch: 5000, Loss: 0.065, Accuracy: 98.00%\n",
      "Epoch: 2, Batch: 5100, Loss: 0.041, Accuracy: 98.01%\n",
      "Epoch: 2, Batch: 5200, Loss: 0.086, Accuracy: 98.01%\n",
      "Epoch: 2, Batch: 5300, Loss: 0.054, Accuracy: 98.01%\n",
      "Epoch: 2, Batch: 5400, Loss: 0.044, Accuracy: 98.03%\n",
      "Epoch: 2, Batch: 5500, Loss: 0.049, Accuracy: 98.03%\n",
      "Epoch: 2, Batch: 5600, Loss: 0.079, Accuracy: 98.03%\n",
      "Epoch: 2, Batch: 5700, Loss: 0.053, Accuracy: 98.05%\n",
      "Epoch: 2, Batch: 5800, Loss: 0.036, Accuracy: 98.06%\n",
      "Epoch: 2, Batch: 5900, Loss: 0.033, Accuracy: 98.08%\n",
      "Epoch: 2, Batch: 6000, Loss: 0.046, Accuracy: 98.09%\n",
      "Epoch: 2, Batch: 6100, Loss: 0.046, Accuracy: 98.09%\n",
      "Epoch: 2, Batch: 6200, Loss: 0.051, Accuracy: 98.10%\n",
      "Epoch: 2, Batch: 6300, Loss: 0.088, Accuracy: 98.09%\n",
      "Epoch: 2, Batch: 6400, Loss: 0.082, Accuracy: 98.09%\n",
      "Epoch: 2, Batch: 6500, Loss: 0.056, Accuracy: 98.09%\n",
      "Epoch: 2, Batch: 6600, Loss: 0.057, Accuracy: 98.10%\n",
      "Epoch: 2, Batch: 6700, Loss: 0.039, Accuracy: 98.11%\n",
      "Epoch: 2, Batch: 6800, Loss: 0.042, Accuracy: 98.12%\n",
      "Epoch: 2, Batch: 6900, Loss: 0.040, Accuracy: 98.12%\n",
      "Epoch: 2, Batch: 7000, Loss: 0.072, Accuracy: 98.12%\n",
      "Epoch: 2, Batch: 7100, Loss: 0.051, Accuracy: 98.13%\n",
      "Epoch: 2, Batch: 7200, Loss: 0.056, Accuracy: 98.13%\n",
      "Epoch: 2, Batch: 7300, Loss: 0.073, Accuracy: 98.13%\n",
      "Epoch: 2, Batch: 7400, Loss: 0.069, Accuracy: 98.13%\n",
      "Epoch: 2, Batch: 7500, Loss: 0.064, Accuracy: 98.13%\n",
      "Train Accuracy: 98.13%\n",
      "Test Accuracy: 98.89%\n"
     ]
    }
   ],
   "source": [
    "class ConvResidualModel(nn.Module):\n",
    "    def __init__(self, num_blocks=2, channels=8, hidden_dim=16, output_dim=10):\n",
    "        super(ConvResidualModel, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=channels, kernel_size=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.res_blocks = nn.Sequential(\n",
    "            *[ConvResidualBlock(channels, channels) for _ in range(num_blocks)]\n",
    "        )\n",
    "        self.flat_features = channels * 13 * 13\n",
    "        self.fc = nn.Linear(self.flat_features, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.res_blocks(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model_resnet = ConvResidualModel(num_blocks=3, channels=8).to(device)\n",
    "optimizer_resnet = torch.optim.Adam(model_resnet.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCH + 1):\n",
    "    optimizer_resnet, train_acc = train(model_resnet, epoch, identity_preprocess, optimizer_resnet)\n",
    "    test_acc = test(model_resnet, identity_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df418703-b1e1-4276-8ba7-dd5622c7b7cd",
   "metadata": {
    "id": "2nes_ZtBoBu0"
   },
   "source": [
    "# Part C - Reimplementing loss functions\n",
    "\n",
    "## C.0 - Combining losses\n",
    "First, we recall that, for a batch of score vectors $s\\in\\mathbb{R}^{n\\times C}$ and true labels $y\\in[1,C]^n$, **cross entropy** is defined as\n",
    "$$CE(s, y) = -\\frac{1}{n}\\sum_{i=1}^n \\log\\left( \\mbox{softmax}(s_i)_{y_i} \\right)$$\n",
    "\n",
    "where $\\mbox{softmax}(x)_i = \\frac{e^{x_i}}{\\sum_{j=1}^n e^{x_j}}$ is the probability associated to class $i\\in[1,C]$ for a score vector $x\\in\\mathbb{R}^C$.\n",
    "\n",
    "Let's try to compute cross-entropy in three different ways (see the [documentation](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)):\n",
    "1. Using `nn.CrossEntropyLoss()`.\n",
    "2. Using `nn.NLLLoss()` and `nn.LogSoftmax()`.\n",
    "3. Using `nn.NLLLoss()` and `nn.Softmax()`.\n",
    "\n",
    "Check that the output is the same for all three methods on Gaussian random scores `torch.randn(n_batch, n_classes)` and random labels `torch.randint(0, n_classes, [n_batch])`, where `n_batch=4` and `n_classes=10`. Note that the scores are real valued vectors while the labels are integers corresponding to the true class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e1b6c172",
   "metadata": {
    "id": "e1b6c172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss: 2.5784943103790283\n",
      "NLLLoss + LogSoftmax: 2.5784943103790283\n",
      "NLLLoss + Softmax + Log: 2.5784943103790283\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_batch = 4\n",
    "n_classes = 10\n",
    "\n",
    "scores = torch.randn(n_batch, n_classes)\n",
    "\n",
    "labels = torch.randint(0, n_classes, [n_batch])\n",
    "\n",
    "cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "loss_ce = cross_entropy_loss(scores, labels)\n",
    "\n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "scores_log = log_softmax(scores)\n",
    "nll_loss = nn.NLLLoss()\n",
    "loss_log_softmax = nll_loss(scores_log, labels)\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "scores_softmax = softmax(scores)\n",
    "scores_log2 = torch.log(scores_softmax)\n",
    "loss_softmax = nll_loss(scores_log2, labels)\n",
    "\n",
    "print(f\"CrossEntropyLoss: {loss_ce.item()}\")\n",
    "print(f\"NLLLoss + LogSoftmax: {loss_log_softmax.item()}\")\n",
    "print(f\"NLLLoss + Softmax + Log: {loss_softmax.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba900c6-f7b2-4179-a2f1-f1eede4b6697",
   "metadata": {
    "id": "TWKaTBVd5ftN"
   },
   "source": [
    "## C.1 - Re-implementation\n",
    "Now re-implement cross-entropy using base functions (`torch.log`, `torch.exp`, `torch.sum`, etc...). Verify that your function returns the same value as Pytorch's implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "41f17f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My loss: 1.8601641654968262\n",
      "PyTorch loss: 1.8601644039154053\n"
     ]
    }
   ],
   "source": [
    "def ce(logits, targets):\n",
    "    log_probs = logits - torch.log(torch.sum(torch.exp(logits), dim=1, keepdim=True))\n",
    "    selected_log_probs = log_probs[torch.arange(len(targets)), targets]\n",
    "    loss = -torch.mean(selected_log_probs)\n",
    "    return loss\n",
    "\n",
    "logits = torch.tensor([[5.0, 5.0, 5.1],\n",
    "                       [5., 2.5, 0.3]], requires_grad=True)\n",
    "targets = torch.tensor([0, 1])\n",
    "\n",
    "my_loss = ce(logits, targets)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "torch_loss = criterion(logits, targets)\n",
    "\n",
    "print(\"My loss:\", my_loss.item())\n",
    "print(\"PyTorch loss:\", torch_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ec13a-330a-4073-99b9-2eb9dd42d1f8",
   "metadata": {
    "id": "OFG0QfKN7WtO"
   },
   "source": [
    "## C.2 - Stability analysis\n",
    "Softmax probabilities can be relatively unstable due to their use of exponentials. Pytorch implementations thus usually use log probas or logits to avoid overflows or floating point errors. Test all methods (including your own) on Gaussian random scores of standard deviation equal to $100$. Which methods are stable? Why? Is it an issue in practice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "741771f5-864d-446a-b654-3b4f5a2598ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecaaf7c-b21f-4e18-ac53-1a77adbc60bf",
   "metadata": {
    "id": "Y3y4BfwbBIGy"
   },
   "source": [
    "Re-implement a stable version of cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83d00dab-a37e-48da-880f-81f10efdc133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_ce(logits, targets):\n",
    "    ### YOUR CODE HERE ###\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackaton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
