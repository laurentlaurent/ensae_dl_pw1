{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17ec8d6a-4218-49b9-a549-0977cec82967",
   "metadata": {
    "id": "MVpsYfWg3z0B"
   },
   "source": [
    "# PW1 - Handwritten character recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d682452d-e56e-4de8-a420-4418d63790a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your name here (e.g. \"Edmond Dant√®s\") so I can grade your work\n",
    "your_name = \"Laurent Vong\"\n",
    "assert your_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8538cf7-81e0-481a-8059-be38b611aafb",
   "metadata": {
    "id": "8CcAqNjJ3z0F"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math, sys, os, torch, torchvision\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c864b86e-6e6b-4d8a-82c8-6822072a676f",
   "metadata": {
    "id": "3Wxb9pdV3z0F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu: False \n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using gpu: %s ' % torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa038da6-b812-4053-9b72-8ff97ceb3b9b",
   "metadata": {
    "id": "1Sjq8zzf3z0G"
   },
   "source": [
    "We will be training many models. Select a number of epochs to train each model. If you are using a slow machine, or if you want to restart training often and have many development iterations, we suggest `NUM_EPOCH = 2`. If you are using a fast machine, or have a GPU available, of if you are confident that you can write accurate code first try, you will get better accuracies by increasing this constant. You could be able to afford up to `NUM_EPOCH = 10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "137adce6-13cc-4ccc-aaf3-42230e322a9b",
   "metadata": {
    "id": "L9CF0H4O3z0G"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCH = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce850e9-ef4e-4323-af2d-be6b94e98994",
   "metadata": {
    "id": "65e20f5e"
   },
   "source": [
    "# Part A - Linear, MLP, and CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aff4bd-8b1d-4531-89d8-64ce4e2b6357",
   "metadata": {
    "id": "KSAiV2ov3z0H"
   },
   "source": [
    "## Handwritten digit recognition dataset\n",
    "\n",
    "We will use the MNIST database (Modified National Institute of Standards and Technology database). It contains tens of thousands of pictures of handwritten digits. This database was compiled in 1994, as part of the effort in the 1990s to standardize automation of sorting devices with human input, for instance sorting mail with handwritten postal codes at the post office. This is now often considered one of the first real successes of neural networks, and the first easy example on which performance of new such algorithms is tested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3429898a-0f57-4cdf-9aa6-7b1121ee4e53",
   "metadata": {},
   "source": [
    "Load the dataset (train and test splits) using `torchvision`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59e1c523-4b78-492a-b103-2861af8c3d89",
   "metadata": {
    "id": "Zu3hU4dQ3z0H"
   },
   "outputs": [],
   "source": [
    "root_dir = './data/MNIST/'\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=root_dir,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=root_dir,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "batch_size = 8\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77fbaba-b01f-46d0-a1d7-47c59faaf042",
   "metadata": {},
   "source": [
    "How many examples in each split? \n",
    "\n",
    "Plot the first image and label of the training set using `matplotlib`\n",
    "\n",
    "What is the input dimension?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "083f07f4-e129-4e9b-b26e-a32fd4bdb99d",
   "metadata": {
    "id": "9fgMls5P3z0I",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data/MNIST/\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data/MNIST/\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print((train_dataset))\n",
    "print((test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc2fbd26-b017-435a-822e-ad382eabd8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":dimensions: torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhUUlEQVR4nO3de3RU9fnv8c8QYLiYDIaQWwmYgIrKRQsSs0SMkh9J2roA0YOKq+DxYMXgD0RF0yoX62+lYotURPC0SnQpXmgF1Fq6FEyoNUBBkUWrkdBQQJJwcWUmBAkh2ecPjlNHEnCHGZ4kvF9r7bWYPd9n9jObLR/37D3f8TiO4wgAgLOsg3UDAIBzEwEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQScoV27dsnj8ejXv/512F6zqKhIHo9HRUVFYXtNoLUhgHBOKiwslMfj0ebNm61biYi5c+fK4/GctHTp0sW6NSCoo3UDACJnyZIlOu+884KPo6KiDLsBQhFAQDt20003KS4uzroNoEl8BAc049ixY5o9e7aGDh0qn8+n7t2765prrtEHH3zQbM1TTz2lvn37qmvXrrr22mu1ffv2k8Z8/vnnuummmxQbG6suXbpo2LBheuutt07bz5EjR/T555/r4MGD3/s9OI6jQCAgJr1Ha0QAAc0IBAL6/e9/r8zMTD3xxBOaO3euDhw4oOzsbG3duvWk8S+99JKefvpp5eXlKT8/X9u3b9f111+vqqqq4Jh//OMfuuqqq/TZZ5/p4Ycf1m9+8xt1795dY8eO1cqVK0/Zz6ZNm3TJJZfomWee+d7vIS0tTT6fT9HR0br99ttDegGs8REc0Izzzz9fu3btUufOnYPrpkyZogEDBmjRokV6/vnnQ8aXlZVpx44d+sEPfiBJysnJUXp6up544gktWLBAkjR9+nT16dNHf//73+X1eiVJ99xzj0aMGKGHHnpI48aNC1vv06ZNU0ZGhrxer/76179q8eLF2rRpkzZv3qyYmJiwbAc4EwQQ0IyoqKjgRfvGxkZVV1ersbFRw4YN08cff3zS+LFjxwbDR5KGDx+u9PR0vfvuu1qwYIG++uorrVu3To899phqampUU1MTHJudna05c+boyy+/DHmNb8vMzPzeH6VNnz495PH48eM1fPhwTZw4Uc8++6wefvjh7/U6QCTxERxwCi+++KIGDx6sLl26qGfPnurVq5f+9Kc/ye/3nzT2wgsvPGndRRddpF27dkk6cYbkOI4effRR9erVK2SZM2eOJGn//v0Rey+33XabEhMT9f7770dsG4AbnAEBzXj55Zc1efJkjR07Vg8++KDi4+MVFRWlgoIC7dy50/XrNTY2SpIeeOABZWdnNzmmf//+Z9Tz6aSkpOirr76K6DaA74sAAprxhz/8QWlpaXrzzTfl8XiC6785W/muHTt2nLTuiy++0AUXXCDpxA0BktSpUydlZWWFv+HTcBxHu3bt0hVXXHHWtw00hY/ggGZ8c/3n29ddNm7cqJKSkibHr1q1Sl9++WXw8aZNm7Rx40bl5uZKkuLj45WZmannnntOFRUVJ9UfOHDglP24uQ27qddasmSJDhw4oJycnNPWA2cDZ0A4p73wwgtas2bNSeunT5+un/zkJ3rzzTc1btw4/fjHP1Z5ebmWLl2qSy+9VIcPHz6ppn///hoxYoSmTp2quro6LVy4UD179tSsWbOCYxYvXqwRI0Zo0KBBmjJlitLS0lRVVaWSkhLt3btXn376abO9btq0Sdddd53mzJmjuXPnnvJ99e3bVxMmTNCgQYPUpUsXffjhh3rttdd0+eWX62c/+9n330FABBFAOKctWbKkyfWTJ0/W5MmTVVlZqeeee05/+ctfdOmll+rll1/WihUrmpwk9Kc//ak6dOighQsXav/+/Ro+fLieeeYZJSUlBcdceuml2rx5s+bNm6fCwkIdOnRI8fHxuuKKKzR79uywva+JEyfqo48+0h//+EcdPXpUffv21axZs/SLX/xC3bp1C9t2gDPhcfiKNADAANeAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJVvc9oMbGRu3bt0/R0dEh058AANoGx3FUU1Oj5ORkdejQ/HlOqwugffv2KSUlxboNAMAZ2rNnj3r37t3s860ugKKjoyVJI/QjdVQn424AAG4dV70+1LvBf8+bE7EAWrx4sZ588klVVlZqyJAhWrRokYYPH37aum8+duuoTuroIYAAoM35//PrnO4ySkRuQnj99dc1c+ZMzZkzRx9//LGGDBmi7OzsiP7YFgCgbYlIAC1YsEBTpkzRHXfcoUsvvVRLly5Vt27d9MILL0RicwCANijsAXTs2DFt2bIl5Ae3OnTooKysrCZ/R6Wurk6BQCBkAQC0f2EPoIMHD6qhoUEJCQkh6xMSElRZWXnS+IKCAvl8vuDCHXAAcG4w/yJqfn6+/H5/cNmzZ491SwCAsyDsd8HFxcUpKipKVVVVIeurqqqUmJh40niv1yuv1xvuNgAArVzYz4A6d+6soUOHau3atcF1jY2NWrt2rTIyMsK9OQBAGxWR7wHNnDlTkyZN0rBhwzR8+HAtXLhQtbW1uuOOOyKxOQBAGxSRAJowYYIOHDig2bNnq7KyUpdffrnWrFlz0o0JAIBzl8dxHMe6iW8LBALy+XzK1BhmQgCANui4U68irZbf71dMTEyz48zvggMAnJsIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmOho3QDQmng6uv9PIqpXXAQ6CY/SBy5oUV1Dt0bXNX377Xdd0+0ej+uaygWdXdd8POx11zWSdLCh1nVN+or7Xdf0n7nBdU17wBkQAMAEAQQAMBH2AJo7d648Hk/IMmDAgHBvBgDQxkXkGtBll12m999//z8bacHn6gCA9i0iydCxY0clJiZG4qUBAO1ERK4B7dixQ8nJyUpLS9PEiRO1e/fuZsfW1dUpEAiELACA9i/sAZSenq7CwkKtWbNGS5YsUXl5ua655hrV1NQ0Ob6goEA+ny+4pKSkhLslAEArFPYAys3N1c0336zBgwcrOztb7777rqqrq/XGG280OT4/P19+vz+47NmzJ9wtAQBaoYjfHdCjRw9ddNFFKisra/J5r9crr9cb6TYAAK1MxL8HdPjwYe3cuVNJSUmR3hQAoA0JewA98MADKi4u1q5du/TRRx9p3LhxioqK0q233hruTQEA2rCwfwS3d+9e3XrrrTp06JB69eqlESNGaMOGDerVq1e4NwUAaMPCHkCvvfZauF8SrVTUJRe6rnG8nVzX7Lu2h+uar69yP4mkJMX63Nf9dUjLJrpsb/58JNp1zRPP5Liu2Thoueua8vqvXddI0q+q/st1TfJfnRZt61zEXHAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMRPwH6dD6NWT+sEV1CwoXu665qFPnFm0LZ1e90+C6Zvaiya5rOta6n7gzY8U01zXRXx53XSNJ3oPuJzHttnlji7Z1LuIMCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABggtmwIW/pvhbVbTma4rrmok5VLdpWe3N/xVWua/51OM51TWG/P7iukSR/o/tZqhOe/qhF22rN3O8FuMEZEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABNMRgodr6hsUd2iJ252XfM/ObWua6K2nee65tN7FrmuaanHDw52XVOW1c11TUN1heua2zLucV0jSbv+231Nqj5t0bZw7uIMCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkmI0WLxS4rcV3T6+2ermsaDn3luuaygf/bdY0k/WPkC65r3vq/17quia/+yHVNS3hKWjZBaKr7v1rANc6AAAAmCCAAgAnXAbR+/XrdcMMNSk5Olsfj0apVq0KedxxHs2fPVlJSkrp27aqsrCzt2LEjXP0CANoJ1wFUW1urIUOGaPHixU0+P3/+fD399NNaunSpNm7cqO7duys7O1tHjx4942YBAO2H65sQcnNzlZub2+RzjuNo4cKFeuSRRzRmzBhJ0ksvvaSEhAStWrVKt9xyy5l1CwBoN8J6Dai8vFyVlZXKysoKrvP5fEpPT1dJSdO31dTV1SkQCIQsAID2L6wBVFlZKUlKSEgIWZ+QkBB87rsKCgrk8/mCS0pKSjhbAgC0UuZ3weXn58vv9weXPXv2WLcEADgLwhpAiYmJkqSqqqqQ9VVVVcHnvsvr9SomJiZkAQC0f2ENoNTUVCUmJmrt2rXBdYFAQBs3blRGRkY4NwUAaONc3wV3+PBhlZWVBR+Xl5dr69atio2NVZ8+fTRjxgw9/vjjuvDCC5WamqpHH31UycnJGjt2bDj7BgC0ca4DaPPmzbruuuuCj2fOnClJmjRpkgoLCzVr1izV1tbqrrvuUnV1tUaMGKE1a9aoS5cu4esaANDmeRzHcayb+LZAICCfz6dMjVFHTyfrdtBGffHclS2r+8lS1zV3/HuU65oDI2pc16ixwX0NYOC4U68irZbf7z/ldX3zu+AAAOcmAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJ1z/HALQFlzz0RYvq7hjkfmbrZX3Xnn7Qd1x7c57rmujXN7iuAVozzoAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYYDJStEsN1f4W1R2aeonrmt1vfe265uHHX3Jdk/+/xrmucT7xua6RpJT/KXFf5Dgt2hbOXZwBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMMFkpMC3NH76meuaW+Y96LrmlTm/dl2z9Sr3E5jqKvclknRZ92muay78XYXrmuP/2uW6Bu0HZ0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMeBzHcayb+LZAICCfz6dMjVFHTyfrdoCIcK6+3HVNzK/2uq55Ne0vrmtaasAH/8d1zcXz/K5rGnb8y3UNzq7jTr2KtFp+v18xMTHNjuMMCABgggACAJhwHUDr16/XDTfcoOTkZHk8Hq1atSrk+cmTJ8vj8YQsOTk54eoXANBOuA6g2tpaDRkyRIsXL252TE5OjioqKoLLq6++ekZNAgDaH9e/iJqbm6vc3NxTjvF6vUpMTGxxUwCA9i8i14CKiooUHx+viy++WFOnTtWhQ4eaHVtXV6dAIBCyAADav7AHUE5Ojl566SWtXbtWTzzxhIqLi5Wbm6uGhoYmxxcUFMjn8wWXlJSUcLcEAGiFXH8Edzq33HJL8M+DBg3S4MGD1a9fPxUVFWnUqFEnjc/Pz9fMmTODjwOBACEEAOeAiN+GnZaWpri4OJWVlTX5vNfrVUxMTMgCAGj/Ih5Ae/fu1aFDh5SUlBTpTQEA2hDXH8EdPnw45GymvLxcW7duVWxsrGJjYzVv3jyNHz9eiYmJ2rlzp2bNmqX+/fsrOzs7rI0DANo21wG0efNmXXfddcHH31y/mTRpkpYsWaJt27bpxRdfVHV1tZKTkzV69Gj98pe/lNfrDV/XAIA2j8lIgTYiKiHedc2+Cf1btK2ND/3WdU2HFnyiP7F8tOsa/4jmv9aB1oHJSAEArRoBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwETYf5IbQGQ0VO13XZPwtPsaSTo667jrmm6ezq5rfnfBO65rfjJuhuuabis3uq5B5HEGBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwASTkQIGGkdc7rpm581dXNcMvHyX6xqpZROLtsSir65wXdNt9eYIdAILnAEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwwWSkwLd4hg10XfPFf7ufuPN3V7/oumZkl2Oua86mOqfedc2Gr1Ldb6ixwn0NWiXOgAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJhgMlK0eh1T+7qu2XlHcou2NXfCa65rxp93sEXbas1+XjXMdU3xb69yXXP+iyWua9B+cAYEADBBAAEATLgKoIKCAl155ZWKjo5WfHy8xo4dq9LS0pAxR48eVV5ennr27KnzzjtP48ePV1VVVVibBgC0fa4CqLi4WHl5edqwYYPee+891dfXa/To0aqtrQ2Oue+++/T2229rxYoVKi4u1r59+3TjjTeGvXEAQNvm6iaENWvWhDwuLCxUfHy8tmzZopEjR8rv9+v555/X8uXLdf3110uSli1bpksuuUQbNmzQVVe5v0gJAGifzugakN/vlyTFxsZKkrZs2aL6+nplZWUFxwwYMEB9+vRRSUnTd7vU1dUpEAiELACA9q/FAdTY2KgZM2bo6quv1sCBAyVJlZWV6ty5s3r06BEyNiEhQZWVlU2+TkFBgXw+X3BJSUlpaUsAgDakxQGUl5en7du367XX3H9v4tvy8/Pl9/uDy549e87o9QAAbUOLvog6bdo0vfPOO1q/fr169+4dXJ+YmKhjx46puro65CyoqqpKiYmJTb6W1+uV1+ttSRsAgDbM1RmQ4ziaNm2aVq5cqXXr1ik1NTXk+aFDh6pTp05au3ZtcF1paal2796tjIyM8HQMAGgXXJ0B5eXlafny5Vq9erWio6OD13V8Pp+6du0qn8+nO++8UzNnzlRsbKxiYmJ07733KiMjgzvgAAAhXAXQkiVLJEmZmZkh65ctW6bJkydLkp566il16NBB48ePV11dnbKzs/Xss8+GpVkAQPvhcRzHsW7i2wKBgHw+nzI1Rh09nazbwSl0vKCP6xr/0CTXNRMeW3P6Qd9xd49/ua5p7e6vcP8pQsmz7icVlaTYwk3uixobWrQttD/HnXoVabX8fr9iYmKaHcdccAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEy36RVS0Xh2Tmv7l2VP56oXuLdrW1NRi1zW3Rle1aFut2bQvR7iu+XjJ5a5r4v6w3XVNbE2J6xrgbOEMCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkmIz1LjmUPc19z31eua37e/13XNaO71rquae2qGr5uUd3It+53XTPgkc9d18RWu58ktNF1BdC6cQYEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABJORniW7xrrP+i8GrYhAJ+GzuLqf65rfFo92XeNp8LiuGfB4uesaSbqwaqPrmoYWbQkAZ0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMeBzHcayb+LZAICCfz6dMjVFHTyfrdgAALh136lWk1fL7/YqJiWl2HGdAAAATBBAAwISrACooKNCVV16p6OhoxcfHa+zYsSotLQ0Zk5mZKY/HE7LcfffdYW0aAND2uQqg4uJi5eXlacOGDXrvvfdUX1+v0aNHq7a2NmTclClTVFFREVzmz58f1qYBAG2fq19EXbNmTcjjwsJCxcfHa8uWLRo5cmRwfbdu3ZSYmBieDgEA7dIZXQPy+/2SpNjY2JD1r7zyiuLi4jRw4EDl5+fryJEjzb5GXV2dAoFAyAIAaP9cnQF9W2Njo2bMmKGrr75aAwcODK6/7bbb1LdvXyUnJ2vbtm166KGHVFpaqjfffLPJ1ykoKNC8efNa2gYAoI1q8feApk6dqj//+c/68MMP1bt372bHrVu3TqNGjVJZWZn69et30vN1dXWqq6sLPg4EAkpJSeF7QADQRn3f7wG16Axo2rRpeuedd7R+/fpTho8kpaenS1KzAeT1euX1elvSBgCgDXMVQI7j6N5779XKlStVVFSk1NTU09Zs3bpVkpSUlNSiBgEA7ZOrAMrLy9Py5cu1evVqRUdHq7KyUpLk8/nUtWtX7dy5U8uXL9ePfvQj9ezZU9u2bdN9992nkSNHavDgwRF5AwCAtsnVNSCPx9Pk+mXLlmny5Mnas2ePbr/9dm3fvl21tbVKSUnRuHHj9Mgjj5zyc8BvYy44AGjbInIN6HRZlZKSouLiYjcvCQA4RzEXHADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADAREfrBr7LcRxJ0nHVS45xMwAA146rXtJ//j1vTqsLoJqaGknSh3rXuBMAwJmoqamRz+dr9nmPc7qIOssaGxu1b98+RUdHy+PxhDwXCASUkpKiPXv2KCYmxqhDe+yHE9gPJ7AfTmA/nNAa9oPjOKqpqVFycrI6dGj+Sk+rOwPq0KGDevfufcoxMTEx5/QB9g32wwnshxPYDyewH06w3g+nOvP5BjchAABMEEAAABNtKoC8Xq/mzJkjr9dr3Yop9sMJ7IcT2A8nsB9OaEv7odXdhAAAODe0qTMgAED7QQABAEwQQAAAEwQQAMAEAQQAMNFmAmjx4sW64IIL1KVLF6Wnp2vTpk3WLZ11c+fOlcfjCVkGDBhg3VbErV+/XjfccIOSk5Pl8Xi0atWqkOcdx9Hs2bOVlJSkrl27KisrSzt27LBpNoJOtx8mT5580vGRk5Nj02yEFBQU6Morr1R0dLTi4+M1duxYlZaWhow5evSo8vLy1LNnT5133nkaP368qqqqjDqOjO+zHzIzM086Hu6++26jjpvWJgLo9ddf18yZMzVnzhx9/PHHGjJkiLKzs7V//37r1s66yy67TBUVFcHlww8/tG4p4mprazVkyBAtXry4yefnz5+vp59+WkuXLtXGjRvVvXt3ZWdn6+jRo2e508g63X6QpJycnJDj49VXXz2LHUZecXGx8vLytGHDBr333nuqr6/X6NGjVVtbGxxz33336e2339aKFStUXFysffv26cYbbzTsOvy+z36QpClTpoQcD/PnzzfquBlOGzB8+HAnLy8v+LihocFJTk52CgoKDLs6++bMmeMMGTLEug1TkpyVK1cGHzc2NjqJiYnOk08+GVxXXV3teL1e59VXXzXo8Oz47n5wHMeZNGmSM2bMGJN+rOzfv9+R5BQXFzuOc+LvvlOnTs6KFSuCYz777DNHklNSUmLVZsR9dz84juNce+21zvTp0+2a+h5a/RnQsWPHtGXLFmVlZQXXdejQQVlZWSopKTHszMaOHTuUnJystLQ0TZw4Ubt377ZuyVR5ebkqKytDjg+fz6f09PRz8vgoKipSfHy8Lr74Yk2dOlWHDh2ybimi/H6/JCk2NlaStGXLFtXX14ccDwMGDFCfPn3a9fHw3f3wjVdeeUVxcXEaOHCg8vPzdeTIEYv2mtXqZsP+roMHD6qhoUEJCQkh6xMSEvT5558bdWUjPT1dhYWFuvjii1VRUaF58+bpmmuu0fbt2xUdHW3dnonKykpJavL4+Oa5c0VOTo5uvPFGpaamaufOnfr5z3+u3NxclZSUKCoqyrq9sGtsbNSMGTN09dVXa+DAgZJOHA+dO3dWjx49Qsa25+Ohqf0gSbfddpv69u2r5ORkbdu2TQ899JBKS0v15ptvGnYbqtUHEP4jNzc3+OfBgwcrPT1dffv21RtvvKE777zTsDO0Brfcckvwz4MGDdLgwYPVr18/FRUVadSoUYadRUZeXp62b99+TlwHPZXm9sNdd90V/POgQYOUlJSkUaNGaefOnerXr9/ZbrNJrf4juLi4OEVFRZ10F0tVVZUSExONumodevTooYsuukhlZWXWrZj55hjg+DhZWlqa4uLi2uXxMW3aNL3zzjv64IMPQn4/LDExUceOHVN1dXXI+PZ6PDS3H5qSnp4uSa3qeGj1AdS5c2cNHTpUa9euDa5rbGzU2rVrlZGRYdiZvcOHD2vnzp1KSkqybsVMamqqEhMTQ46PQCCgjRs3nvPHx969e3Xo0KF2dXw4jqNp06Zp5cqVWrdunVJTU0OeHzp0qDp16hRyPJSWlmr37t3t6ng43X5oytatWyWpdR0P1ndBfB+vvfaa4/V6ncLCQuef//ync9dddzk9evRwKisrrVs7q+6//36nqKjIKS8vd/72t785WVlZTlxcnLN//37r1iKqpqbG+eSTT5xPPvnEkeQsWLDA+eSTT5x///vfjuM4zq9+9SunR48ezurVq51t27Y5Y8aMcVJTU52vv/7auPPwOtV+qKmpcR544AGnpKTEKS8vd95//33nhz/8oXPhhRc6R48etW49bKZOner4fD6nqKjIqaioCC5HjhwJjrn77rudPn36OOvWrXM2b97sZGRkOBkZGYZdh9/p9kNZWZnz2GOPOZs3b3bKy8ud1atXO2lpac7IkSONOw/VJgLIcRxn0aJFTp8+fZzOnTs7w4cPdzZs2GDd0lk3YcIEJykpyencubPzgx/8wJkwYYJTVlZm3VbEffDBB46kk5ZJkyY5jnPiVuxHH33USUhIcLxerzNq1CintLTUtukIONV+OHLkiDN69GinV69eTqdOnZy+ffs6U6ZMaXf/k9bU+5fkLFu2LDjm66+/du655x7n/PPPd7p16+aMGzfOqaiosGs6Ak63H3bv3u2MHDnSiY2Ndbxer9O/f3/nwQcfdPx+v23j38HvAQEATLT6a0AAgPaJAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACb+HwnNjsX8THVuAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_dataset[0][0].squeeze())\n",
    "plt.title(f\"Label: {train_dataset[0][1]}\")\n",
    "print(f\":dimensions: {train_dataset[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6380c03-1427-4dea-974e-5a38621ea6c1",
   "metadata": {
    "id": "Guv5_hY63z0L"
   },
   "source": [
    "# A.1 - Linear features\n",
    "\n",
    "We start with a very simple model, linear with respect to pixel values.\n",
    "Use a `preprocess` function to downsample the image to 7x7 pixels, then flatten it and use a `torch.nn.Linear` model.\n",
    "\n",
    "The torch average-pooling function is `torch.nn.functional.avg_pool2d`, check the documentation to set the arguments properly.\n",
    "DO NOT use your implementation of average-pooling, it would take prohibitively long to train and you would not finish the practical.\n",
    "If the training takes too long, go back to the first section and lower the `NUM_EPOCH` constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bb8e5d-7d84-4a59-aa5d-e942ffa22aa8",
   "metadata": {},
   "source": [
    "Again, use matplotlib to visualize an example of downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac111d5c-dfa2-44e2-9a57-f2f4c2caff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    x = torch.nn.functional.avg_pool2d(x, kernel_size=4)\n",
    "    x = x.view(x.size(0), -1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edc22bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAIICAYAAABzSo2uAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABOEElEQVR4nO3de3zP9f//8fvbZu8N2xh2Yps5J4aIlkNEWBElIhWSDp+ppOP6JMes9KkUolTUJ6f4RuoXhUIKOXyE+oQtamJzysZi2J6/P/ru/fW2Ob738tr2vl0vl9fl0vv1fj5fr8f71duer/v7dXIYY4wAAAAAAECRK2N3AQAAAAAAlFaEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRueJ2RI0fK4XBcVt8ZM2bI4XBo9+7dRVvUGXbv3i2Hw6EZM2ZYto6SJi0tTf7+/vruu+/sLsUyzz77rFq2bGl3GQAAiw0YMEA1atQo0mXWqFFDAwYMKNJllmR5eXlq2LChXnzxRbtLkcQYD0I3SpCffvpJd999t6pVqyan06nIyEj169dPP/30k92l2WLFihVyOByaP3++3aVYbvTo0WrZsqVatWrlmvfJJ5/ozjvvVM2aNVWuXDnVq1dPTzzxhI4cOVKg/4kTJ5ScnKwGDRqoXLlyqlatmnr16nXZ3x0r1j106FD9+OOPWrRo0WXVBACXI//H5PzJ399fkZGR6ty5s958800dPXrU7hJRhBwOh4YMGWJ3GZabPXu20tLS3D7rgAED3L7rZ09//PHHJa0jfz/sXNOZgZ8xHr52FwBcjE8++UR9+/ZVSEiIBg0apNjYWO3evVvvvfee5s+frzlz5ui22267qGU9//zzevbZZy+rjnvuuUd9+vSR0+m8rP64dAcOHNAHH3ygDz74wG3+Aw88oMjISN19992Kjo7W1q1bNWnSJH3xxRfatGmTAgICXG379eunRYsWafDgwbrmmmu0d+9eTZ48WfHx8dq6datiYmIuqSYr1h0eHq7u3bvrX//6l2699VYPthgAXLrRo0crNjZWp06dUnp6ulasWKGhQ4fqtdde06JFixQXF2d3icBFe+WVV9SnTx8FBwe75j344IPq2LGjWztjjB566CHVqFFD1apVu6R1XHXVVfr3v/9dYP6///1vffXVV+rUqZNrHmM8ZIBiLiUlxZQrV87Ur1/f7N+/3+29AwcOmPr165vy5cub1NTU8y7n2LFjVpZZZHbt2mUkmenTp5+33TfffGMkmXnz5l2Zwmzy2muvmYCAAHP06FG3+d98802Bth988IGRZKZNm+aat2fPHiPJPPnkk25tv/76ayPJvPbaa5dck1Xrnj9/vnE4HBf8LgNAUZk+fbqRZNavX1/gveXLl5uAgAATExNj/vrrLxuqK5369+9vYmJiinSZMTExpn///hdsJ8kkJiYW6bqLm02bNhlJZtmyZRds++233xpJ5sUXXyyy9deuXdvUqVOnwHzGeO/G6eUo9l555RX99ddfeuedd1S1alW396pUqaK3335b2dnZGj9+vGt+/nXbP//8s+666y5VqlRJrVu3dnvvTMePH9ejjz6qKlWqKDAwULfeeqv++OMPORwOjRw50tWusGu6a9Sooa5du2r16tVq0aKF/P39VbNmTX344Ydu6zh8+LCefPJJNWrUSBUqVFBQUJASEhL0448/FtGW+r/PtmPHDt19990KDg5W1apVNXz4cBljlJaWpu7duysoKEjh4eF69dVX3fqfPHlSL7zwgpo1a6bg4GCVL19ebdq00TfffFNgXYcOHdI999yjoKAgVaxYUf3799ePP/5Y6PXov/zyi+644w6FhITI399fzZs3v+hTrBYuXKiWLVuqQoUKbvPbtWtXoG3+2Q7//e9/XfPyT40MCwtzaxsRESFJrqPS+/fvV9WqVdWuXTsZY1ztUlJSVL58ed15552WrTtf/i/wn376aYHlA8CVduONN2r48OH67bff9NFHH7m99/XXX6tNmzYqX768KlasqO7du7v9/duyZYscDofb3/qNGzfK4XDommuucVtWQkKC2/WuFzuunjp1SqNGjVKdOnXk7++vypUrq3Xr1lq6dKlbHQMGDFDNmjXl7++v8PBw3XfffTp06JDbsjwdP/NPNZ47d66ee+45hYeHq3z58rr11luVlpZ2wW2dl5enCRMm6Oqrr5a/v7/CwsL04IMP6s8//3RrZ4zR2LFjVb16dZUrV07t27f36DK7/Lo//vhjjRo1StWqVVNgYKDuuOMOZWZmKicnR0OHDlVoaKgqVKiggQMHKicnx20Z06dP14033qjQ0FA5nU41aNBAU6ZMKfQzjhw5UpGRka7af/7550KvRz9y5IiGDh2qqKgoOZ1O1a5dWy+//LLy8vIu+JkWLlwoPz8/tW3b9oJtZ82aJYfDobvuusvt8zgcDr3//vtubceNGyeHw6EvvvjinMv74YcflJKSon79+hV4jzHey9mb+YELi4yMNDVq1Dhvmxo1apjq1au7Xo8YMcJIMg0aNDDdu3c3b731lpk8ebLbe2fq3bu3kWTuueceM3nyZNO7d2/TuHFjI8mMGDHC1S7/iMCuXbtc82JiYky9evVMWFiYee6558ykSZPMNddcYxwOh9m2bZur3fr1602tWrXMs88+a95++20zevRoU61aNRMcHGz++OMPVztPjnTnf7YmTZqYvn37mrfeesvccsstrqOq9erVMw8//LB56623TKtWrYwks3LlSlf/AwcOmIiICDNs2DAzZcoUM378eFOvXj1TtmxZ85///MfVLjc318THxxsfHx8zZMgQM2nSJHPTTTe5ttmZtW/bts0EBwebBg0amJdfftlMmjTJtG3b1jgcDvPJJ5+c9zOePHnSBAQEmGHDhp23Xb4dO3YYSWbcuHFuy6hevboJDw83ixYtMmlpaWbdunXmhhtuMLGxsebPP/90tZ03b56RZN544w3X52zVqpUJCwszBw8etHTd+WrXrm169ux5UZ8XADx1viPdxhiTlpZmJJk77rjDNW/p0qXG19fX1K1b14wfP96MGjXKVKlSxVSqVMk1Pubm5pqKFSuaJ554wtXv9ddfN2XKlDFlypQxmZmZrnZBQUFuZwRd7Lj63HPPGYfDYQYPHmymTZtmXn31VdO3b1/z0ksvudr861//Mm3atDGjR48277zzjnnsscdMQECAadGihcnLy3O183T8zB+TGzVqZOLi4sxrr71mnn32WePv72/q1q3rdqZAYUe677//fuPr62sGDx5spk6dap555hlTvnx5c+2115qTJ0+62j3//PNGkrn55pvNpEmTzH333WciIyNNlSpVLutId37dTZo0MfHx8ebNN980jz76qHE4HKZPnz7mrrvuMgkJCWby5MnmnnvuMZLMqFGj3JZ57bXXmgEDBpjXX3/dTJw40XTq1MlIMpMmTXJr9/TTTxtJplu3bmbSpElm8ODBpnr16gVqz87ONnFxcaZy5crmueeeM1OnTjX33nuvcTgc5rHHHrvgZ+zYsaO55pprLtju5MmTpnLlyqZVq1YF3uvatasJDg42v//+uzHGmC1bthg/Pz8zaNCg8y7z0UcfNZLMzp07C32fMd57EbpRrB05csRIMt27dz9vu1tvvdVIMllZWcaY/xs8+/btW6Dt2aF748aNRpIZOnSoW7sBAwZcdOiWZFatWuWat3//fuN0Ot12Nk6cOGFyc3Pd1rFr1y7jdDrN6NGj3eZ5GrofeOAB17zTp0+b6tWrG4fD4bYj8ueff5qAgAC3ge706dMmJyfHbT1//vmnCQsLM/fdd59r3v/8z/8YSWbChAmuebm5uebGG28sUHuHDh1Mo0aNzIkTJ1zz8vLyzPXXX1/o6VdnSklJMZLMxIkTz9su36BBg4yPj4/ZsWOH2/x169aZWrVqGUmuqVmzZmbfvn0FltG3b19Trlw5s2PHDvPKK68YSWbhwoVXZN3GGNOpUydz1VVXXdTnBQBPXSh0G2NMcHCwadq0qet1kyZNTGhoqDl06JBr3o8//mjKlClj7r33Xte8W265xbRo0cL1+vbbbze333678fHxMYsXLzbG/N+pwJ9++qmr3cWOq40bNza33HLLeT9fYafFz549u8DyPR0/88fkatWqufZFjDHm448/dvsx15iCoTv/FOeZM2e61blkyRK3+fv37zd+fn7mlltucfvB4LnnnjOSPArdDRs2dAv3ffv2NQ6HwyQkJLj1j4+PL/CDQWHbuHPnzqZmzZqu1+np6cbX19f06NHDrd3IkSML1D5mzBhTvnz5AuPps88+a3x8fFxB+FyqV69+UcH2s88+M5LMW2+9VeC9ffv2mZCQEHPTTTeZnJwc07RpUxMdHe36sagwp0+fNmFhYW7f+bMxxnsvTi9HsZZ/em5gYOB52+W/n5WV5Tb/oYceuuA6lixZIkn6xz/+4Tb/kUceueg6GzRooDZt2rheV61aVfXq1dOvv/7qmud0OlWmzN//5HJzc3Xo0CFVqFBB9erV06ZNmy56XRfj/vvvd/23j4+PmjdvLmOMBg0a5JpfsWLFAjX6+PjIz89P0t+ngR0+fFinT59W8+bN3WpcsmSJypYtq8GDB7vmlSlTRomJiW51HD58WF9//bV69+6to0eP6uDBgzp48KAOHTqkzp07a+fOnee9W2j+6X+VKlW64GeeNWuW3nvvPT3xxBOqU6eO23uVKlVSkyZN9Oyzz2rhwoX617/+pd27d6tXr146ceKEW9tJkyYpODhYd9xxh4YPH6577rlH3bt3vyLrzm9/8ODBC35eALhSKlSo4BqP9+3bp82bN2vAgAEKCQlxtYmLi9NNN93kduptmzZttGnTJmVnZ0uSVq9erZtvvllNmjTRt99+K0n69ttv5XA4XJeA5buYcbVixYr66aeftHPnznPWfuZlPCdOnNDBgwd13XXXSVKhY+/ljp/57r33Xrd9ljvuuEMRERHnPSV53rx5Cg4O1k033eQaJw8ePKhmzZqpQoUKrku8li1bppMnT+qRRx5xu0xu6NCh51z2xbr33ntVtmxZ1+uWLVvKGKP77rvPrV3Lli2Vlpam06dPu+aduY0zMzN18OBB3XDDDfr111+VmZkpSVq+fLlOnz59Ufta8+bNU5s2bVzjYf7UsWNH5ebmatWqVef9LIcOHbro/YayZcuqd+/eBd4LDw/X5MmTtXTpUrVp00abN2/W+++/r6CgoHMub/ny5crIyCj01PJ8jPHei7uXo1jLH7gu9MiSc4Xz2NjYC67jt99+U5kyZQq0rV279kXXGR0dXWBepUqV3K7FysvL0xtvvKG33npLu3btUm5uruu9ypUrX/S6Lqee4OBg+fv7q0qVKgXmn31d2wcffKBXX31Vv/zyi06dOuWaf+b2+e233xQREaFy5cq59T17m6WkpMgYo+HDh2v48OGF1rp///4L3jHUnHGNdWG+/fZbDRo0SJ07dy7wTM7MzEy1adNGTz31lJ544gnX/ObNm6tdu3aaPn26Hn74Ydf8kJAQvfnmm+rVq5fCwsL05ptvXrF153/Wy32OPABY4dixYwoNDZX0999/SapXr16BdldddZW+/PJLZWdnu+4Jcvr0aa1Zs0ZRUVHav3+/2rRpo59++sktdDdo0MAtwEsXN66OHj1a3bt3V926ddWwYUN16dJF99xzj9ud1g8fPqxRo0Zpzpw52r9/v9vy8gPh+dZ7KeOnpAI/vDocDtWuXdvtXjBn27lzpzIzM13b+Gz5dedv+7PXUbVq1YsKmedT2OeWpKioqALz8/LylJmZ6dp3+e677zRixAitWbNGf/31l1v7zMxMBQcHu2o/ez8hJCSkQO07d+7Uli1bCtzHJ9/Z/x8Lc6H9hmPHjunTTz9V586dz7kP1qdPH3300Uf6f//v/+mBBx5Qhw4dzrvMmTNnysfHx+0eMIXVxRjvnQjdKNaCg4MVERGhLVu2nLfdli1bVK1atQK/QJ59oyqr+Pj4FDr/zD/648aN0/Dhw3XfffdpzJgxCgkJUZkyZTR06NCLujGIp/VcTI0fffSRBgwYoB49euipp55SaGiofHx8lJycrNTU1EuuI/9zPfnkk+rcuXOhbc7340b+QHj2jWTO9OOPP+rWW29Vw4YNNX/+fPn6uv9Z+5//+R9lZGQUeETHDTfcoKCgIH333XcFgu+XX37pWu+ePXtUsWLFK7buP//8s8DOHQDYZc+ePcrMzLykH6LzNW/eXP7+/lq1apWio6MVGhqqunXrqk2bNnrrrbeUk5Ojb7/9ttBHfl7MmNW2bVulpqbq008/1VdffaV3331Xr7/+uqZOneo6Yt27d299//33euqpp9SkSRNVqFBBeXl56tKlS6Fj7+WOn57Iy8tTaGioZs6cWej75wqfRelcn/FCnz01NVUdOnRQ/fr19dprrykqKkp+fn764osv9Prrr1/W/k1eXp5uuukmPf3004W+X7du3fP2r1y58nn3G6S/b7b2119/nfeo9KFDh7RhwwZJ0s8//6y8vDzXGYtnO378uBYsWKCOHTsWuHnqmRjjvRehG8Ve165dNW3aNK1evbrA6WfS37+S7969Ww8++OBlLT8mJkZ5eXnatWuX26/HKSkpl11zYebPn6/27dvrvffec5t/5MiRYvMHeP78+apZs6Y++eQTt19iR4wY4dYuJiZG33zzjf766y+3o91nb7OaNWtKksqWLVvg2ZgXIzo6WgEBAdq1a1eh76empqpLly4KDQ3VF198UeAO55KUkZEhSW5nFkh/7zDk5ua6nSIn/X3q/Lvvvqunn35aM2fOVP/+/bVu3boCgdqKdUvSrl271Lhx40I/LwBcafnPIc7/4TQmJkaStH379gJtf/nlF1WpUkXly5eXJPn5+alFixb69ttvFR0d7TpdvE2bNsrJydHMmTOVkZFxUXeZPpeQkBANHDhQAwcO1LFjx9S2bVuNHDlS999/v/78808tX75co0aN0gsvvODqc77T0T119rKNMUpJSTnvc85r1aqlZcuWqVWrVuc9WJC/7Xfu3OkaXyXpwIEDFwyZVvnss8+Uk5OjRYsWuR0tP/upJ/m1p6SkuJ05d+jQoQK116pVS8eOHbus/QZJql+//jn3G/LNnDlTFSpUOO8zsxMTE3X06FElJycrKSlJEyZM0LBhwwptu2jRIh09evS8IV5ijPdmXNONYu+pp55SQECAHnzwwQKnch0+fFgPPfSQypUrp6eeeuqylp+/I/HWW2+5zZ84ceLlFXwOPj4+BX4Vnzdv3nmvab7S8n/RPrPOdevWac2aNW7tOnfurFOnTmnatGmueXl5eZo8ebJbu9DQULVr105vv/229u3bV2B9Bw4cOG89ZcuWVfPmzV2/NJ8pPT1dnTp1UpkyZfTll1+e80hA/i/ic+bMcZu/aNEiZWdnq2nTpq55R44c0f33368WLVpo3Lhxevfdd7Vp0yaNGzfO8nVLf5+Gl5qaquuvv77Q5QHAlfT1119rzJgxio2NdYWJiIgINWnSRB988IGOHDniartt2zZ99dVXuvnmm92W0aZNG61bt07ffPONK3RXqVJFV111lV5++WVXm8tx9j5BhQoVVLt2bdcjrQob0yRpwoQJl7W+i/Hhhx+6XRI3f/587du3TwkJCefs07t3b+Xm5mrMmDEF3jt9+rRrO3fs2FFly5bVxIkT3T6TlZ/nQgrbxpmZmZo+fbpbuw4dOsjX17fAo8QmTZpUYJm9e/fWmjVrXGednenIkSOF/mB9pvj4eG3btq3Ao83yHThwQMuWLdNtt91W4DK5fPPnz9fcuXP10ksv6dlnn1WfPn30/PPPa8eOHYW2nzVrlsqVK1foWRv5GOO9G0e6UezVqVNHH3zwgfr166dGjRpp0KBBio2N1e7du/Xee+/p4MGDmj17tmrVqnVZy2/WrJl69uypCRMm6NChQ7ruuuu0cuVK1x/Worr2pmvXrho9erQGDhyo66+/Xlu3btXMmTPdfq22W9euXfXJJ5/otttu0y233KJdu3Zp6tSpatCggY4dO+Zq16NHD7Vo0UJPPPGEUlJSVL9+fS1atEiHDx+W5L7NJk+erNatW6tRo0YaPHiwatasqYyMDK1Zs0Z79uy54HPKu3fvrn/+85/Kyspyu3ygS5cu+vXXX/X0009r9erVWr16teu9sLAw3XTTTZKkbt266eqrr9bo0aP122+/6brrrlNKSoomTZqkiIgIt5vjPPbYYzp06JCWLVsmHx8fdenSRffff7/Gjh2r7t27u36dtmLd0t83yTHGXPDGbQBQ1BYvXqxffvlFp0+fVkZGhr7++mstXbpUMTExWrRokfz9/V1tX3nlFSUkJCg+Pl6DBg3S8ePHNXHiRAUHB2vkyJFuy23Tpo1efPFFpaWluYXrtm3b6u2331aNGjVUvXr1y6q5QYMGateunZo1a6aQkBBt2LBB8+fP15AhQyRJQUFBatu2rcaPH69Tp06pWrVq+uqrry54FNQTISEhat26tQYOHKiMjAxNmDBBtWvXdrvx6NluuOEGPfjgg0pOTtbmzZvVqVMnlS1bVjt37tS8efP0xhtv6I477lDVqlX15JNPKjk5WV27dtXNN9+s//znP1q8eLFtZ8x16tRJfn5+6tatmx588EEdO3ZM06ZNU2hoqNuP7WFhYXrsscf06quv6tZbb1WXLl30448/umo/c7/hqaee0qJFi9S1a1cNGDBAzZo1U3Z2trZu3ar58+dr9+7d5/283bt315gxY7Ry5Up16tSpwPtz587V6dOnz3lUev/+/Xr44YfVvn1713dp0qRJ+uabbzRgwACtXr3a7TTzw4cPa/HixerZs2ehZ73lY4z3clfwTumAR7Zs2WL69u1rIiIiTNmyZU14eLjp27ev2bp1a4G2+Y/+OHDgwDnfO1N2drZJTEw0ISEhpkKFCqZHjx5m+/btRpLbY0LO9ciwwh5ZcsMNN5gbbrjB9frEiRPmiSeeMBERESYgIMC0atXKrFmzpkC7onhk2Nmfu3///qZ8+fKF1nj11Ve7Xufl5Zlx48aZmJgY43Q6TdOmTc3nn39e6DNFDxw4YO666y4TGBhogoODzYABA8x3331nJJk5c+a4tU1NTTX33nuvCQ8PN2XLljXVqlUzXbt2NfPnzz/vZzTGmIyMDOPr62v+/e9/u83XGY/gOns6c3saY8zhw4fN448/burWrWucTqepUqWK6dOnj/n1119dbT799FMjybz66qtufbOyskxMTIxp3Lix63EqRb3ufHfeeadp3br1BbcJABSV/HEtf/Lz8zPh4eHmpptuMm+88Ybb46/OtGzZMtOqVSsTEBBggoKCTLdu3czPP/9coF1WVpbx8fExgYGB5vTp0675H330kZFk7rnnngJ9LnZcHTt2rGnRooWpWLGiCQgIMPXr1zcvvvii26Ov9uzZY2677TZTsWJFExwcbHr16mX27t1b4JGgno6f+WPy7NmzTVJSkgkNDTUBAQHmlltuMb/99luBZZ49phpjzDvvvGOaNWtmAgICTGBgoGnUqJF5+umnzd69e11tcnNzzahRo1z7Eu3atTPbtm0zMTExHj0y7Mx9CWPO/Si5wrbTokWLTFxcnPH39zc1atQwL7/8snn//fcL7C+dPn3aDB8+3ISHh5uAgABz4403mv/+97+mcuXK5qGHHnJbz9GjR01SUpKpXbu28fPzM1WqVDHXX3+9+de//uX2//dc4uLizvlM7euuu86Ehoa6fR/PdPvtt5vAwECze/dut/n5+wkvv/yy2/ypU6caSWbRokXnrYkx3rs5jCmiu0AApczmzZvVtGlTffTRRxe8Rgd/W7hwoW677TatXr1arVq1KrLlDho0SDt27HDd7bY0Sk9PV2xsrObMmcOv4ABQwqxYsULt27fXvHnzdMcdd9hdTolx5MgRVapUSWPHjtU///nPIlvuv//9byUmJur3338/581QryTGeHBNN6C/7zp5tgkTJqhMmTIe3eClNDt7m+Xm5mrixIkKCgrSNddcU6TrGjFihNavX6/vvvuuSJdbnEyYMEGNGjViMAYAlErn2teSpHbt2hXpuvr166fo6OgC95qxC2M8uKYbkDR+/Hht3LhR7du3l6+vrxYvXqzFixfrgQceKPCMSvztkUce0fHjxxUfH6+cnBx98skn+v777zVu3Lgif1RbdHS0Tpw4UaTLLG5eeuklu0sAAMAyc+fO1YwZM3TzzTerQoUKWr16tWbPnq1OnToV6dlxklSmTBlt27atSJfpCcZ4ELoBSddff72WLl2qMWPG6NixY4qOjtbIkSOL9FSn0ubGG2/Uq6++qs8//1wnTpxQ7dq1NXHiRNdNRwAAAPLFxcXJ19dX48ePV1ZWluvmamPHjrW7NMByXNMNAAAAAIBFuKYbAAAAAACLELoBAAAAALBIsbumOy8vT3v37lVgYKAcDofd5QAAYDtjjI4eParIyEiVKWPP7+WMzwAAuLvY8bnYhe69e/dyt2gAAAqRlpam6tWr27JuxmcAAAp3ofG52IXuwMBASVJr3SxflbW5GgAA7Hdap7RaX7jGSDswPgMA4O5ix+diF7rzT1nzVVn5OhjUAQDQ/z5nxM7TuhmfAQA4y0WOz9xIDQAAAAAAi1gWuidPnqwaNWrI399fLVu21A8//GDVqgAAAAAAKJYsCd1z587VsGHDNGLECG3atEmNGzdW586dtX//fitWBwAAAABAsWRJ6H7ttdc0ePBgDRw4UA0aNNDUqVNVrlw5vf/++1asDgAAAACAYqnIQ/fJkye1ceNGdezY8f9WUqaMOnbsqDVr1hRon5OTo6ysLLcJAAAAAIDSoMhD98GDB5Wbm6uwsDC3+WFhYUpPTy/QPjk5WcHBwa6JZ4ACAAAAAEoL2+9enpSUpMzMTNeUlpZmd0kAAAAAABSJIn9Od5UqVeTj46OMjAy3+RkZGQoPDy/Q3ul0yul0FnUZAAAAAADYrsiPdPv5+alZs2Zavny5a15eXp6WL1+u+Pj4ol4dAAAAAADFVpEf6ZakYcOGqX///mrevLlatGihCRMmKDs7WwMHDrRidQAAAAAAFEuWhO4777xTBw4c0AsvvKD09HQ1adJES5YsKXBzNQAAAAAASjNLQrckDRkyREOGDLFq8QAAAAAAFHu2370cAAAAAIDSitANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAIAXmTx5smrUqCF/f3+1bNlSP/zwg90lAQBQqhG6AQDwEnPnztWwYcM0YsQIbdq0SY0bN1bnzp21f/9+u0sDAKDUInQDAOAlXnvtNQ0ePFgDBw5UgwYNNHXqVJUrV07vv/++3aUBAFBqEboBAPACJ0+e1MaNG9WxY0fXvDJlyqhjx45as2ZNgfY5OTnKyspymwAAwKUjdAMA4AUOHjyo3NxchYWFuc0PCwtTenp6gfbJyckKDg52TVFRUVeqVAAAShVCNwAAKCApKUmZmZmuKS0tze6SAAAokXztLgAAAFivSpUq8vHxUUZGhtv8jIwMhYeHF2jvdDrldDqvVHkAAJRaHOkGAMAL+Pn5qVmzZlq+fLlrXl5enpYvX674+HgbKwMAoHTjSDcAAF5i2LBh6t+/v5o3b64WLVpowoQJys7O1sCBA+0uDQCAUovQDQCAl7jzzjt14MABvfDCC0pPT1eTJk20ZMmSAjdXAwAARYfQDQCAFxkyZIiGDBlidxkAAHgNrukGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAivnYXAAAAUFI4fNl1+mNoC7tLsN3xpsftLsF2ZXxy7S7Bdqf3B9hdgu3qPLrO7hJKBI50AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARX7sLAHBuDl/P/on6VK1SRJXYZ/uTNTzqn1suz6P+MbX2e9Rfksr9w+FR//TX/Dzqv6n5XI/6H8zN9qi/JLWc94RH/WsPW+txDQAAAHbgSDcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgkSIP3SNHjpTD4XCb6tevX9SrAQAAAACg2LPk7uVXX321li1b9n8r8fAOzAAAAAAAlESWpGFfX1+Fh4dbsWgAAAAAAEoMS67p3rlzpyIjI1WzZk3169dPv//++znb5uTkKCsry20CAAAAAKA0KPLQ3bJlS82YMUNLlizRlClTtGvXLrVp00ZHjx4ttH1ycrKCg4NdU1RUVFGXBAAAAACALYo8dCckJKhXr16Ki4tT586d9cUXX+jIkSP6+OOPC22flJSkzMxM15SWllbUJQEAAAAAYAvL73BWsWJF1a1bVykpKYW+73Q65XQ6rS4DAAAAAIArzvLndB87dkypqamKiIiwelUAAAAAABQrRR66n3zySa1cuVK7d+/W999/r9tuu00+Pj7q27dvUa8KAABcpFWrVqlbt26KjIyUw+HQwoUL7S4JAACvUOShe8+ePerbt6/q1aun3r17q3Llylq7dq2qVq1a1KsCAAAXKTs7W40bN9bkyZPtLgUAAK9S5Nd0z5kzp6gXCQAAPJSQkKCEhAS7ywAAwOtYfiM14HL5XFXHo/7GWdaj/ntvqOhRf0k6fl22R/1Dgj3r/23juR71h7T4r0CPl/HypC4e9V/XaJZH/XedOu5R/5cybvKovyRFfms8XgaurJycHOXk5LheZ2Vl2VgNAAAll+U3UgMAACVPcnKygoODXVNUVJTdJQEAUCIRugEAQAFJSUnKzMx0TWlpaXaXBABAicTp5QAAoACn0ymn02l3GQAAlHgc6QYAAAAAwCIc6QYAwAscO3ZMKSkprte7du3S5s2bFRISoujoaBsrAwCgdCN0AwDgBTZs2KD27du7Xg8bNkyS1L9/f82YMcOmqgAAKP0I3QAAeIF27drJGB7dBgDAlcY13QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYxNfuAlB65ba7xqP+r82Y7FH/umX9POqP0uGUyfWo/wsTB3hcg2+28ah//LwhHvUP/OO0R/2dB4971F+Sym1Y5/EyAAAASiKOdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEV+7C0Dp5dy+16P+G09EedS/btkMj/pDemLfdR4v49djVTzqP6PWfI/6Z+YZj/qHvfm9R/1LA8+2IFC6mNxcu0uw3bH6J+0uwXYVyuXYXYLtQicF2F2C7XyXr7O7BJQQHOkGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCK+dheA0uv0vnSP+k98uZdH/V/sku1Rf58tFTzqL0k//mOix8vwxNiDcR71T+lYzuMaco/s86j/XfH/8Kj/7kc96q5Y/ejZAgAAAODVONINAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAIAXSE5O1rXXXqvAwECFhoaqR48e2r59u91lAQBQ6hG6AQDwAitXrlRiYqLWrl2rpUuX6tSpU+rUqZOys7PtLg0AgFLN1+4CAACA9ZYsWeL2esaMGQoNDdXGjRvVtm1bm6oCAKD0I3Sj2AqZvsaj/lU/q+xR/9xDhz3qL0lXN7zPo/4/tX3fo/6L3rnBo/6hR773qH9RcKz50aP+sZ59jYBSKzMzU5IUEhJS6Ps5OTnKyclxvc7KyroidQEAUNpwejkAAF4mLy9PQ4cOVatWrdSwYcNC2yQnJys4ONg1RUVFXeEqAQAoHQjdAAB4mcTERG3btk1z5sw5Z5ukpCRlZma6prS0tCtYIQAApQenlwMA4EWGDBmizz//XKtWrVL16tXP2c7pdMrpdF7BygAAKJ0I3QAAeAFjjB555BEtWLBAK1asUGxsrN0lAQDgFS759PJVq1apW7duioyMlMPh0MKFC93eN8bohRdeUEREhAICAtSxY0ft3LmzqOoFAACXITExUR999JFmzZqlwMBApaenKz09XcePH7e7NAAASrVLDt3Z2dlq3LixJk+eXOj748eP15tvvqmpU6dq3bp1Kl++vDp37qwTJ054XCwAALg8U6ZMUWZmptq1a6eIiAjXNHfuXLtLAwCgVLvk08sTEhKUkJBQ6HvGGE2YMEHPP/+8unfvLkn68MMPFRYWpoULF6pPnz6eVQsAAC6LMcbuEgAA8EpFevfyXbt2KT09XR07dnTNCw4OVsuWLbVmTeEPy83JyVFWVpbbBAAAAABAaVCkoTs9PV2SFBYW5jY/LCzM9d7ZeA4oAAAAAKC0sv053TwHFAAAAABQWhVp6A4PD5ckZWRkuM3PyMhwvXc2p9OpoKAgtwkAAAAAgNKgSEN3bGyswsPDtXz5cte8rKwsrVu3TvHx8UW5KgAAAAAAir1Lvnv5sWPHlJKS4nq9a9cubd68WSEhIYqOjtbQoUM1duxY1alTR7GxsRo+fLgiIyPVo0ePoqwbAAAAAIBi75JD94YNG9S+fXvX62HDhkmS+vfvrxkzZujpp59Wdna2HnjgAR05ckStW7fWkiVL5O/vX3RVAwAAAABQAlxy6G7Xrt15n/XpcDg0evRojR492qPCAAAAAAAo6Wy/ezkAAAAAAKXVJR/pBkqK3IOH7C5Bp7L8bF3/1f1+9qj/gSk+nheRl+v5MgAAAIASiiPdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFjE1+4CgNLsqmd2eNR/YKMOHvWfHrPco/439Er0qL8kBc5d6/EyAKDYMMbuCmxX9/4Ndpdgu5SPmtpdgu0O13faXYLtQj3bzYIX4Ug3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABbxtbsAoDTLPZLpUf9DD1/lUf/fFx33qP+zYz/0qL8kJfW+zaP+5j/BHvWPenGNR/1ljGf9AQAA4NU40g0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AgBeYMmWK4uLiFBQUpKCgIMXHx2vx4sV2lwUAQKlH6AYAwAtUr15dL730kjZu3KgNGzboxhtvVPfu3fXTTz/ZXRoAAKWar90FAAAA63Xr1s3t9YsvvqgpU6Zo7dq1uvrqq22qCgCA0o/QDRRjeT/+16P+fUY95VH/mSP+5VF/Sdp83YeeLeA6z7pfXX6IR/3rTNvnWQGSTv+62+NlAEUpNzdX8+bNU3Z2tuLj4wttk5OTo5ycHNfrrKysK1UeAAClCqeXAwDgJbZu3aoKFSrI6XTqoYce0oIFC9SgQYNC2yYnJys4ONg1RUVFXeFqAQAoHQjdAAB4iXr16mnz5s1at26dHn74YfXv318///xzoW2TkpKUmZnpmtLS0q5wtQAAlA6cXg4AgJfw8/NT7dq1JUnNmjXT+vXr9cYbb+jtt98u0NbpdMrpdF7pEgEAKHU40g0AgJfKy8tzu24bAAAUPY50AwDgBZKSkpSQkKDo6GgdPXpUs2bN0ooVK/Tll1/aXRoAAKUaoRsAAC+wf/9+3Xvvvdq3b5+Cg4MVFxenL7/8UjfddJPdpQEAUKoRugEA8ALvvfee3SUAAOCVuKYbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIv42l0AAOuEvL/Go/5Dtid6XEPQS3s86j+75pce9f/p3kke9a8fdb9H/SWp3ijPft/M3fmrxzUAAADAHhzpBgAAAADAIoRuAAAAAAAsQugGAAAAAMAilxy6V61apW7duikyMlIOh0MLFy50e3/AgAFyOBxuU5cuXYqqXgAAAAAASoxLDt3Z2dlq3LixJk+efM42Xbp00b59+1zT7NmzPSoSAAAAAICS6JLvXp6QkKCEhITztnE6nQoPD7/sogAAAAAAKA0suaZ7xYoVCg0NVb169fTwww/r0KFD52ybk5OjrKwstwkAAAAAgNKgyEN3ly5d9OGHH2r58uV6+eWXtXLlSiUkJCg3N7fQ9snJyQoODnZNUVFRRV0SAAAAAAC2uOTTyy+kT58+rv9u1KiR4uLiVKtWLa1YsUIdOnQo0D4pKUnDhg1zvc7KyiJ4AwAAAABKBcsfGVazZk1VqVJFKSkphb7vdDoVFBTkNgEAAAAAUBpYHrr37NmjQ4cOKSIiwupVAQAAAABQrFzy6eXHjh1zO2q9a9cubd68WSEhIQoJCdGoUaPUs2dPhYeHKzU1VU8//bRq166tzp07F2nhAAAAAAAUd5ccujds2KD27du7Xudfj92/f39NmTJFW7Zs0QcffKAjR44oMjJSnTp10pgxY+R0OouuagAAAAAASoBLDt3t2rWTMeac73/55ZceFQQAAAAAQGlh+TXdAAAAAAB4qyJ/ZBiA0sPx3WaPl/HXHaEe9b/2zkc86r/umTc86v9L+3c96i9J/Wp08qh/ZmuPSwAAFKHIT/zsLsF23056y+4SbNfl3ZZ2l2A7k5NjdwklAke6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALCIr90FACjdcjP2e9Q/7E3P+p94+rRH/cs5/DzqL0nTanzuUf+utw31qH+5Bes86g8AAIDLx5FuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAC80EsvvSSHw6GhQ4faXQoAAKUaoRsAAC+zfv16vf3224qLi7O7FAAASj1CNwAAXuTYsWPq16+fpk2bpkqVKtldDgAApZ6v3QUAKL7yWjfxeBmpvfw96t+wyW6P+pdz+HnUvyhMPNzUo/7lPt1QRJUAUmJiom655RZ17NhRY8eOPWe7nJwc5eTkuF5nZWVdifIAACh1CN0AAHiJOXPmaNOmTVq/fv0F2yYnJ2vUqFFXoCoAAEo3Ti8HAMALpKWl6bHHHtPMmTPl73/hM1CSkpKUmZnpmtLS0q5AlQAAlD4c6QYAwAts3LhR+/fv1zXXXOOal5ubq1WrVmnSpEnKycmRj4+P6z2n0ymn02lHqQAAlCqEbgAAvECHDh20detWt3kDBw5U/fr19cwzz7gFbgAAUHQI3QAAeIHAwEA1bNjQbV758uVVuXLlAvMBAEDR4ZpuAAAAAAAswpFuAAC81IoVK+wuAQCAUo8j3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYxNfuAgCcm6N5Q4/673jUz6P+01p94FF/SWrrf9LjZdgpx5zyeBlrD8d6toC8fR7XAAAAAHtwpBsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAi/jaXQBQXPnGxni8jNSBkR71H3nnHI/696xw0KP+pcFzGc096r/yjes8rqHSB2s8XgaA4iH7jpZ2l2C7tv/kb9qx3E12l2C7m3oPsLsE25XJ2Wx3CSghONINAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWOSSQndycrKuvfZaBQYGKjQ0VD169ND27dvd2pw4cUKJiYmqXLmyKlSooJ49eyojI6NIiwYAAAAAoCS4pNC9cuVKJSYmau3atVq6dKlOnTqlTp06KTs729Xm8ccf12effaZ58+Zp5cqV2rt3r26//fYiLxwAAAAAgOLukh4ZtmTJErfXM2bMUGhoqDZu3Ki2bdsqMzNT7733nmbNmqUbb7xRkjR9+nRdddVVWrt2ra67zvNH7wAAAAAAUFJ4dE13ZmamJCkkJESStHHjRp06dUodO3Z0talfv76io6O1Zk3hz3TMyclRVlaW2wQAAAAAQGlw2aE7Ly9PQ4cOVatWrdSwYUNJUnp6uvz8/FSxYkW3tmFhYUpPTy90OcnJyQoODnZNUVFRl1sSAAAAAADFymWH7sTERG3btk1z5szxqICkpCRlZma6prS0NI+WBwAAAABAcXFJ13TnGzJkiD7//HOtWrVK1atXd80PDw/XyZMndeTIEbej3RkZGQoPDy90WU6nU06n83LKAAAAAACgWLukI93GGA0ZMkQLFizQ119/rdjYWLf3mzVrprJly2r58uWuedu3b9fvv/+u+Pj4oqkYAAAAAIAS4pKOdCcmJmrWrFn69NNPFRgY6LpOOzg4WAEBAQoODtagQYM0bNgwhYSEKCgoSI888oji4+O5czkAAAAAwOtcUuieMmWKJKldu3Zu86dPn64BAwZIkl5//XWVKVNGPXv2VE5Ojjp37qy33nqrSIoFAAAAAKAkuaTQbYy5YBt/f39NnjxZkydPvuyiAAAAAAAoDS7rRmrAleBbI9qj/pnNIjzqf+foJR71l6SHKn7i8TJKuif2eXZpyZq3mnvUP2TGDx71r5S3xqP+AAAA8G6X/cgwAAAAAABwfoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgDAC4wcOVIOh8Ntql+/vt1lAQBQ6vnaXQAAALgyrr76ai1btsz12teX3QAAAKzGaAsAgJfw9fVVeHi43WUAAOBVCN0olG+E5ztlh98v71H/h2NXetS/b2CGR/1LgyF/tPao/6YpTTyuocr8bR71Dzm6xuMaAPxt586dioyMlL+/v+Lj45WcnKzo6OhC2+bk5CgnJ8f1Oisr60qVCQBAqcI13QAAeIGWLVtqxowZWrJkiaZMmaJdu3apTZs2Onr0aKHtk5OTFRwc7JqioqKucMUAAJQOhG4AALxAQkKCevXqpbi4OHXu3FlffPGFjhw5oo8//rjQ9klJScrMzHRNaWlpV7hiAABKB04vBwDAC1WsWFF169ZVSkpKoe87nU45nc4rXBUAAKUPR7oBAPBCx44dU2pqqiIiIuwuBQCAUo3QDQCAF3jyySe1cuVK7d69W99//71uu+02+fj4qG/fvnaXBgBAqcbp5QAAeIE9e/aob9++OnTokKpWrarWrVtr7dq1qlq1qt2lAQBQqhG6AQDwAnPmzLG7BAAAvBKnlwMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEV+7C0DhTnZu7ln/xw971P+52l941F+SOgVke7yMki4j97hH/dsuesKj/vWf/8Wj/iFH1njUX5LyPF4CAAAAUHJxpBsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAi/jaXQAKt7uHZ7+H7Gg0r4gqsc/kI7U86v/Gyk4e9XfkOjzqL0n1x+7yqH+djHUe9c/1qDcAAAVtuq+R3SXYzvznJ7tLsF0Zbba7BKDE4Eg3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABbxtbsAFK7uwz941L/rw82KqJKSq64824ZFIdfuAgAAAADYiiPdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUuKXQnJyfr2muvVWBgoEJDQ9WjRw9t377drU27du3kcDjcpoceeqhIiwYAAAAAoCS4pNC9cuVKJSYmau3atVq6dKlOnTqlTp06KTs7263d4MGDtW/fPtc0fvz4Ii0aAAAAAICS4JIeGbZkyRK31zNmzFBoaKg2btyotm3buuaXK1dO4eHhRVMhAAAAAAAllEfXdGdmZkqSQkJC3ObPnDlTVapUUcOGDZWUlKS//vrrnMvIyclRVlaW2wQAAAAAQGlwSUe6z5SXl6ehQ4eqVatWatiwoWv+XXfdpZiYGEVGRmrLli165plntH37dn3yySeFLic5OVmjRo263DIAAAAAACi2Ljt0JyYmatu2bVq9erXb/AceeMD1340aNVJERIQ6dOig1NRU1apVq8BykpKSNGzYMNfrrKwsRUVFXW5ZAAAAAAAUG5cVuocMGaLPP/9cq1atUvXq1c/btmXLlpKklJSUQkO30+mU0+m8nDIAAAAAACjWLil0G2P0yCOPaMGCBVqxYoViY2Mv2Gfz5s2SpIiIiMsqEAAAAACAkuqSbqSWmJiojz76SLNmzVJgYKDS09OVnp6u48ePS5JSU1M1ZswYbdy4Ubt379aiRYt07733qm3btoqLi7PkAwAAgIvzxx9/6O6771blypUVEBCgRo0aacOGDXaXBQBAqXZJR7qnTJkiSWrXrp3b/OnTp2vAgAHy8/PTsmXLNGHCBGVnZysqKko9e/bU888/X2QFAwCAS/fnn3+qVatWat++vRYvXqyqVatq586dqlSpkt2lAQBQql3y6eXnExUVpZUrV3pUEAAAKHovv/yyoqKiNH36dNe8i7lMDAAAeMaj53QDAICSYdGiRWrevLl69eql0NBQNW3aVNOmTTtn+5ycHGVlZblNAADg0hG6AQDwAr/++qumTJmiOnXq6Msvv9TDDz+sRx99VB988EGh7ZOTkxUcHOyaeJwnAACXh9ANAIAXyMvL0zXXXKNx48apadOmeuCBBzR48GBNnTq10PZJSUnKzMx0TWlpaVe4YgAASgdCNwAAXiAiIkINGjRwm3fVVVfp999/L7S90+lUUFCQ2wQAAC4doRsAAC/QqlUrbd++3W3ejh07FBMTY1NFAAB4B0I3AABe4PHHH9fatWs1btw4paSkaNasWXrnnXeUmJhod2kAAJRqhG4AALzAtddeqwULFmj27Nlq2LChxowZowkTJqhfv352lwYAQKl2Sc/pBgAAJVfXrl3VtWtXu8sAAMCrcKQbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwiK/dBZzNGCNJOq1TkrG5GAAAioHTOiXp/8ZIOzA+/+30qRN2l2C707k5dpdgO2NO2V0CgGLgYsfnYhe6jx49KklarS9srgQAgOLl6NGjCg4Otm3dEuOzFn5qdwUAgGLmQuOzw9j5s3kh8vLytHfvXgUGBsrhcBR4PysrS1FRUUpLS1NQUJANFZYObEfPsQ09xzb0HNvQcyVhGxpjdPToUUVGRqpMGXuuDLvQ+HwllIT/V1ZjG7ANJLaBxDaQ2AaS/dvgYsfnYneku0yZMqpevfoF2wUFBXntl6sosR09xzb0HNvQc2xDzxX3bWjXEe58Fzs+XwnF/f/VlcA2YBtIbAOJbSCxDSR7t8HFjM/cSA0AAAAAAIsQugEAAAAAsEiJC91Op1MjRoyQ0+m0u5QSje3oObah59iGnmMbeo5tWHLw/4ptILENJLaBxDaQ2AZSydkGxe5GagAAAAAAlBYl7kg3AAAAAAAlBaEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsEiJC92TJ09WjRo15O/vr5YtW+qHH36wu6QSY+TIkXI4HG5T/fr17S6r2Fu1apW6deumyMhIORwOLVy40O19Y4xeeOEFRUREKCAgQB07dtTOnTvtKbaYutA2HDBgQIHvZpcuXewpthhKTk7Wtddeq8DAQIWGhqpHjx7avn27W5sTJ04oMTFRlStXVoUKFdSzZ09lZGTYVHHxdDHbsV27dgW+iw899JBNFeNM3j7+X+jvaGl3Mf9+S7spU6YoLi5OQUFBCgoKUnx8vBYvXmx3WbZ66aWX5HA4NHToULtLuWLYn//bH3/8obvvvluVK1dWQECAGjVqpA0bNthd1jmVqNA9d+5cDRs2TCNGjNCmTZvUuHFjde7cWfv377e7tBLj6quv1r59+1zT6tWr7S6p2MvOzlbjxo01efLkQt8fP3683nzzTU2dOlXr1q1T+fLl1blzZ504ceIKV1p8XWgbSlKXLl3cvpuzZ8++ghUWbytXrlRiYqLWrl2rpUuX6tSpU+rUqZOys7NdbR5//HF99tlnmjdvnlauXKm9e/fq9ttvt7Hq4uditqMkDR482O27OH78eJsqRj7G/4v7O1qaXey/39KsevXqeumll7Rx40Zt2LBBN954o7p3766ffvrJ7tJssX79er399tuKi4uzu5Qrztv35//880+1atVKZcuW1eLFi/Xzzz/r1VdfVaVKlewu7dxMCdKiRQuTmJjoep2bm2siIyNNcnKyjVWVHCNGjDCNGze2u4wSTZJZsGCB63VeXp4JDw83r7zyimvekSNHjNPpNLNnz7ahwuLv7G1ojDH9+/c33bt3t6Wekmj//v1Gklm5cqUx5u/vXNmyZc28efNcbf773/8aSWbNmjV2lVnsnb0djTHmhhtuMI899ph9RaFQjP/uCvs76m0K+/frjSpVqmTeffddu8u44o4ePWrq1Kljli5d6nV/t9mfN+aZZ54xrVu3truMS1JijnSfPHlSGzduVMeOHV3zypQpo44dO2rNmjU2Vlay7Ny5U5GRkapZs6b69eun33//3e6SSrRdu3YpPT3d7XsZHBysli1b8r28RCtWrFBoaKjq1aunhx9+WIcOHbK7pGIrMzNTkhQSEiJJ2rhxo06dOuX2Paxfv76io6P5Hp7H2dsx38yZM1WlShU1bNhQSUlJ+uuvv+woD/+L8R+FOde/X2+Rm5urOXPmKDs7W/Hx8XaXc8UlJibqlltucfu74E28fX9+0aJFat68uXr16qXQ0FA1bdpU06ZNs7us8/K1u4CLdfDgQeXm5iosLMxtflhYmH755RebqipZWrZsqRkzZqhevXrat2+fRo0apTZt2mjbtm0KDAy0u7wSKT09XZIK/V7mv4cL69Kli26//XbFxsYqNTVVzz33nBISErRmzRr5+PjYXV6xkpeXp6FDh6pVq1Zq2LChpL+/h35+fqpYsaJbW76H51bYdpSku+66SzExMYqMjNSWLVv0zDPPaPv27frkk09srNa7Mf7jbOf69+sNtm7dqvj4eJ04cUIVKlTQggUL1KBBA7vLuqLmzJmjTZs2af369XaXYgv256Vff/1VU6ZM0bBhw/Tcc89p/fr1evTRR+Xn56f+/fvbXV6hSkzohucSEhJc/x0XF6eWLVsqJiZGH3/8sQYNGmRjZfB2ffr0cf13o0aNFBcXp1q1amnFihXq0KGDjZUVP4mJidq2bZvXXb9V1M61HR944AHXfzdq1EgRERHq0KGDUlNTVatWrStdJoBCePPfwXr16mnz5s3KzMzU/Pnz1b9/f61cudJrgndaWpoee+wxLV26VP7+/naXYwv25//+4a158+YaN26cJKlp06batm2bpk6dWmxDd4k5vbxKlSry8fEpcDfejIwMhYeH21RVyVaxYkXVrVtXKSkpdpdSYuV/9/heFq2aNWuqSpUqfDfPMmTIEH3++ef65ptvVL16ddf88PBwnTx5UkeOHHFrz/ewcOfajoVp2bKlJPFdtBHjP850Kf9+SyM/Pz/Vrl1bzZo1U3Jysho3bqw33njD7rKumI0bN2r//v265ppr5OvrK19fX61cuVJvvvmmfH19lZuba3eJV5w37s9HREQU+KHpqquuKtan2ZeY0O3n56dmzZpp+fLlrnl5eXlavny5V17LUhSOHTum1NRURURE2F1KiRUbG6vw8HC372VWVpbWrVvH99IDe/bs0aFDh/hu/i9jjIYMGaIFCxbo66+/VmxsrNv7zZo1U9myZd2+h9u3b9fvv//O9/AMF9qOhdm8ebMk8V20EeM/pMv79+sN8vLylJOTY3cZV0yHDh20detWbd682TU1b95c/fr10+bNm73ykjRv3J9v1apVgUcG7tixQzExMTZVdGEl6vTyYcOGqX///mrevLlatGihCRMmKDs7WwMHDrS7tBLhySefVLdu3RQTE6O9e/dqxIgR8vHxUd++fe0urVg7duyY26+Hu3bt0ubNmxUSEqLo6GgNHTpUY8eOVZ06dRQbG6vhw4crMjJSPXr0sK/oYuZ82zAkJESjRo1Sz549FR4ertTUVD399NOqXbu2OnfubGPVxUdiYqJmzZqlTz/9VIGBga7rtIODgxUQEKDg4GANGjRIw4YNU0hIiIKCgvTII48oPj5e1113nc3VFx8X2o6pqamaNWuWbr75ZlWuXFlbtmzR448/rrZt23rlI2mKE8b/C49Fpd2F/v16g6SkJCUkJCg6OlpHjx7VrFmztGLFCn355Zd2l3bFBAYGFriOv3z58qpcubLXXN/P/vzfj0m9/vrrNW7cOPXu3Vs//PCD3nnnHb3zzjt2l3ZuNt89/ZJNnDjRREdHGz8/P9OiRQuzdu1au0sqMe68804TERFh/Pz8TLVq1cydd95pUlJS7C6r2Pvmm2+MpAJT//79jTF/PzZs+PDhJiwszDidTtOhQwezfft2e4suZs63Df/66y/TqVMnU7VqVVO2bFkTExNjBg8ebNLT0+0uu9gobNtJMtOnT3e1OX78uPnHP/5hKlWqZMqVK2duu+02s2/fPvuKLoYutB1///1307ZtWxMSEmKcTqepXbu2eeqpp0xmZqa9hcMYw/h/obGotLuYv4Ol3X333WdiYmKMn5+fqVq1qunQoYP56quv7C7Ldt72yDD25//22WefmYYNGxqn02nq169v3nnnHbtLOi+HMcZYnuwBAAAAAPBCJeaabgAAAAAAShpCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGCR/w/h/S11E4YDBwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([1, 28, 28])\n",
      "Downsampled shape: torch.Size([1, 7, 7])\n",
      "Flattened shape: torch.Size([1, 49])\n"
     ]
    }
   ],
   "source": [
    "img = train_dataset[0][0]  \n",
    "img_original = img.squeeze().numpy()\n",
    "img_downsampled = torch.nn.functional.avg_pool2d(img, kernel_size=4).squeeze().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_original)\n",
    "plt.title('Original Image (28x28)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_downsampled)\n",
    "plt.title('Downsampled Image (7x7)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Original shape: {img.shape}\")\n",
    "print(f\"Downsampled shape: {torch.nn.functional.avg_pool2d(img, kernel_size=4).shape}\")\n",
    "print(f\"Flattened shape: {preprocess(img.unsqueeze(0)).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aa4adcb-be17-4f0d-ba9f-4da062227230",
   "metadata": {
    "id": "2v3GqEPU3z0L"
   },
   "outputs": [],
   "source": [
    "### YOUR ( MODEL / PREPROCESSING ) CODE HERE ###\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.linear = nn.Linear(49, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5becae4-e27f-43ed-a1c5-ced8c16f4cac",
   "metadata": {
    "id": "qeWZ7DeNMG20"
   },
   "source": [
    "## A.2 - Loss and optimizer\n",
    "Create a cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a85b789e",
   "metadata": {
    "id": "a85b789e"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = LinearModel().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aec31b-3d2b-4b29-ad85-e88a6e25660a",
   "metadata": {
    "id": "ZCnlsh9iMhx_"
   },
   "source": [
    "## A.3 - Training and testing loops\n",
    "Finally, create the functions `train(model, epoch, preprocess, optimizer)` and `test(model)` to train (one epoch with SGD and a learning rate of $10^{-3}$) and test your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "521e5485-b676-4f73-bedc-d35c5fcfd394",
   "metadata": {
    "id": "iMXijrch3z0L"
   },
   "outputs": [],
   "source": [
    "def train(model, epoch, preprocess, optimizer):\n",
    "    ### YOUR CODE HERE ###\n",
    "    optimizer, train_accuracy = None, None \n",
    "    return optimizer, train_accuracy\n",
    "\n",
    "def test(model, preprocess):\n",
    "    ### YOUR CODE HERE ###\n",
    "    accuracy = None\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1539b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, preprocess, optimizer):\n",
    "    model.train()  \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        data = preprocess(data)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        \n",
    "        if batch_idx % 100 == 99:\n",
    "            print(f'Epoch: {epoch}, Batch: {batch_idx+1}, Loss: {running_loss/100:.3f}, Accuracy: {100*correct/total:.2f}%')\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    train_accuracy = 100 * correct / total\n",
    "    print(f'Train Accuracy: {train_accuracy:.2f}%')\n",
    "    \n",
    "    return optimizer, train_accuracy\n",
    "\n",
    "\n",
    "def test(model, preprocess):\n",
    "    model.eval()  \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            data = preprocess(data)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3caf21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 100, Loss: 2.326, Accuracy: 12.50%\n",
      "Epoch: 1, Batch: 200, Loss: 2.320, Accuracy: 12.94%\n",
      "Epoch: 1, Batch: 300, Loss: 2.323, Accuracy: 12.75%\n",
      "Epoch: 1, Batch: 400, Loss: 2.320, Accuracy: 12.91%\n",
      "Epoch: 1, Batch: 500, Loss: 2.303, Accuracy: 13.43%\n",
      "Epoch: 1, Batch: 600, Loss: 2.310, Accuracy: 13.77%\n",
      "Epoch: 1, Batch: 700, Loss: 2.285, Accuracy: 14.14%\n",
      "Epoch: 1, Batch: 800, Loss: 2.298, Accuracy: 14.58%\n",
      "Epoch: 1, Batch: 900, Loss: 2.285, Accuracy: 15.04%\n",
      "Epoch: 1, Batch: 1000, Loss: 2.287, Accuracy: 15.29%\n",
      "Epoch: 1, Batch: 1100, Loss: 2.273, Accuracy: 15.69%\n",
      "Epoch: 1, Batch: 1200, Loss: 2.274, Accuracy: 16.24%\n",
      "Epoch: 1, Batch: 1300, Loss: 2.277, Accuracy: 16.41%\n",
      "Epoch: 1, Batch: 1400, Loss: 2.266, Accuracy: 16.88%\n",
      "Epoch: 1, Batch: 1500, Loss: 2.262, Accuracy: 17.22%\n",
      "Epoch: 1, Batch: 1600, Loss: 2.254, Accuracy: 17.71%\n",
      "Epoch: 1, Batch: 1700, Loss: 2.251, Accuracy: 17.94%\n",
      "Epoch: 1, Batch: 1800, Loss: 2.253, Accuracy: 18.33%\n",
      "Epoch: 1, Batch: 1900, Loss: 2.244, Accuracy: 18.84%\n",
      "Epoch: 1, Batch: 2000, Loss: 2.235, Accuracy: 19.22%\n",
      "Epoch: 1, Batch: 2100, Loss: 2.231, Accuracy: 19.77%\n",
      "Epoch: 1, Batch: 2200, Loss: 2.237, Accuracy: 20.17%\n",
      "Epoch: 1, Batch: 2300, Loss: 2.225, Accuracy: 20.73%\n",
      "Epoch: 1, Batch: 2400, Loss: 2.226, Accuracy: 21.28%\n",
      "Epoch: 1, Batch: 2500, Loss: 2.222, Accuracy: 21.93%\n",
      "Epoch: 1, Batch: 2600, Loss: 2.219, Accuracy: 22.50%\n",
      "Epoch: 1, Batch: 2700, Loss: 2.210, Accuracy: 23.00%\n",
      "Epoch: 1, Batch: 2800, Loss: 2.209, Accuracy: 23.50%\n",
      "Epoch: 1, Batch: 2900, Loss: 2.201, Accuracy: 24.08%\n",
      "Epoch: 1, Batch: 3000, Loss: 2.196, Accuracy: 24.61%\n",
      "Epoch: 1, Batch: 3100, Loss: 2.194, Accuracy: 25.15%\n",
      "Epoch: 1, Batch: 3200, Loss: 2.191, Accuracy: 25.70%\n",
      "Epoch: 1, Batch: 3300, Loss: 2.190, Accuracy: 26.29%\n",
      "Epoch: 1, Batch: 3400, Loss: 2.175, Accuracy: 26.90%\n",
      "Epoch: 1, Batch: 3500, Loss: 2.176, Accuracy: 27.37%\n",
      "Epoch: 1, Batch: 3600, Loss: 2.176, Accuracy: 27.86%\n",
      "Epoch: 1, Batch: 3700, Loss: 2.167, Accuracy: 28.44%\n",
      "Epoch: 1, Batch: 3800, Loss: 2.166, Accuracy: 28.93%\n",
      "Epoch: 1, Batch: 3900, Loss: 2.163, Accuracy: 29.39%\n",
      "Epoch: 1, Batch: 4000, Loss: 2.163, Accuracy: 29.83%\n",
      "Epoch: 1, Batch: 4100, Loss: 2.153, Accuracy: 30.25%\n",
      "Epoch: 1, Batch: 4200, Loss: 2.161, Accuracy: 30.65%\n",
      "Epoch: 1, Batch: 4300, Loss: 2.150, Accuracy: 31.05%\n",
      "Epoch: 1, Batch: 4400, Loss: 2.154, Accuracy: 31.45%\n",
      "Epoch: 1, Batch: 4500, Loss: 2.137, Accuracy: 31.86%\n",
      "Epoch: 1, Batch: 4600, Loss: 2.137, Accuracy: 32.26%\n",
      "Epoch: 1, Batch: 4700, Loss: 2.140, Accuracy: 32.58%\n",
      "Epoch: 1, Batch: 4800, Loss: 2.132, Accuracy: 32.92%\n",
      "Epoch: 1, Batch: 4900, Loss: 2.121, Accuracy: 33.34%\n",
      "Epoch: 1, Batch: 5000, Loss: 2.113, Accuracy: 33.76%\n",
      "Epoch: 1, Batch: 5100, Loss: 2.119, Accuracy: 34.12%\n",
      "Epoch: 1, Batch: 5200, Loss: 2.117, Accuracy: 34.44%\n",
      "Epoch: 1, Batch: 5300, Loss: 2.105, Accuracy: 34.82%\n",
      "Epoch: 1, Batch: 5400, Loss: 2.107, Accuracy: 35.18%\n",
      "Epoch: 1, Batch: 5500, Loss: 2.120, Accuracy: 35.40%\n",
      "Epoch: 1, Batch: 5600, Loss: 2.100, Accuracy: 35.71%\n",
      "Epoch: 1, Batch: 5700, Loss: 2.094, Accuracy: 36.01%\n",
      "Epoch: 1, Batch: 5800, Loss: 2.088, Accuracy: 36.33%\n",
      "Epoch: 1, Batch: 5900, Loss: 2.095, Accuracy: 36.58%\n",
      "Epoch: 1, Batch: 6000, Loss: 2.088, Accuracy: 36.88%\n",
      "Epoch: 1, Batch: 6100, Loss: 2.089, Accuracy: 37.17%\n",
      "Epoch: 1, Batch: 6200, Loss: 2.081, Accuracy: 37.45%\n",
      "Epoch: 1, Batch: 6300, Loss: 2.079, Accuracy: 37.70%\n",
      "Epoch: 1, Batch: 6400, Loss: 2.081, Accuracy: 37.98%\n",
      "Epoch: 1, Batch: 6500, Loss: 2.065, Accuracy: 38.29%\n",
      "Epoch: 1, Batch: 6600, Loss: 2.072, Accuracy: 38.56%\n",
      "Epoch: 1, Batch: 6700, Loss: 2.055, Accuracy: 38.82%\n",
      "Epoch: 1, Batch: 6800, Loss: 2.066, Accuracy: 39.07%\n",
      "Epoch: 1, Batch: 6900, Loss: 2.059, Accuracy: 39.34%\n",
      "Epoch: 1, Batch: 7000, Loss: 2.051, Accuracy: 39.62%\n",
      "Epoch: 1, Batch: 7100, Loss: 2.053, Accuracy: 39.83%\n",
      "Epoch: 1, Batch: 7200, Loss: 2.052, Accuracy: 40.07%\n",
      "Epoch: 1, Batch: 7300, Loss: 2.036, Accuracy: 40.33%\n",
      "Epoch: 1, Batch: 7400, Loss: 2.043, Accuracy: 40.58%\n",
      "Epoch: 1, Batch: 7500, Loss: 2.036, Accuracy: 40.81%\n",
      "Train Accuracy: 40.81%\n",
      "Test Accuracy: 61.44%\n",
      "Epoch: 2, Batch: 100, Loss: 2.030, Accuracy: 59.75%\n",
      "Epoch: 2, Batch: 200, Loss: 2.019, Accuracy: 59.56%\n",
      "Epoch: 2, Batch: 300, Loss: 2.034, Accuracy: 58.46%\n",
      "Epoch: 2, Batch: 400, Loss: 2.017, Accuracy: 58.97%\n",
      "Epoch: 2, Batch: 500, Loss: 2.010, Accuracy: 59.52%\n",
      "Epoch: 2, Batch: 600, Loss: 2.017, Accuracy: 60.08%\n",
      "Epoch: 2, Batch: 700, Loss: 2.020, Accuracy: 60.00%\n",
      "Epoch: 2, Batch: 800, Loss: 2.004, Accuracy: 60.02%\n",
      "Epoch: 2, Batch: 900, Loss: 1.999, Accuracy: 60.36%\n",
      "Epoch: 2, Batch: 1000, Loss: 1.998, Accuracy: 60.42%\n",
      "Epoch: 2, Batch: 1100, Loss: 1.997, Accuracy: 60.50%\n",
      "Epoch: 2, Batch: 1200, Loss: 1.985, Accuracy: 60.62%\n",
      "Epoch: 2, Batch: 1300, Loss: 1.982, Accuracy: 60.85%\n",
      "Epoch: 2, Batch: 1400, Loss: 1.984, Accuracy: 60.96%\n",
      "Epoch: 2, Batch: 1500, Loss: 1.989, Accuracy: 61.03%\n",
      "Epoch: 2, Batch: 1600, Loss: 2.000, Accuracy: 60.96%\n",
      "Epoch: 2, Batch: 1700, Loss: 1.982, Accuracy: 60.99%\n",
      "Epoch: 2, Batch: 1800, Loss: 1.957, Accuracy: 61.36%\n",
      "Epoch: 2, Batch: 1900, Loss: 1.981, Accuracy: 61.38%\n",
      "Epoch: 2, Batch: 2000, Loss: 1.950, Accuracy: 61.74%\n",
      "Epoch: 2, Batch: 2100, Loss: 1.971, Accuracy: 61.73%\n",
      "Epoch: 2, Batch: 2200, Loss: 1.968, Accuracy: 61.80%\n",
      "Epoch: 2, Batch: 2300, Loss: 1.965, Accuracy: 61.89%\n",
      "Epoch: 2, Batch: 2400, Loss: 1.947, Accuracy: 62.02%\n",
      "Epoch: 2, Batch: 2500, Loss: 1.944, Accuracy: 62.27%\n",
      "Epoch: 2, Batch: 2600, Loss: 1.958, Accuracy: 62.26%\n",
      "Epoch: 2, Batch: 2700, Loss: 1.942, Accuracy: 62.35%\n",
      "Epoch: 2, Batch: 2800, Loss: 1.942, Accuracy: 62.43%\n",
      "Epoch: 2, Batch: 2900, Loss: 1.932, Accuracy: 62.59%\n",
      "Epoch: 2, Batch: 3000, Loss: 1.925, Accuracy: 62.64%\n",
      "Epoch: 2, Batch: 3100, Loss: 1.940, Accuracy: 62.71%\n",
      "Epoch: 2, Batch: 3200, Loss: 1.936, Accuracy: 62.76%\n",
      "Epoch: 2, Batch: 3300, Loss: 1.921, Accuracy: 62.83%\n",
      "Epoch: 2, Batch: 3400, Loss: 1.933, Accuracy: 62.87%\n",
      "Epoch: 2, Batch: 3500, Loss: 1.922, Accuracy: 62.94%\n",
      "Epoch: 2, Batch: 3600, Loss: 1.911, Accuracy: 63.00%\n",
      "Epoch: 2, Batch: 3700, Loss: 1.912, Accuracy: 63.11%\n",
      "Epoch: 2, Batch: 3800, Loss: 1.921, Accuracy: 63.12%\n",
      "Epoch: 2, Batch: 3900, Loss: 1.896, Accuracy: 63.27%\n",
      "Epoch: 2, Batch: 4000, Loss: 1.911, Accuracy: 63.36%\n",
      "Epoch: 2, Batch: 4100, Loss: 1.907, Accuracy: 63.39%\n",
      "Epoch: 2, Batch: 4200, Loss: 1.908, Accuracy: 63.48%\n",
      "Epoch: 2, Batch: 4300, Loss: 1.916, Accuracy: 63.51%\n",
      "Epoch: 2, Batch: 4400, Loss: 1.890, Accuracy: 63.56%\n",
      "Epoch: 2, Batch: 4500, Loss: 1.903, Accuracy: 63.61%\n",
      "Epoch: 2, Batch: 4600, Loss: 1.884, Accuracy: 63.68%\n",
      "Epoch: 2, Batch: 4700, Loss: 1.886, Accuracy: 63.72%\n",
      "Epoch: 2, Batch: 4800, Loss: 1.877, Accuracy: 63.88%\n",
      "Epoch: 2, Batch: 4900, Loss: 1.877, Accuracy: 63.96%\n",
      "Epoch: 2, Batch: 5000, Loss: 1.887, Accuracy: 64.05%\n",
      "Epoch: 2, Batch: 5100, Loss: 1.851, Accuracy: 64.16%\n",
      "Epoch: 2, Batch: 5200, Loss: 1.880, Accuracy: 64.19%\n",
      "Epoch: 2, Batch: 5300, Loss: 1.878, Accuracy: 64.25%\n",
      "Epoch: 2, Batch: 5400, Loss: 1.882, Accuracy: 64.28%\n",
      "Epoch: 2, Batch: 5500, Loss: 1.840, Accuracy: 64.41%\n",
      "Epoch: 2, Batch: 5600, Loss: 1.857, Accuracy: 64.47%\n",
      "Epoch: 2, Batch: 5700, Loss: 1.866, Accuracy: 64.53%\n",
      "Epoch: 2, Batch: 5800, Loss: 1.857, Accuracy: 64.61%\n",
      "Epoch: 2, Batch: 5900, Loss: 1.856, Accuracy: 64.69%\n",
      "Epoch: 2, Batch: 6000, Loss: 1.877, Accuracy: 64.72%\n",
      "Epoch: 2, Batch: 6100, Loss: 1.851, Accuracy: 64.77%\n",
      "Epoch: 2, Batch: 6200, Loss: 1.860, Accuracy: 64.75%\n",
      "Epoch: 2, Batch: 6300, Loss: 1.846, Accuracy: 64.80%\n",
      "Epoch: 2, Batch: 6400, Loss: 1.828, Accuracy: 64.88%\n",
      "Epoch: 2, Batch: 6500, Loss: 1.829, Accuracy: 64.93%\n",
      "Epoch: 2, Batch: 6600, Loss: 1.842, Accuracy: 64.98%\n",
      "Epoch: 2, Batch: 6700, Loss: 1.817, Accuracy: 65.04%\n",
      "Epoch: 2, Batch: 6800, Loss: 1.826, Accuracy: 65.10%\n",
      "Epoch: 2, Batch: 6900, Loss: 1.829, Accuracy: 65.17%\n",
      "Epoch: 2, Batch: 7000, Loss: 1.841, Accuracy: 65.21%\n",
      "Epoch: 2, Batch: 7100, Loss: 1.848, Accuracy: 65.21%\n",
      "Epoch: 2, Batch: 7200, Loss: 1.815, Accuracy: 65.25%\n",
      "Epoch: 2, Batch: 7300, Loss: 1.825, Accuracy: 65.32%\n",
      "Epoch: 2, Batch: 7400, Loss: 1.807, Accuracy: 65.41%\n",
      "Epoch: 2, Batch: 7500, Loss: 1.808, Accuracy: 65.48%\n",
      "Train Accuracy: 65.48%\n",
      "Test Accuracy: 72.02%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, NUM_EPOCH + 1):\n",
    "    optimizer, train_acc = train(model, epoch, preprocess, optimizer)\n",
    "    test_acc = test(model, preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa359382-2580-44ae-bcdb-3f18cf1f4c61",
   "metadata": {
    "id": "_t4SiXk33z0L"
   },
   "source": [
    "You should get at least 85\\% test accuracy even with only 2 epochs. We will be aiming for around 95\\% test accuracy and above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf28bb4e-7178-4340-9247-f69591e86dcf",
   "metadata": {
    "id": "RrwYAMMBEUPN"
   },
   "source": [
    "## A.4 - Multi-layer perceptron (MLP)\n",
    "\n",
    "Create a class MLP that creates an MLP of given width and depth, and use it to create a 3-layer MLP of width $100$. We will assume that `width > 0` and `depth > 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79cb6479-d475-4f0e-b0f7-fdd107d9e835",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8353cd9",
    "outputId": "c7f5eeaf-0638-45c3-842e-4372d21ff712"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, width, depth):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = [nn.Linear(input_dim, width), nn.ReLU()]\n",
    "        for _ in range(depth - 1):\n",
    "            layers.append(nn.Linear(width, width))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        layers.append(nn.Linear(width, output_dim))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca92a238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=49, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch: 1, Batch: 100, Loss: 2.307, Accuracy: 8.25%\n",
      "Epoch: 1, Batch: 200, Loss: 2.306, Accuracy: 8.81%\n",
      "Epoch: 1, Batch: 300, Loss: 2.305, Accuracy: 8.67%\n",
      "Epoch: 1, Batch: 400, Loss: 2.306, Accuracy: 9.06%\n",
      "Epoch: 1, Batch: 500, Loss: 2.304, Accuracy: 8.75%\n",
      "Epoch: 1, Batch: 600, Loss: 2.305, Accuracy: 8.44%\n",
      "Epoch: 1, Batch: 700, Loss: 2.299, Accuracy: 8.48%\n",
      "Epoch: 1, Batch: 800, Loss: 2.301, Accuracy: 8.61%\n",
      "Epoch: 1, Batch: 900, Loss: 2.299, Accuracy: 8.79%\n",
      "Epoch: 1, Batch: 1000, Loss: 2.302, Accuracy: 8.75%\n",
      "Epoch: 1, Batch: 1100, Loss: 2.300, Accuracy: 8.93%\n",
      "Epoch: 1, Batch: 1200, Loss: 2.299, Accuracy: 9.44%\n",
      "Epoch: 1, Batch: 1300, Loss: 2.296, Accuracy: 9.87%\n",
      "Epoch: 1, Batch: 1400, Loss: 2.296, Accuracy: 10.18%\n",
      "Epoch: 1, Batch: 1500, Loss: 2.298, Accuracy: 10.47%\n",
      "Epoch: 1, Batch: 1600, Loss: 2.300, Accuracy: 10.77%\n",
      "Epoch: 1, Batch: 1700, Loss: 2.297, Accuracy: 11.10%\n",
      "Epoch: 1, Batch: 1800, Loss: 2.295, Accuracy: 11.52%\n",
      "Epoch: 1, Batch: 1900, Loss: 2.298, Accuracy: 11.81%\n",
      "Epoch: 1, Batch: 2000, Loss: 2.294, Accuracy: 12.14%\n",
      "Epoch: 1, Batch: 2100, Loss: 2.294, Accuracy: 12.45%\n",
      "Epoch: 1, Batch: 2200, Loss: 2.294, Accuracy: 12.72%\n",
      "Epoch: 1, Batch: 2300, Loss: 2.293, Accuracy: 12.88%\n",
      "Epoch: 1, Batch: 2400, Loss: 2.294, Accuracy: 13.05%\n",
      "Epoch: 1, Batch: 2500, Loss: 2.293, Accuracy: 13.23%\n",
      "Epoch: 1, Batch: 2600, Loss: 2.290, Accuracy: 13.46%\n",
      "Epoch: 1, Batch: 2700, Loss: 2.292, Accuracy: 13.51%\n",
      "Epoch: 1, Batch: 2800, Loss: 2.290, Accuracy: 13.74%\n",
      "Epoch: 1, Batch: 2900, Loss: 2.289, Accuracy: 13.91%\n",
      "Epoch: 1, Batch: 3000, Loss: 2.290, Accuracy: 14.03%\n",
      "Epoch: 1, Batch: 3100, Loss: 2.288, Accuracy: 14.17%\n",
      "Epoch: 1, Batch: 3200, Loss: 2.289, Accuracy: 14.29%\n",
      "Epoch: 1, Batch: 3300, Loss: 2.287, Accuracy: 14.41%\n",
      "Epoch: 1, Batch: 3400, Loss: 2.288, Accuracy: 14.49%\n",
      "Epoch: 1, Batch: 3500, Loss: 2.290, Accuracy: 14.61%\n",
      "Epoch: 1, Batch: 3600, Loss: 2.288, Accuracy: 14.77%\n",
      "Epoch: 1, Batch: 3700, Loss: 2.287, Accuracy: 14.89%\n",
      "Epoch: 1, Batch: 3800, Loss: 2.284, Accuracy: 15.06%\n",
      "Epoch: 1, Batch: 3900, Loss: 2.288, Accuracy: 15.18%\n",
      "Epoch: 1, Batch: 4000, Loss: 2.284, Accuracy: 15.38%\n",
      "Epoch: 1, Batch: 4100, Loss: 2.283, Accuracy: 15.54%\n",
      "Epoch: 1, Batch: 4200, Loss: 2.283, Accuracy: 15.72%\n",
      "Epoch: 1, Batch: 4300, Loss: 2.283, Accuracy: 15.88%\n",
      "Epoch: 1, Batch: 4400, Loss: 2.282, Accuracy: 16.00%\n",
      "Epoch: 1, Batch: 4500, Loss: 2.281, Accuracy: 16.18%\n",
      "Epoch: 1, Batch: 4600, Loss: 2.281, Accuracy: 16.30%\n",
      "Epoch: 1, Batch: 4700, Loss: 2.280, Accuracy: 16.43%\n",
      "Epoch: 1, Batch: 4800, Loss: 2.281, Accuracy: 16.59%\n",
      "Epoch: 1, Batch: 4900, Loss: 2.282, Accuracy: 16.74%\n",
      "Epoch: 1, Batch: 5000, Loss: 2.283, Accuracy: 16.89%\n",
      "Epoch: 1, Batch: 5100, Loss: 2.282, Accuracy: 17.03%\n",
      "Epoch: 1, Batch: 5200, Loss: 2.279, Accuracy: 17.24%\n",
      "Epoch: 1, Batch: 5300, Loss: 2.278, Accuracy: 17.41%\n",
      "Epoch: 1, Batch: 5400, Loss: 2.276, Accuracy: 17.62%\n",
      "Epoch: 1, Batch: 5500, Loss: 2.280, Accuracy: 17.72%\n",
      "Epoch: 1, Batch: 5600, Loss: 2.278, Accuracy: 17.86%\n",
      "Epoch: 1, Batch: 5700, Loss: 2.278, Accuracy: 18.03%\n",
      "Epoch: 1, Batch: 5800, Loss: 2.275, Accuracy: 18.20%\n",
      "Epoch: 1, Batch: 5900, Loss: 2.274, Accuracy: 18.40%\n",
      "Epoch: 1, Batch: 6000, Loss: 2.273, Accuracy: 18.57%\n",
      "Epoch: 1, Batch: 6100, Loss: 2.275, Accuracy: 18.71%\n",
      "Epoch: 1, Batch: 6200, Loss: 2.275, Accuracy: 18.90%\n",
      "Epoch: 1, Batch: 6300, Loss: 2.274, Accuracy: 19.08%\n",
      "Epoch: 1, Batch: 6400, Loss: 2.272, Accuracy: 19.28%\n",
      "Epoch: 1, Batch: 6500, Loss: 2.273, Accuracy: 19.46%\n",
      "Epoch: 1, Batch: 6600, Loss: 2.273, Accuracy: 19.62%\n",
      "Epoch: 1, Batch: 6700, Loss: 2.271, Accuracy: 19.82%\n",
      "Epoch: 1, Batch: 6800, Loss: 2.272, Accuracy: 19.99%\n",
      "Epoch: 1, Batch: 6900, Loss: 2.271, Accuracy: 20.18%\n",
      "Epoch: 1, Batch: 7000, Loss: 2.269, Accuracy: 20.35%\n",
      "Epoch: 1, Batch: 7100, Loss: 2.264, Accuracy: 20.61%\n",
      "Epoch: 1, Batch: 7200, Loss: 2.269, Accuracy: 20.81%\n",
      "Epoch: 1, Batch: 7300, Loss: 2.265, Accuracy: 21.04%\n",
      "Epoch: 1, Batch: 7400, Loss: 2.265, Accuracy: 21.25%\n",
      "Epoch: 1, Batch: 7500, Loss: 2.266, Accuracy: 21.44%\n",
      "Train Accuracy: 21.44%\n",
      "Test Accuracy: 39.09%\n",
      "Epoch: 2, Batch: 100, Loss: 2.263, Accuracy: 40.00%\n",
      "Epoch: 2, Batch: 200, Loss: 2.264, Accuracy: 39.69%\n",
      "Epoch: 2, Batch: 300, Loss: 2.260, Accuracy: 40.33%\n",
      "Epoch: 2, Batch: 400, Loss: 2.263, Accuracy: 39.97%\n",
      "Epoch: 2, Batch: 500, Loss: 2.257, Accuracy: 40.27%\n",
      "Epoch: 2, Batch: 600, Loss: 2.262, Accuracy: 39.83%\n",
      "Epoch: 2, Batch: 700, Loss: 2.258, Accuracy: 39.68%\n",
      "Epoch: 2, Batch: 800, Loss: 2.257, Accuracy: 39.62%\n",
      "Epoch: 2, Batch: 900, Loss: 2.256, Accuracy: 39.68%\n",
      "Epoch: 2, Batch: 1000, Loss: 2.259, Accuracy: 39.21%\n",
      "Epoch: 2, Batch: 1100, Loss: 2.254, Accuracy: 39.31%\n",
      "Epoch: 2, Batch: 1200, Loss: 2.255, Accuracy: 39.29%\n",
      "Epoch: 2, Batch: 1300, Loss: 2.256, Accuracy: 39.12%\n",
      "Epoch: 2, Batch: 1400, Loss: 2.250, Accuracy: 39.20%\n",
      "Epoch: 2, Batch: 1500, Loss: 2.253, Accuracy: 38.97%\n",
      "Epoch: 2, Batch: 1600, Loss: 2.249, Accuracy: 39.11%\n",
      "Epoch: 2, Batch: 1700, Loss: 2.249, Accuracy: 39.17%\n",
      "Epoch: 2, Batch: 1800, Loss: 2.247, Accuracy: 39.29%\n",
      "Epoch: 2, Batch: 1900, Loss: 2.248, Accuracy: 39.26%\n",
      "Epoch: 2, Batch: 2000, Loss: 2.244, Accuracy: 39.42%\n",
      "Epoch: 2, Batch: 2100, Loss: 2.249, Accuracy: 39.30%\n",
      "Epoch: 2, Batch: 2200, Loss: 2.239, Accuracy: 39.48%\n",
      "Epoch: 2, Batch: 2300, Loss: 2.244, Accuracy: 39.47%\n",
      "Epoch: 2, Batch: 2400, Loss: 2.243, Accuracy: 39.55%\n",
      "Epoch: 2, Batch: 2500, Loss: 2.242, Accuracy: 39.50%\n",
      "Epoch: 2, Batch: 2600, Loss: 2.241, Accuracy: 39.59%\n",
      "Epoch: 2, Batch: 2700, Loss: 2.239, Accuracy: 39.63%\n",
      "Epoch: 2, Batch: 2800, Loss: 2.237, Accuracy: 39.75%\n",
      "Epoch: 2, Batch: 2900, Loss: 2.234, Accuracy: 39.82%\n",
      "Epoch: 2, Batch: 3000, Loss: 2.233, Accuracy: 40.00%\n",
      "Epoch: 2, Batch: 3100, Loss: 2.233, Accuracy: 40.06%\n",
      "Epoch: 2, Batch: 3200, Loss: 2.230, Accuracy: 40.17%\n",
      "Epoch: 2, Batch: 3300, Loss: 2.231, Accuracy: 40.26%\n",
      "Epoch: 2, Batch: 3400, Loss: 2.227, Accuracy: 40.40%\n",
      "Epoch: 2, Batch: 3500, Loss: 2.227, Accuracy: 40.44%\n",
      "Epoch: 2, Batch: 3600, Loss: 2.228, Accuracy: 40.47%\n",
      "Epoch: 2, Batch: 3700, Loss: 2.222, Accuracy: 40.53%\n",
      "Epoch: 2, Batch: 3800, Loss: 2.222, Accuracy: 40.59%\n",
      "Epoch: 2, Batch: 3900, Loss: 2.223, Accuracy: 40.65%\n",
      "Epoch: 2, Batch: 4000, Loss: 2.224, Accuracy: 40.66%\n",
      "Epoch: 2, Batch: 4100, Loss: 2.221, Accuracy: 40.75%\n",
      "Epoch: 2, Batch: 4200, Loss: 2.215, Accuracy: 40.85%\n",
      "Epoch: 2, Batch: 4300, Loss: 2.216, Accuracy: 40.94%\n",
      "Epoch: 2, Batch: 4400, Loss: 2.219, Accuracy: 40.90%\n",
      "Epoch: 2, Batch: 4500, Loss: 2.216, Accuracy: 40.94%\n",
      "Epoch: 2, Batch: 4600, Loss: 2.207, Accuracy: 41.05%\n",
      "Epoch: 2, Batch: 4700, Loss: 2.211, Accuracy: 41.04%\n",
      "Epoch: 2, Batch: 4800, Loss: 2.207, Accuracy: 41.10%\n",
      "Epoch: 2, Batch: 4900, Loss: 2.205, Accuracy: 41.16%\n",
      "Epoch: 2, Batch: 5000, Loss: 2.205, Accuracy: 41.20%\n",
      "Epoch: 2, Batch: 5100, Loss: 2.198, Accuracy: 41.32%\n",
      "Epoch: 2, Batch: 5200, Loss: 2.199, Accuracy: 41.34%\n",
      "Epoch: 2, Batch: 5300, Loss: 2.196, Accuracy: 41.41%\n",
      "Epoch: 2, Batch: 5400, Loss: 2.188, Accuracy: 41.49%\n",
      "Epoch: 2, Batch: 5500, Loss: 2.190, Accuracy: 41.56%\n",
      "Epoch: 2, Batch: 5600, Loss: 2.186, Accuracy: 41.64%\n",
      "Epoch: 2, Batch: 5700, Loss: 2.189, Accuracy: 41.66%\n",
      "Epoch: 2, Batch: 5800, Loss: 2.188, Accuracy: 41.70%\n",
      "Epoch: 2, Batch: 5900, Loss: 2.180, Accuracy: 41.73%\n",
      "Epoch: 2, Batch: 6000, Loss: 2.181, Accuracy: 41.76%\n",
      "Epoch: 2, Batch: 6100, Loss: 2.179, Accuracy: 41.80%\n",
      "Epoch: 2, Batch: 6200, Loss: 2.175, Accuracy: 41.89%\n",
      "Epoch: 2, Batch: 6300, Loss: 2.165, Accuracy: 42.02%\n",
      "Epoch: 2, Batch: 6400, Loss: 2.167, Accuracy: 42.09%\n",
      "Epoch: 2, Batch: 6500, Loss: 2.174, Accuracy: 42.12%\n",
      "Epoch: 2, Batch: 6600, Loss: 2.165, Accuracy: 42.22%\n",
      "Epoch: 2, Batch: 6700, Loss: 2.161, Accuracy: 42.29%\n",
      "Epoch: 2, Batch: 6800, Loss: 2.159, Accuracy: 42.39%\n",
      "Epoch: 2, Batch: 6900, Loss: 2.158, Accuracy: 42.46%\n",
      "Epoch: 2, Batch: 7000, Loss: 2.155, Accuracy: 42.51%\n",
      "Epoch: 2, Batch: 7100, Loss: 2.146, Accuracy: 42.58%\n",
      "Epoch: 2, Batch: 7200, Loss: 2.146, Accuracy: 42.64%\n",
      "Epoch: 2, Batch: 7300, Loss: 2.138, Accuracy: 42.72%\n",
      "Epoch: 2, Batch: 7400, Loss: 2.146, Accuracy: 42.74%\n",
      "Epoch: 2, Batch: 7500, Loss: 2.145, Accuracy: 42.78%\n",
      "Train Accuracy: 42.78%\n",
      "Test Accuracy: 46.36%\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, width, depth):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "    \n",
    "        layers = []\n",
    "        \n",
    "        layers.append(nn.Linear(input_dim, width))\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "        for i in range(depth - 2):\n",
    "            layers.append(nn.Linear(width, width))\n",
    "            layers.append(nn.ReLU())\n",
    "        \n",
    "        layers.append(nn.Linear(width, output_dim))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "model_mlp = MLP(input_dim=49, output_dim=10, width=100, depth=3).to(device)\n",
    "\n",
    "\n",
    "print(model_mlp)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_mlp = torch.optim.SGD(model_mlp.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCH + 1):\n",
    "    optimizer_mlp, train_acc = train(model_mlp, epoch, preprocess, optimizer_mlp)\n",
    "    test_acc = test(model_mlp, preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ca5a11-93e4-47ab-81f1-e4ee3cae45c9",
   "metadata": {
    "id": "v1czyC9R3z0R"
   },
   "source": [
    "# A.5 - Deep convolutional model\n",
    "\n",
    "Write a convolutional model, with learned features.\n",
    "Use two layers, one convolutional with 8 filters of size 3x3, then take a relu and max-pool with kernel size 2, and finally flatten and add a Linear layer. You can use the identity as pre-processing function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4933e318-5521-4bf8-b011-bdb95ed0d8b0",
   "metadata": {},
   "source": [
    "\n",
    "Here is a little animation to remind you of the sliding window principle of convolutions.\n",
    "\n",
    "![conv](https://github.com//vdumoulin/conv_arithmetic/raw/master/gif/no_padding_no_strides.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7808152a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 100, Loss: 1.551, Accuracy: 54.88%\n",
      "Epoch: 1, Batch: 200, Loss: 0.669, Accuracy: 68.94%\n",
      "Epoch: 1, Batch: 300, Loss: 0.455, Accuracy: 74.75%\n",
      "Epoch: 1, Batch: 400, Loss: 0.408, Accuracy: 78.09%\n",
      "Epoch: 1, Batch: 500, Loss: 0.469, Accuracy: 79.62%\n",
      "Epoch: 1, Batch: 600, Loss: 0.305, Accuracy: 81.44%\n",
      "Epoch: 1, Batch: 700, Loss: 0.323, Accuracy: 82.79%\n",
      "Epoch: 1, Batch: 800, Loss: 0.381, Accuracy: 83.62%\n",
      "Epoch: 1, Batch: 900, Loss: 0.307, Accuracy: 84.44%\n",
      "Epoch: 1, Batch: 1000, Loss: 0.294, Accuracy: 85.16%\n",
      "Epoch: 1, Batch: 1100, Loss: 0.256, Accuracy: 85.81%\n",
      "Epoch: 1, Batch: 1200, Loss: 0.295, Accuracy: 86.27%\n",
      "Epoch: 1, Batch: 1300, Loss: 0.236, Accuracy: 86.83%\n",
      "Epoch: 1, Batch: 1400, Loss: 0.238, Accuracy: 87.28%\n",
      "Epoch: 1, Batch: 1500, Loss: 0.234, Accuracy: 87.66%\n",
      "Epoch: 1, Batch: 1600, Loss: 0.250, Accuracy: 88.03%\n",
      "Epoch: 1, Batch: 1700, Loss: 0.259, Accuracy: 88.38%\n",
      "Epoch: 1, Batch: 1800, Loss: 0.201, Accuracy: 88.67%\n",
      "Epoch: 1, Batch: 1900, Loss: 0.199, Accuracy: 89.04%\n",
      "Epoch: 1, Batch: 2000, Loss: 0.204, Accuracy: 89.29%\n",
      "Epoch: 1, Batch: 2100, Loss: 0.220, Accuracy: 89.48%\n",
      "Epoch: 1, Batch: 2200, Loss: 0.183, Accuracy: 89.73%\n",
      "Epoch: 1, Batch: 2300, Loss: 0.151, Accuracy: 90.00%\n",
      "Epoch: 1, Batch: 2400, Loss: 0.158, Accuracy: 90.26%\n",
      "Epoch: 1, Batch: 2500, Loss: 0.197, Accuracy: 90.43%\n",
      "Epoch: 1, Batch: 2600, Loss: 0.129, Accuracy: 90.65%\n",
      "Epoch: 1, Batch: 2700, Loss: 0.159, Accuracy: 90.86%\n",
      "Epoch: 1, Batch: 2800, Loss: 0.155, Accuracy: 91.01%\n",
      "Epoch: 1, Batch: 2900, Loss: 0.145, Accuracy: 91.16%\n",
      "Epoch: 1, Batch: 3000, Loss: 0.180, Accuracy: 91.28%\n",
      "Epoch: 1, Batch: 3100, Loss: 0.175, Accuracy: 91.42%\n",
      "Epoch: 1, Batch: 3200, Loss: 0.155, Accuracy: 91.54%\n",
      "Epoch: 1, Batch: 3300, Loss: 0.211, Accuracy: 91.61%\n",
      "Epoch: 1, Batch: 3400, Loss: 0.140, Accuracy: 91.74%\n",
      "Epoch: 1, Batch: 3500, Loss: 0.113, Accuracy: 91.87%\n",
      "Epoch: 1, Batch: 3600, Loss: 0.136, Accuracy: 91.99%\n",
      "Epoch: 1, Batch: 3700, Loss: 0.135, Accuracy: 92.08%\n",
      "Epoch: 1, Batch: 3800, Loss: 0.099, Accuracy: 92.21%\n",
      "Epoch: 1, Batch: 3900, Loss: 0.109, Accuracy: 92.34%\n",
      "Epoch: 1, Batch: 4000, Loss: 0.111, Accuracy: 92.45%\n",
      "Epoch: 1, Batch: 4100, Loss: 0.165, Accuracy: 92.51%\n",
      "Epoch: 1, Batch: 4200, Loss: 0.136, Accuracy: 92.60%\n",
      "Epoch: 1, Batch: 4300, Loss: 0.113, Accuracy: 92.66%\n",
      "Epoch: 1, Batch: 4400, Loss: 0.131, Accuracy: 92.75%\n",
      "Epoch: 1, Batch: 4500, Loss: 0.112, Accuracy: 92.84%\n",
      "Epoch: 1, Batch: 4600, Loss: 0.123, Accuracy: 92.91%\n",
      "Epoch: 1, Batch: 4700, Loss: 0.120, Accuracy: 92.99%\n",
      "Epoch: 1, Batch: 4800, Loss: 0.122, Accuracy: 93.07%\n",
      "Epoch: 1, Batch: 4900, Loss: 0.119, Accuracy: 93.15%\n",
      "Epoch: 1, Batch: 5000, Loss: 0.113, Accuracy: 93.22%\n",
      "Epoch: 1, Batch: 5100, Loss: 0.120, Accuracy: 93.27%\n",
      "Epoch: 1, Batch: 5200, Loss: 0.101, Accuracy: 93.34%\n",
      "Epoch: 1, Batch: 5300, Loss: 0.151, Accuracy: 93.39%\n",
      "Epoch: 1, Batch: 5400, Loss: 0.101, Accuracy: 93.45%\n",
      "Epoch: 1, Batch: 5500, Loss: 0.135, Accuracy: 93.50%\n",
      "Epoch: 1, Batch: 5600, Loss: 0.093, Accuracy: 93.58%\n",
      "Epoch: 1, Batch: 5700, Loss: 0.125, Accuracy: 93.62%\n",
      "Epoch: 1, Batch: 5800, Loss: 0.140, Accuracy: 93.65%\n",
      "Epoch: 1, Batch: 5900, Loss: 0.102, Accuracy: 93.71%\n",
      "Epoch: 1, Batch: 6000, Loss: 0.112, Accuracy: 93.75%\n",
      "Epoch: 1, Batch: 6100, Loss: 0.106, Accuracy: 93.80%\n",
      "Epoch: 1, Batch: 6200, Loss: 0.118, Accuracy: 93.84%\n",
      "Epoch: 1, Batch: 6300, Loss: 0.102, Accuracy: 93.89%\n",
      "Epoch: 1, Batch: 6400, Loss: 0.127, Accuracy: 93.94%\n",
      "Epoch: 1, Batch: 6500, Loss: 0.105, Accuracy: 93.99%\n",
      "Epoch: 1, Batch: 6600, Loss: 0.103, Accuracy: 94.02%\n",
      "Epoch: 1, Batch: 6700, Loss: 0.097, Accuracy: 94.07%\n",
      "Epoch: 1, Batch: 6800, Loss: 0.084, Accuracy: 94.12%\n",
      "Epoch: 1, Batch: 6900, Loss: 0.097, Accuracy: 94.17%\n",
      "Epoch: 1, Batch: 7000, Loss: 0.098, Accuracy: 94.21%\n",
      "Epoch: 1, Batch: 7100, Loss: 0.092, Accuracy: 94.25%\n",
      "Epoch: 1, Batch: 7200, Loss: 0.103, Accuracy: 94.28%\n",
      "Epoch: 1, Batch: 7300, Loss: 0.102, Accuracy: 94.32%\n",
      "Epoch: 1, Batch: 7400, Loss: 0.077, Accuracy: 94.36%\n",
      "Epoch: 1, Batch: 7500, Loss: 0.075, Accuracy: 94.40%\n",
      "Train Accuracy: 94.40%\n",
      "Test Accuracy: 97.31%\n",
      "Epoch: 2, Batch: 100, Loss: 0.074, Accuracy: 97.38%\n",
      "Epoch: 2, Batch: 200, Loss: 0.109, Accuracy: 97.12%\n",
      "Epoch: 2, Batch: 300, Loss: 0.082, Accuracy: 97.25%\n",
      "Epoch: 2, Batch: 400, Loss: 0.108, Accuracy: 97.12%\n",
      "Epoch: 2, Batch: 500, Loss: 0.087, Accuracy: 97.10%\n",
      "Epoch: 2, Batch: 600, Loss: 0.082, Accuracy: 97.17%\n",
      "Epoch: 2, Batch: 700, Loss: 0.063, Accuracy: 97.30%\n",
      "Epoch: 2, Batch: 800, Loss: 0.082, Accuracy: 97.36%\n",
      "Epoch: 2, Batch: 900, Loss: 0.067, Accuracy: 97.44%\n",
      "Epoch: 2, Batch: 1000, Loss: 0.125, Accuracy: 97.35%\n",
      "Epoch: 2, Batch: 1100, Loss: 0.058, Accuracy: 97.41%\n",
      "Epoch: 2, Batch: 1200, Loss: 0.066, Accuracy: 97.45%\n",
      "Epoch: 2, Batch: 1300, Loss: 0.109, Accuracy: 97.43%\n",
      "Epoch: 2, Batch: 1400, Loss: 0.086, Accuracy: 97.41%\n",
      "Epoch: 2, Batch: 1500, Loss: 0.077, Accuracy: 97.47%\n",
      "Epoch: 2, Batch: 1600, Loss: 0.071, Accuracy: 97.48%\n",
      "Epoch: 2, Batch: 1700, Loss: 0.086, Accuracy: 97.49%\n",
      "Epoch: 2, Batch: 1800, Loss: 0.085, Accuracy: 97.49%\n",
      "Epoch: 2, Batch: 1900, Loss: 0.090, Accuracy: 97.47%\n",
      "Epoch: 2, Batch: 2000, Loss: 0.085, Accuracy: 97.47%\n",
      "Epoch: 2, Batch: 2100, Loss: 0.097, Accuracy: 97.48%\n",
      "Epoch: 2, Batch: 2200, Loss: 0.086, Accuracy: 97.49%\n",
      "Epoch: 2, Batch: 2300, Loss: 0.087, Accuracy: 97.49%\n",
      "Epoch: 2, Batch: 2400, Loss: 0.109, Accuracy: 97.48%\n",
      "Epoch: 2, Batch: 2500, Loss: 0.098, Accuracy: 97.48%\n",
      "Epoch: 2, Batch: 2600, Loss: 0.085, Accuracy: 97.48%\n",
      "Epoch: 2, Batch: 2700, Loss: 0.074, Accuracy: 97.47%\n",
      "Epoch: 2, Batch: 2800, Loss: 0.077, Accuracy: 97.47%\n",
      "Epoch: 2, Batch: 2900, Loss: 0.069, Accuracy: 97.49%\n",
      "Epoch: 2, Batch: 3000, Loss: 0.089, Accuracy: 97.47%\n",
      "Epoch: 2, Batch: 3100, Loss: 0.056, Accuracy: 97.51%\n",
      "Epoch: 2, Batch: 3200, Loss: 0.097, Accuracy: 97.49%\n",
      "Epoch: 2, Batch: 3300, Loss: 0.084, Accuracy: 97.49%\n",
      "Epoch: 2, Batch: 3400, Loss: 0.082, Accuracy: 97.48%\n",
      "Epoch: 2, Batch: 3500, Loss: 0.094, Accuracy: 97.47%\n",
      "Epoch: 2, Batch: 3600, Loss: 0.076, Accuracy: 97.47%\n",
      "Epoch: 2, Batch: 3700, Loss: 0.087, Accuracy: 97.46%\n",
      "Epoch: 2, Batch: 3800, Loss: 0.073, Accuracy: 97.46%\n",
      "Epoch: 2, Batch: 3900, Loss: 0.097, Accuracy: 97.45%\n",
      "Epoch: 2, Batch: 4000, Loss: 0.105, Accuracy: 97.43%\n",
      "Epoch: 2, Batch: 4100, Loss: 0.098, Accuracy: 97.41%\n",
      "Epoch: 2, Batch: 4200, Loss: 0.085, Accuracy: 97.39%\n",
      "Epoch: 2, Batch: 4300, Loss: 0.091, Accuracy: 97.40%\n",
      "Epoch: 2, Batch: 4400, Loss: 0.057, Accuracy: 97.41%\n",
      "Epoch: 2, Batch: 4500, Loss: 0.055, Accuracy: 97.44%\n",
      "Epoch: 2, Batch: 4600, Loss: 0.084, Accuracy: 97.45%\n",
      "Epoch: 2, Batch: 4700, Loss: 0.087, Accuracy: 97.45%\n",
      "Epoch: 2, Batch: 4800, Loss: 0.093, Accuracy: 97.43%\n",
      "Epoch: 2, Batch: 4900, Loss: 0.094, Accuracy: 97.43%\n",
      "Epoch: 2, Batch: 5000, Loss: 0.071, Accuracy: 97.44%\n",
      "Epoch: 2, Batch: 5100, Loss: 0.069, Accuracy: 97.44%\n",
      "Epoch: 2, Batch: 5200, Loss: 0.060, Accuracy: 97.45%\n",
      "Epoch: 2, Batch: 5300, Loss: 0.097, Accuracy: 97.44%\n",
      "Epoch: 2, Batch: 5400, Loss: 0.074, Accuracy: 97.44%\n",
      "Epoch: 2, Batch: 5500, Loss: 0.065, Accuracy: 97.45%\n",
      "Epoch: 2, Batch: 5600, Loss: 0.104, Accuracy: 97.46%\n",
      "Epoch: 2, Batch: 5700, Loss: 0.109, Accuracy: 97.45%\n",
      "Epoch: 2, Batch: 5800, Loss: 0.079, Accuracy: 97.45%\n",
      "Epoch: 2, Batch: 5900, Loss: 0.051, Accuracy: 97.47%\n",
      "Epoch: 2, Batch: 6000, Loss: 0.059, Accuracy: 97.49%\n",
      "Epoch: 2, Batch: 6100, Loss: 0.074, Accuracy: 97.49%\n",
      "Epoch: 2, Batch: 6200, Loss: 0.063, Accuracy: 97.50%\n",
      "Epoch: 2, Batch: 6300, Loss: 0.041, Accuracy: 97.52%\n",
      "Epoch: 2, Batch: 6400, Loss: 0.070, Accuracy: 97.52%\n",
      "Epoch: 2, Batch: 6500, Loss: 0.073, Accuracy: 97.52%\n",
      "Epoch: 2, Batch: 6600, Loss: 0.064, Accuracy: 97.53%\n",
      "Epoch: 2, Batch: 6700, Loss: 0.052, Accuracy: 97.54%\n",
      "Epoch: 2, Batch: 6800, Loss: 0.109, Accuracy: 97.53%\n",
      "Epoch: 2, Batch: 6900, Loss: 0.085, Accuracy: 97.53%\n",
      "Epoch: 2, Batch: 7000, Loss: 0.057, Accuracy: 97.54%\n",
      "Epoch: 2, Batch: 7100, Loss: 0.088, Accuracy: 97.53%\n",
      "Epoch: 2, Batch: 7200, Loss: 0.072, Accuracy: 97.53%\n",
      "Epoch: 2, Batch: 7300, Loss: 0.083, Accuracy: 97.53%\n",
      "Epoch: 2, Batch: 7400, Loss: 0.122, Accuracy: 97.52%\n",
      "Epoch: 2, Batch: 7500, Loss: 0.086, Accuracy: 97.52%\n",
      "Train Accuracy: 97.52%\n",
      "Test Accuracy: 97.63%\n",
      "Epoch: 3, Batch: 100, Loss: 0.057, Accuracy: 98.62%\n",
      "Epoch: 3, Batch: 200, Loss: 0.042, Accuracy: 98.69%\n",
      "Epoch: 3, Batch: 300, Loss: 0.054, Accuracy: 98.50%\n",
      "Epoch: 3, Batch: 400, Loss: 0.063, Accuracy: 98.44%\n",
      "Epoch: 3, Batch: 500, Loss: 0.058, Accuracy: 98.42%\n",
      "Epoch: 3, Batch: 600, Loss: 0.061, Accuracy: 98.33%\n",
      "Epoch: 3, Batch: 700, Loss: 0.066, Accuracy: 98.36%\n",
      "Epoch: 3, Batch: 800, Loss: 0.080, Accuracy: 98.23%\n",
      "Epoch: 3, Batch: 900, Loss: 0.070, Accuracy: 98.25%\n",
      "Epoch: 3, Batch: 1000, Loss: 0.068, Accuracy: 98.20%\n",
      "Epoch: 3, Batch: 1100, Loss: 0.061, Accuracy: 98.24%\n",
      "Epoch: 3, Batch: 1200, Loss: 0.060, Accuracy: 98.25%\n",
      "Epoch: 3, Batch: 1300, Loss: 0.046, Accuracy: 98.27%\n",
      "Epoch: 3, Batch: 1400, Loss: 0.066, Accuracy: 98.25%\n",
      "Epoch: 3, Batch: 1500, Loss: 0.084, Accuracy: 98.21%\n",
      "Epoch: 3, Batch: 1600, Loss: 0.091, Accuracy: 98.17%\n",
      "Epoch: 3, Batch: 1700, Loss: 0.054, Accuracy: 98.15%\n",
      "Epoch: 3, Batch: 1800, Loss: 0.077, Accuracy: 98.13%\n",
      "Epoch: 3, Batch: 1900, Loss: 0.075, Accuracy: 98.13%\n",
      "Epoch: 3, Batch: 2000, Loss: 0.029, Accuracy: 98.20%\n",
      "Epoch: 3, Batch: 2100, Loss: 0.089, Accuracy: 98.15%\n",
      "Epoch: 3, Batch: 2200, Loss: 0.063, Accuracy: 98.17%\n",
      "Epoch: 3, Batch: 2300, Loss: 0.070, Accuracy: 98.15%\n",
      "Epoch: 3, Batch: 2400, Loss: 0.062, Accuracy: 98.12%\n",
      "Epoch: 3, Batch: 2500, Loss: 0.082, Accuracy: 98.08%\n",
      "Epoch: 3, Batch: 2600, Loss: 0.054, Accuracy: 98.10%\n",
      "Epoch: 3, Batch: 2700, Loss: 0.075, Accuracy: 98.09%\n",
      "Epoch: 3, Batch: 2800, Loss: 0.079, Accuracy: 98.10%\n",
      "Epoch: 3, Batch: 2900, Loss: 0.056, Accuracy: 98.11%\n",
      "Epoch: 3, Batch: 3000, Loss: 0.063, Accuracy: 98.10%\n",
      "Epoch: 3, Batch: 3100, Loss: 0.056, Accuracy: 98.09%\n",
      "Epoch: 3, Batch: 3200, Loss: 0.071, Accuracy: 98.07%\n",
      "Epoch: 3, Batch: 3300, Loss: 0.063, Accuracy: 98.07%\n",
      "Epoch: 3, Batch: 3400, Loss: 0.080, Accuracy: 98.06%\n",
      "Epoch: 3, Batch: 3500, Loss: 0.061, Accuracy: 98.06%\n",
      "Epoch: 3, Batch: 3600, Loss: 0.070, Accuracy: 98.06%\n",
      "Epoch: 3, Batch: 3700, Loss: 0.101, Accuracy: 98.05%\n",
      "Epoch: 3, Batch: 3800, Loss: 0.029, Accuracy: 98.08%\n",
      "Epoch: 3, Batch: 3900, Loss: 0.056, Accuracy: 98.07%\n",
      "Epoch: 3, Batch: 4000, Loss: 0.070, Accuracy: 98.07%\n",
      "Epoch: 3, Batch: 4100, Loss: 0.095, Accuracy: 98.04%\n",
      "Epoch: 3, Batch: 4200, Loss: 0.070, Accuracy: 98.04%\n",
      "Epoch: 3, Batch: 4300, Loss: 0.058, Accuracy: 98.05%\n",
      "Epoch: 3, Batch: 4400, Loss: 0.085, Accuracy: 98.05%\n",
      "Epoch: 3, Batch: 4500, Loss: 0.056, Accuracy: 98.06%\n",
      "Epoch: 3, Batch: 4600, Loss: 0.084, Accuracy: 98.04%\n",
      "Epoch: 3, Batch: 4700, Loss: 0.051, Accuracy: 98.06%\n",
      "Epoch: 3, Batch: 4800, Loss: 0.063, Accuracy: 98.07%\n",
      "Epoch: 3, Batch: 4900, Loss: 0.056, Accuracy: 98.06%\n",
      "Epoch: 3, Batch: 5000, Loss: 0.076, Accuracy: 98.05%\n",
      "Epoch: 3, Batch: 5100, Loss: 0.063, Accuracy: 98.05%\n",
      "Epoch: 3, Batch: 5200, Loss: 0.053, Accuracy: 98.06%\n",
      "Epoch: 3, Batch: 5300, Loss: 0.074, Accuracy: 98.05%\n",
      "Epoch: 3, Batch: 5400, Loss: 0.056, Accuracy: 98.06%\n",
      "Epoch: 3, Batch: 5500, Loss: 0.066, Accuracy: 98.06%\n",
      "Epoch: 3, Batch: 5600, Loss: 0.065, Accuracy: 98.07%\n",
      "Epoch: 3, Batch: 5700, Loss: 0.062, Accuracy: 98.06%\n",
      "Epoch: 3, Batch: 5800, Loss: 0.049, Accuracy: 98.07%\n",
      "Epoch: 3, Batch: 5900, Loss: 0.043, Accuracy: 98.08%\n",
      "Epoch: 3, Batch: 6000, Loss: 0.056, Accuracy: 98.09%\n",
      "Epoch: 3, Batch: 6100, Loss: 0.073, Accuracy: 98.08%\n",
      "Epoch: 3, Batch: 6200, Loss: 0.086, Accuracy: 98.07%\n",
      "Epoch: 3, Batch: 6300, Loss: 0.044, Accuracy: 98.09%\n",
      "Epoch: 3, Batch: 6400, Loss: 0.075, Accuracy: 98.08%\n",
      "Epoch: 3, Batch: 6500, Loss: 0.059, Accuracy: 98.08%\n",
      "Epoch: 3, Batch: 6600, Loss: 0.068, Accuracy: 98.08%\n",
      "Epoch: 3, Batch: 6700, Loss: 0.036, Accuracy: 98.09%\n",
      "Epoch: 3, Batch: 6800, Loss: 0.058, Accuracy: 98.09%\n",
      "Epoch: 3, Batch: 6900, Loss: 0.050, Accuracy: 98.09%\n",
      "Epoch: 3, Batch: 7000, Loss: 0.047, Accuracy: 98.09%\n",
      "Epoch: 3, Batch: 7100, Loss: 0.084, Accuracy: 98.09%\n",
      "Epoch: 3, Batch: 7200, Loss: 0.081, Accuracy: 98.09%\n",
      "Epoch: 3, Batch: 7300, Loss: 0.052, Accuracy: 98.09%\n",
      "Epoch: 3, Batch: 7400, Loss: 0.072, Accuracy: 98.08%\n",
      "Epoch: 3, Batch: 7500, Loss: 0.051, Accuracy: 98.09%\n",
      "Train Accuracy: 98.09%\n",
      "Test Accuracy: 97.98%\n"
     ]
    }
   ],
   "source": [
    "class ConvModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvModel, self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.flat_features = 1352\n",
    "        self.fc = torch.nn.Linear(self.flat_features, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x) \n",
    "        x = self.relu(x)  \n",
    "        x = self.pool(x)  \n",
    "        x = x.view(-1, self.flat_features)  \n",
    "        x = self.fc(x)  \n",
    "        return x\n",
    "\n",
    "\n",
    "model_conv = ConvModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_conv = torch.optim.Adam(model_conv.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "def identity_preprocess(x):\n",
    "    return x\n",
    "\n",
    "for epoch in range(1, NUM_EPOCH + 2):\n",
    "    optimizer_conv, train_acc = train(model_conv, epoch, identity_preprocess, optimizer_conv)\n",
    "    test_acc = test(model_conv, identity_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0313eed-03ad-461d-9ddb-bb690c631149",
   "metadata": {
    "id": "pbQ1LUqf3z0R"
   },
   "source": [
    "You should be able to get around 97\\% to 98\\% accuracy with this model. Try increasing the NUM_EPOCH constant and watch what happens to test accuracy and train accuracy as training progresses further.\n",
    "\n",
    "Write a deeper convolutional model, with one convolutional layer as previously, but three linear layers with relu activations after that.\n",
    "Use `h = 100` hidden neurons. How does the test accuracy compare with the previous two-layer network ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46285c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 100, Loss: 2.030, Accuracy: 29.38%\n",
      "Epoch: 1, Batch: 200, Loss: 0.895, Accuracy: 49.81%\n",
      "Epoch: 1, Batch: 300, Loss: 0.696, Accuracy: 58.71%\n",
      "Epoch: 1, Batch: 400, Loss: 0.538, Accuracy: 64.97%\n",
      "Epoch: 1, Batch: 500, Loss: 0.518, Accuracy: 68.75%\n",
      "Epoch: 1, Batch: 600, Loss: 0.431, Accuracy: 71.83%\n",
      "Epoch: 1, Batch: 700, Loss: 0.401, Accuracy: 74.00%\n",
      "Epoch: 1, Batch: 800, Loss: 0.329, Accuracy: 76.03%\n",
      "Epoch: 1, Batch: 900, Loss: 0.434, Accuracy: 77.15%\n",
      "Epoch: 1, Batch: 1000, Loss: 0.350, Accuracy: 78.30%\n",
      "Epoch: 1, Batch: 1100, Loss: 0.350, Accuracy: 79.33%\n",
      "Epoch: 1, Batch: 1200, Loss: 0.366, Accuracy: 80.08%\n",
      "Epoch: 1, Batch: 1300, Loss: 0.311, Accuracy: 80.88%\n",
      "Epoch: 1, Batch: 1400, Loss: 0.308, Accuracy: 81.55%\n",
      "Epoch: 1, Batch: 1500, Loss: 0.335, Accuracy: 82.10%\n",
      "Epoch: 1, Batch: 1600, Loss: 0.291, Accuracy: 82.72%\n",
      "Epoch: 1, Batch: 1700, Loss: 0.264, Accuracy: 83.24%\n",
      "Epoch: 1, Batch: 1800, Loss: 0.253, Accuracy: 83.72%\n",
      "Epoch: 1, Batch: 1900, Loss: 0.277, Accuracy: 84.16%\n",
      "Epoch: 1, Batch: 2000, Loss: 0.236, Accuracy: 84.58%\n",
      "Epoch: 1, Batch: 2100, Loss: 0.232, Accuracy: 84.94%\n",
      "Epoch: 1, Batch: 2200, Loss: 0.277, Accuracy: 85.22%\n",
      "Epoch: 1, Batch: 2300, Loss: 0.257, Accuracy: 85.54%\n",
      "Epoch: 1, Batch: 2400, Loss: 0.216, Accuracy: 85.84%\n",
      "Epoch: 1, Batch: 2500, Loss: 0.250, Accuracy: 86.15%\n",
      "Epoch: 1, Batch: 2600, Loss: 0.206, Accuracy: 86.45%\n",
      "Epoch: 1, Batch: 2700, Loss: 0.192, Accuracy: 86.74%\n",
      "Epoch: 1, Batch: 2800, Loss: 0.204, Accuracy: 86.96%\n",
      "Epoch: 1, Batch: 2900, Loss: 0.205, Accuracy: 87.20%\n",
      "Epoch: 1, Batch: 3000, Loss: 0.200, Accuracy: 87.43%\n",
      "Epoch: 1, Batch: 3100, Loss: 0.159, Accuracy: 87.67%\n",
      "Epoch: 1, Batch: 3200, Loss: 0.206, Accuracy: 87.86%\n",
      "Epoch: 1, Batch: 3300, Loss: 0.182, Accuracy: 88.07%\n",
      "Epoch: 1, Batch: 3400, Loss: 0.205, Accuracy: 88.25%\n",
      "Epoch: 1, Batch: 3500, Loss: 0.203, Accuracy: 88.41%\n",
      "Epoch: 1, Batch: 3600, Loss: 0.193, Accuracy: 88.58%\n",
      "Epoch: 1, Batch: 3700, Loss: 0.153, Accuracy: 88.77%\n",
      "Epoch: 1, Batch: 3800, Loss: 0.183, Accuracy: 88.93%\n",
      "Epoch: 1, Batch: 3900, Loss: 0.184, Accuracy: 89.06%\n",
      "Epoch: 1, Batch: 4000, Loss: 0.139, Accuracy: 89.22%\n",
      "Epoch: 1, Batch: 4100, Loss: 0.148, Accuracy: 89.37%\n",
      "Epoch: 1, Batch: 4200, Loss: 0.168, Accuracy: 89.50%\n",
      "Epoch: 1, Batch: 4300, Loss: 0.117, Accuracy: 89.67%\n",
      "Epoch: 1, Batch: 4400, Loss: 0.197, Accuracy: 89.79%\n",
      "Epoch: 1, Batch: 4500, Loss: 0.155, Accuracy: 89.92%\n",
      "Epoch: 1, Batch: 4600, Loss: 0.173, Accuracy: 90.02%\n",
      "Epoch: 1, Batch: 4700, Loss: 0.122, Accuracy: 90.16%\n",
      "Epoch: 1, Batch: 4800, Loss: 0.169, Accuracy: 90.27%\n",
      "Epoch: 1, Batch: 4900, Loss: 0.114, Accuracy: 90.39%\n",
      "Epoch: 1, Batch: 5000, Loss: 0.129, Accuracy: 90.50%\n",
      "Epoch: 1, Batch: 5100, Loss: 0.183, Accuracy: 90.58%\n",
      "Epoch: 1, Batch: 5200, Loss: 0.155, Accuracy: 90.69%\n",
      "Epoch: 1, Batch: 5300, Loss: 0.131, Accuracy: 90.78%\n",
      "Epoch: 1, Batch: 5400, Loss: 0.144, Accuracy: 90.87%\n",
      "Epoch: 1, Batch: 5500, Loss: 0.193, Accuracy: 90.95%\n",
      "Epoch: 1, Batch: 5600, Loss: 0.107, Accuracy: 91.05%\n",
      "Epoch: 1, Batch: 5700, Loss: 0.162, Accuracy: 91.14%\n",
      "Epoch: 1, Batch: 5800, Loss: 0.163, Accuracy: 91.19%\n",
      "Epoch: 1, Batch: 5900, Loss: 0.149, Accuracy: 91.26%\n",
      "Epoch: 1, Batch: 6000, Loss: 0.124, Accuracy: 91.34%\n",
      "Epoch: 1, Batch: 6100, Loss: 0.104, Accuracy: 91.42%\n",
      "Epoch: 1, Batch: 6200, Loss: 0.150, Accuracy: 91.48%\n",
      "Epoch: 1, Batch: 6300, Loss: 0.104, Accuracy: 91.56%\n",
      "Epoch: 1, Batch: 6400, Loss: 0.100, Accuracy: 91.64%\n",
      "Epoch: 1, Batch: 6500, Loss: 0.125, Accuracy: 91.72%\n",
      "Epoch: 1, Batch: 6600, Loss: 0.124, Accuracy: 91.79%\n",
      "Epoch: 1, Batch: 6700, Loss: 0.115, Accuracy: 91.86%\n",
      "Epoch: 1, Batch: 6800, Loss: 0.170, Accuracy: 91.90%\n",
      "Epoch: 1, Batch: 6900, Loss: 0.113, Accuracy: 91.96%\n",
      "Epoch: 1, Batch: 7000, Loss: 0.116, Accuracy: 92.02%\n",
      "Epoch: 1, Batch: 7100, Loss: 0.130, Accuracy: 92.07%\n",
      "Epoch: 1, Batch: 7200, Loss: 0.126, Accuracy: 92.13%\n",
      "Epoch: 1, Batch: 7300, Loss: 0.121, Accuracy: 92.18%\n",
      "Epoch: 1, Batch: 7400, Loss: 0.101, Accuracy: 92.24%\n",
      "Epoch: 1, Batch: 7500, Loss: 0.108, Accuracy: 92.29%\n",
      "Train Accuracy: 92.29%\n",
      "Test Accuracy: 96.93%\n",
      "Epoch: 2, Batch: 100, Loss: 0.108, Accuracy: 96.50%\n",
      "Epoch: 2, Batch: 200, Loss: 0.124, Accuracy: 96.44%\n",
      "Epoch: 2, Batch: 300, Loss: 0.096, Accuracy: 96.33%\n",
      "Epoch: 2, Batch: 400, Loss: 0.102, Accuracy: 96.31%\n",
      "Epoch: 2, Batch: 500, Loss: 0.077, Accuracy: 96.55%\n",
      "Epoch: 2, Batch: 600, Loss: 0.085, Accuracy: 96.75%\n",
      "Epoch: 2, Batch: 700, Loss: 0.109, Accuracy: 96.68%\n",
      "Epoch: 2, Batch: 800, Loss: 0.125, Accuracy: 96.56%\n",
      "Epoch: 2, Batch: 900, Loss: 0.105, Accuracy: 96.67%\n",
      "Epoch: 2, Batch: 1000, Loss: 0.068, Accuracy: 96.76%\n",
      "Epoch: 2, Batch: 1100, Loss: 0.110, Accuracy: 96.77%\n",
      "Epoch: 2, Batch: 1200, Loss: 0.075, Accuracy: 96.88%\n",
      "Epoch: 2, Batch: 1300, Loss: 0.118, Accuracy: 96.82%\n",
      "Epoch: 2, Batch: 1400, Loss: 0.090, Accuracy: 96.80%\n",
      "Epoch: 2, Batch: 1500, Loss: 0.060, Accuracy: 96.90%\n",
      "Epoch: 2, Batch: 1600, Loss: 0.088, Accuracy: 96.91%\n",
      "Epoch: 2, Batch: 1700, Loss: 0.094, Accuracy: 96.93%\n",
      "Epoch: 2, Batch: 1800, Loss: 0.088, Accuracy: 96.94%\n",
      "Epoch: 2, Batch: 1900, Loss: 0.077, Accuracy: 96.98%\n",
      "Epoch: 2, Batch: 2000, Loss: 0.106, Accuracy: 96.98%\n",
      "Epoch: 2, Batch: 2100, Loss: 0.116, Accuracy: 96.94%\n",
      "Epoch: 2, Batch: 2200, Loss: 0.086, Accuracy: 96.95%\n",
      "Epoch: 2, Batch: 2300, Loss: 0.079, Accuracy: 96.96%\n",
      "Epoch: 2, Batch: 2400, Loss: 0.063, Accuracy: 96.99%\n",
      "Epoch: 2, Batch: 2500, Loss: 0.098, Accuracy: 96.98%\n",
      "Epoch: 2, Batch: 2600, Loss: 0.095, Accuracy: 96.98%\n",
      "Epoch: 2, Batch: 2700, Loss: 0.111, Accuracy: 97.00%\n",
      "Epoch: 2, Batch: 2800, Loss: 0.079, Accuracy: 97.02%\n",
      "Epoch: 2, Batch: 2900, Loss: 0.094, Accuracy: 97.03%\n",
      "Epoch: 2, Batch: 3000, Loss: 0.074, Accuracy: 97.05%\n",
      "Epoch: 2, Batch: 3100, Loss: 0.121, Accuracy: 97.03%\n",
      "Epoch: 2, Batch: 3200, Loss: 0.111, Accuracy: 97.00%\n",
      "Epoch: 2, Batch: 3300, Loss: 0.093, Accuracy: 96.99%\n",
      "Epoch: 2, Batch: 3400, Loss: 0.091, Accuracy: 97.00%\n",
      "Epoch: 2, Batch: 3500, Loss: 0.071, Accuracy: 97.02%\n",
      "Epoch: 2, Batch: 3600, Loss: 0.064, Accuracy: 97.04%\n",
      "Epoch: 2, Batch: 3700, Loss: 0.068, Accuracy: 97.06%\n",
      "Epoch: 2, Batch: 3800, Loss: 0.140, Accuracy: 97.03%\n",
      "Epoch: 2, Batch: 3900, Loss: 0.073, Accuracy: 97.03%\n",
      "Epoch: 2, Batch: 4000, Loss: 0.086, Accuracy: 97.02%\n",
      "Epoch: 2, Batch: 4100, Loss: 0.072, Accuracy: 97.03%\n",
      "Epoch: 2, Batch: 4200, Loss: 0.077, Accuracy: 97.05%\n",
      "Epoch: 2, Batch: 4300, Loss: 0.060, Accuracy: 97.06%\n",
      "Epoch: 2, Batch: 4400, Loss: 0.093, Accuracy: 97.06%\n",
      "Epoch: 2, Batch: 4500, Loss: 0.089, Accuracy: 97.06%\n",
      "Epoch: 2, Batch: 4600, Loss: 0.102, Accuracy: 97.06%\n",
      "Epoch: 2, Batch: 4700, Loss: 0.087, Accuracy: 97.06%\n",
      "Epoch: 2, Batch: 4800, Loss: 0.054, Accuracy: 97.09%\n",
      "Epoch: 2, Batch: 4900, Loss: 0.101, Accuracy: 97.11%\n",
      "Epoch: 2, Batch: 5000, Loss: 0.102, Accuracy: 97.11%\n",
      "Epoch: 2, Batch: 5100, Loss: 0.085, Accuracy: 97.11%\n",
      "Epoch: 2, Batch: 5200, Loss: 0.066, Accuracy: 97.12%\n",
      "Epoch: 2, Batch: 5300, Loss: 0.088, Accuracy: 97.14%\n",
      "Epoch: 2, Batch: 5400, Loss: 0.083, Accuracy: 97.15%\n",
      "Epoch: 2, Batch: 5500, Loss: 0.079, Accuracy: 97.15%\n",
      "Epoch: 2, Batch: 5600, Loss: 0.076, Accuracy: 97.17%\n",
      "Epoch: 2, Batch: 5700, Loss: 0.058, Accuracy: 97.19%\n",
      "Epoch: 2, Batch: 5800, Loss: 0.082, Accuracy: 97.20%\n",
      "Epoch: 2, Batch: 5900, Loss: 0.084, Accuracy: 97.21%\n",
      "Epoch: 2, Batch: 6000, Loss: 0.052, Accuracy: 97.23%\n",
      "Epoch: 2, Batch: 6100, Loss: 0.052, Accuracy: 97.24%\n",
      "Epoch: 2, Batch: 6200, Loss: 0.091, Accuracy: 97.25%\n",
      "Epoch: 2, Batch: 6300, Loss: 0.068, Accuracy: 97.25%\n",
      "Epoch: 2, Batch: 6400, Loss: 0.057, Accuracy: 97.27%\n",
      "Epoch: 2, Batch: 6500, Loss: 0.081, Accuracy: 97.27%\n",
      "Epoch: 2, Batch: 6600, Loss: 0.059, Accuracy: 97.28%\n",
      "Epoch: 2, Batch: 6700, Loss: 0.114, Accuracy: 97.28%\n",
      "Epoch: 2, Batch: 6800, Loss: 0.104, Accuracy: 97.28%\n",
      "Epoch: 2, Batch: 6900, Loss: 0.102, Accuracy: 97.26%\n",
      "Epoch: 2, Batch: 7000, Loss: 0.100, Accuracy: 97.26%\n",
      "Epoch: 2, Batch: 7100, Loss: 0.063, Accuracy: 97.27%\n",
      "Epoch: 2, Batch: 7200, Loss: 0.089, Accuracy: 97.27%\n",
      "Epoch: 2, Batch: 7300, Loss: 0.045, Accuracy: 97.28%\n",
      "Epoch: 2, Batch: 7400, Loss: 0.069, Accuracy: 97.30%\n",
      "Epoch: 2, Batch: 7500, Loss: 0.056, Accuracy: 97.30%\n",
      "Train Accuracy: 97.30%\n",
      "Test Accuracy: 97.41%\n",
      "ConvDeepModel a 146490 param√®tres\n",
      "ConvModel original a 13610 param√®tres\n"
     ]
    }
   ],
   "source": [
    "class ConvDeepModel(torch.nn.Module):\n",
    "    def __init__(self, h=100):\n",
    "        super(ConvDeepModel, self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.flat_features = 1352\n",
    "        self.fc1 = torch.nn.Linear(self.flat_features, h)\n",
    "        self.fc2 = torch.nn.Linear(h, h)\n",
    "        self.fc3 = torch.nn.Linear(h, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = x.view(-1, self.flat_features)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model_conv_deep = ConvDeepModel(h=100).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_conv_deep = torch.optim.Adam(model_conv_deep.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCH + 1):\n",
    "    optimizer_conv_deep, train_acc = train(model_conv_deep, epoch, identity_preprocess, optimizer_conv_deep)\n",
    "    test_acc = test(model_conv_deep, identity_preprocess)\n",
    "\n",
    "\n",
    "print(f\"ConvDeepModel a {sum(p.numel() for p in model_conv_deep.parameters())} param√®tres\")\n",
    "print(f\"ConvModel original a {sum(p.numel() for p in model_conv.parameters())} param√®tres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe39ddf4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46fd763b-b36a-461c-ad34-f472e62ce46d",
   "metadata": {},
   "source": [
    "## A.6 Visualisations of convolutions\n",
    "\n",
    "After training your model, let's see what features it has learned!\n",
    "\n",
    "Plot an image from the test set then plot all 8 feature maps extracted by the convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c8f281d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_image_and_feature_maps(model, test_loader, device):\n",
    "    data_iter = iter(test_loader)  \n",
    "    image, label = next(data_iter)\n",
    "    image = image.to(device)\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image[0].cpu().numpy().squeeze())\n",
    "    plt.title(f'Label: {label[0].item()}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    conv_layer = model.conv\n",
    "    feature_maps = conv_layer(image) \n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(8):\n",
    "        plt.subplot(2, 4, i+1)\n",
    "        plt.imshow(feature_maps[0, i].cpu().detach().numpy())\n",
    "        plt.title(f'Feature map {i+1}')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plot_image_and_feature_maps(model_conv_deep, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc457ad1-3240-4ffb-a8f3-98c6554dfce5",
   "metadata": {
    "id": "riu_K1at3z0R"
   },
   "source": [
    "# Part B - Residual models\n",
    "\n",
    "## B.1 - Residual blocks\n",
    "\n",
    "Write a residual block with two linear layers to learn a function $\\mathbb{R}^d \\to \\mathbb{R}^d$ with $h < d$ hidden neurons.\n",
    "Write a convolutional residual block with the same idea. What hyperparameter acts as the number of hidden neurons in convolutional blocks ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aec298d4-4372-4a1f-be53-a278d051c0f6",
   "metadata": {
    "id": "gkCILVwd3z0R"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(torch.nn.Module):\n",
    "    def __init__(self, d, h):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(d, h)\n",
    "        self.linear2 = torch.nn.Linear(h, d)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = out + identity\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7e92a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvResidualBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(ConvResidualBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.relu = nn.ReLU()    \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        x = self.conv1(x)  \n",
    "        x = self.relu(x)  \n",
    "        x = self.conv2(x)  \n",
    "        x += identity \n",
    "        x = self.relu(x)\n",
    "    \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d29a3b",
   "metadata": {},
   "source": [
    "Out_channels repr√©sente le nombre de filtres de sortie dans la couche convolutionnelle et ca repr√©sente aussi le nombre de neurones cach√©s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc0097d-269c-40f4-b182-bdc79bd5c512",
   "metadata": {
    "id": "huKWOvVc3z0S"
   },
   "source": [
    "## B.2 - Stacking residual blocks\n",
    "\n",
    "Use a single convolution layer, followed by a relu and max-pool, then an arbitrary number of residual blocks as defined above, and finish with a linear layer. Can you match the accuracy of the two-layer network ? Can you exceed it ? What happens when you increase the number of layers ? Look at the details of the ResNet architecture on the lecture's slides to get an idea of how to increase the number of hidden neurons and the number of layers. One of the strengths of ResNets was there relatively low number of parameters compared\n",
    "to a multi-layer architecture like that of the previous section, does this show in your experiments ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf0d4de4-11e8-490c-8262-064b3e841fa5",
   "metadata": {
    "id": "U4gg9uWg3z0S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 100, Loss: 1.345, Accuracy: 57.12%\n",
      "Epoch: 1, Batch: 200, Loss: 0.545, Accuracy: 69.94%\n",
      "Epoch: 1, Batch: 300, Loss: 0.456, Accuracy: 75.58%\n",
      "Epoch: 1, Batch: 400, Loss: 0.295, Accuracy: 79.50%\n",
      "Epoch: 1, Batch: 500, Loss: 0.346, Accuracy: 81.80%\n",
      "Epoch: 1, Batch: 600, Loss: 0.306, Accuracy: 83.29%\n",
      "Epoch: 1, Batch: 700, Loss: 0.226, Accuracy: 84.66%\n",
      "Epoch: 1, Batch: 800, Loss: 0.185, Accuracy: 85.92%\n",
      "Epoch: 1, Batch: 900, Loss: 0.199, Accuracy: 86.81%\n",
      "Epoch: 1, Batch: 1000, Loss: 0.220, Accuracy: 87.46%\n",
      "Epoch: 1, Batch: 1100, Loss: 0.188, Accuracy: 88.06%\n",
      "Epoch: 1, Batch: 1200, Loss: 0.141, Accuracy: 88.62%\n",
      "Epoch: 1, Batch: 1300, Loss: 0.151, Accuracy: 89.12%\n",
      "Epoch: 1, Batch: 1400, Loss: 0.174, Accuracy: 89.51%\n",
      "Epoch: 1, Batch: 1500, Loss: 0.138, Accuracy: 89.96%\n",
      "Epoch: 1, Batch: 1600, Loss: 0.137, Accuracy: 90.33%\n",
      "Epoch: 1, Batch: 1700, Loss: 0.111, Accuracy: 90.71%\n",
      "Epoch: 1, Batch: 1800, Loss: 0.160, Accuracy: 90.93%\n",
      "Epoch: 1, Batch: 1900, Loss: 0.124, Accuracy: 91.16%\n",
      "Epoch: 1, Batch: 2000, Loss: 0.111, Accuracy: 91.45%\n",
      "Epoch: 1, Batch: 2100, Loss: 0.085, Accuracy: 91.70%\n",
      "Epoch: 1, Batch: 2200, Loss: 0.137, Accuracy: 91.90%\n",
      "Epoch: 1, Batch: 2300, Loss: 0.082, Accuracy: 92.15%\n",
      "Epoch: 1, Batch: 2400, Loss: 0.083, Accuracy: 92.38%\n",
      "Epoch: 1, Batch: 2500, Loss: 0.136, Accuracy: 92.53%\n",
      "Epoch: 1, Batch: 2600, Loss: 0.152, Accuracy: 92.66%\n",
      "Epoch: 1, Batch: 2700, Loss: 0.102, Accuracy: 92.81%\n",
      "Epoch: 1, Batch: 2800, Loss: 0.104, Accuracy: 92.98%\n",
      "Epoch: 1, Batch: 2900, Loss: 0.092, Accuracy: 93.11%\n",
      "Epoch: 1, Batch: 3000, Loss: 0.073, Accuracy: 93.26%\n",
      "Epoch: 1, Batch: 3100, Loss: 0.109, Accuracy: 93.39%\n",
      "Epoch: 1, Batch: 3200, Loss: 0.127, Accuracy: 93.49%\n",
      "Epoch: 1, Batch: 3300, Loss: 0.066, Accuracy: 93.62%\n",
      "Epoch: 1, Batch: 3400, Loss: 0.130, Accuracy: 93.72%\n",
      "Epoch: 1, Batch: 3500, Loss: 0.087, Accuracy: 93.81%\n",
      "Epoch: 1, Batch: 3600, Loss: 0.089, Accuracy: 93.92%\n",
      "Epoch: 1, Batch: 3700, Loss: 0.073, Accuracy: 94.02%\n",
      "Epoch: 1, Batch: 3800, Loss: 0.100, Accuracy: 94.11%\n",
      "Epoch: 1, Batch: 3900, Loss: 0.091, Accuracy: 94.18%\n",
      "Epoch: 1, Batch: 4000, Loss: 0.095, Accuracy: 94.26%\n",
      "Epoch: 1, Batch: 4100, Loss: 0.073, Accuracy: 94.34%\n",
      "Epoch: 1, Batch: 4200, Loss: 0.075, Accuracy: 94.40%\n",
      "Epoch: 1, Batch: 4300, Loss: 0.075, Accuracy: 94.48%\n",
      "Epoch: 1, Batch: 4400, Loss: 0.094, Accuracy: 94.55%\n",
      "Epoch: 1, Batch: 4500, Loss: 0.099, Accuracy: 94.59%\n",
      "Epoch: 1, Batch: 4600, Loss: 0.103, Accuracy: 94.63%\n",
      "Epoch: 1, Batch: 4700, Loss: 0.064, Accuracy: 94.70%\n",
      "Epoch: 1, Batch: 4800, Loss: 0.087, Accuracy: 94.76%\n",
      "Epoch: 1, Batch: 4900, Loss: 0.086, Accuracy: 94.82%\n",
      "Epoch: 1, Batch: 5000, Loss: 0.133, Accuracy: 94.84%\n",
      "Epoch: 1, Batch: 5100, Loss: 0.059, Accuracy: 94.91%\n",
      "Epoch: 1, Batch: 5200, Loss: 0.066, Accuracy: 94.97%\n",
      "Epoch: 1, Batch: 5300, Loss: 0.073, Accuracy: 95.02%\n",
      "Epoch: 1, Batch: 5400, Loss: 0.081, Accuracy: 95.06%\n",
      "Epoch: 1, Batch: 5500, Loss: 0.064, Accuracy: 95.12%\n",
      "Epoch: 1, Batch: 5600, Loss: 0.083, Accuracy: 95.15%\n",
      "Epoch: 1, Batch: 5700, Loss: 0.082, Accuracy: 95.19%\n",
      "Epoch: 1, Batch: 5800, Loss: 0.102, Accuracy: 95.22%\n",
      "Epoch: 1, Batch: 5900, Loss: 0.063, Accuracy: 95.26%\n",
      "Epoch: 1, Batch: 6000, Loss: 0.059, Accuracy: 95.32%\n",
      "Epoch: 1, Batch: 6100, Loss: 0.073, Accuracy: 95.36%\n",
      "Epoch: 1, Batch: 6200, Loss: 0.050, Accuracy: 95.40%\n",
      "Epoch: 1, Batch: 6300, Loss: 0.088, Accuracy: 95.43%\n",
      "Epoch: 1, Batch: 6400, Loss: 0.047, Accuracy: 95.48%\n",
      "Epoch: 1, Batch: 6500, Loss: 0.087, Accuracy: 95.53%\n",
      "Epoch: 1, Batch: 6600, Loss: 0.091, Accuracy: 95.55%\n",
      "Epoch: 1, Batch: 6700, Loss: 0.073, Accuracy: 95.59%\n",
      "Epoch: 1, Batch: 6800, Loss: 0.070, Accuracy: 95.62%\n",
      "Epoch: 1, Batch: 6900, Loss: 0.065, Accuracy: 95.66%\n",
      "Epoch: 1, Batch: 7000, Loss: 0.071, Accuracy: 95.68%\n",
      "Epoch: 1, Batch: 7100, Loss: 0.049, Accuracy: 95.72%\n",
      "Epoch: 1, Batch: 7200, Loss: 0.047, Accuracy: 95.76%\n",
      "Epoch: 1, Batch: 7300, Loss: 0.066, Accuracy: 95.79%\n",
      "Epoch: 1, Batch: 7400, Loss: 0.085, Accuracy: 95.81%\n",
      "Epoch: 1, Batch: 7500, Loss: 0.067, Accuracy: 95.84%\n",
      "Train Accuracy: 95.84%\n",
      "Test Accuracy: 97.97%\n",
      "Epoch: 2, Batch: 100, Loss: 0.043, Accuracy: 98.62%\n",
      "Epoch: 2, Batch: 200, Loss: 0.040, Accuracy: 98.75%\n",
      "Epoch: 2, Batch: 300, Loss: 0.053, Accuracy: 98.67%\n",
      "Epoch: 2, Batch: 400, Loss: 0.033, Accuracy: 98.69%\n",
      "Epoch: 2, Batch: 500, Loss: 0.062, Accuracy: 98.47%\n",
      "Epoch: 2, Batch: 600, Loss: 0.071, Accuracy: 98.35%\n",
      "Epoch: 2, Batch: 700, Loss: 0.063, Accuracy: 98.34%\n",
      "Epoch: 2, Batch: 800, Loss: 0.041, Accuracy: 98.41%\n",
      "Epoch: 2, Batch: 900, Loss: 0.046, Accuracy: 98.39%\n",
      "Epoch: 2, Batch: 1000, Loss: 0.058, Accuracy: 98.39%\n",
      "Epoch: 2, Batch: 1100, Loss: 0.050, Accuracy: 98.39%\n",
      "Epoch: 2, Batch: 1200, Loss: 0.043, Accuracy: 98.43%\n",
      "Epoch: 2, Batch: 1300, Loss: 0.055, Accuracy: 98.43%\n",
      "Epoch: 2, Batch: 1400, Loss: 0.070, Accuracy: 98.41%\n",
      "Epoch: 2, Batch: 1500, Loss: 0.072, Accuracy: 98.35%\n",
      "Epoch: 2, Batch: 1600, Loss: 0.028, Accuracy: 98.40%\n",
      "Epoch: 2, Batch: 1700, Loss: 0.043, Accuracy: 98.42%\n",
      "Epoch: 2, Batch: 1800, Loss: 0.050, Accuracy: 98.40%\n",
      "Epoch: 2, Batch: 1900, Loss: 0.065, Accuracy: 98.36%\n",
      "Epoch: 2, Batch: 2000, Loss: 0.040, Accuracy: 98.36%\n",
      "Epoch: 2, Batch: 2100, Loss: 0.045, Accuracy: 98.36%\n",
      "Epoch: 2, Batch: 2200, Loss: 0.057, Accuracy: 98.36%\n",
      "Epoch: 2, Batch: 2300, Loss: 0.085, Accuracy: 98.32%\n",
      "Epoch: 2, Batch: 2400, Loss: 0.066, Accuracy: 98.30%\n",
      "Epoch: 2, Batch: 2500, Loss: 0.046, Accuracy: 98.31%\n",
      "Epoch: 2, Batch: 2600, Loss: 0.058, Accuracy: 98.32%\n",
      "Epoch: 2, Batch: 2700, Loss: 0.043, Accuracy: 98.33%\n",
      "Epoch: 2, Batch: 2800, Loss: 0.038, Accuracy: 98.34%\n",
      "Epoch: 2, Batch: 2900, Loss: 0.052, Accuracy: 98.34%\n",
      "Epoch: 2, Batch: 3000, Loss: 0.096, Accuracy: 98.30%\n",
      "Epoch: 2, Batch: 3100, Loss: 0.076, Accuracy: 98.29%\n",
      "Epoch: 2, Batch: 3200, Loss: 0.053, Accuracy: 98.29%\n",
      "Epoch: 2, Batch: 3300, Loss: 0.042, Accuracy: 98.30%\n",
      "Epoch: 2, Batch: 3400, Loss: 0.092, Accuracy: 98.28%\n",
      "Epoch: 2, Batch: 3500, Loss: 0.044, Accuracy: 98.29%\n",
      "Epoch: 2, Batch: 3600, Loss: 0.035, Accuracy: 98.30%\n",
      "Epoch: 2, Batch: 3700, Loss: 0.035, Accuracy: 98.31%\n",
      "Epoch: 2, Batch: 3800, Loss: 0.068, Accuracy: 98.31%\n",
      "Epoch: 2, Batch: 3900, Loss: 0.060, Accuracy: 98.29%\n",
      "Epoch: 2, Batch: 4000, Loss: 0.056, Accuracy: 98.28%\n",
      "Epoch: 2, Batch: 4100, Loss: 0.053, Accuracy: 98.28%\n",
      "Epoch: 2, Batch: 4200, Loss: 0.032, Accuracy: 98.30%\n",
      "Epoch: 2, Batch: 4300, Loss: 0.036, Accuracy: 98.31%\n",
      "Epoch: 2, Batch: 4400, Loss: 0.046, Accuracy: 98.31%\n",
      "Epoch: 2, Batch: 4500, Loss: 0.071, Accuracy: 98.31%\n",
      "Epoch: 2, Batch: 4600, Loss: 0.035, Accuracy: 98.33%\n",
      "Epoch: 2, Batch: 4700, Loss: 0.050, Accuracy: 98.33%\n",
      "Epoch: 2, Batch: 4800, Loss: 0.061, Accuracy: 98.33%\n",
      "Epoch: 2, Batch: 4900, Loss: 0.062, Accuracy: 98.33%\n",
      "Epoch: 2, Batch: 5000, Loss: 0.062, Accuracy: 98.32%\n",
      "Epoch: 2, Batch: 5100, Loss: 0.053, Accuracy: 98.31%\n",
      "Epoch: 2, Batch: 5200, Loss: 0.060, Accuracy: 98.31%\n",
      "Epoch: 2, Batch: 5300, Loss: 0.058, Accuracy: 98.31%\n",
      "Epoch: 2, Batch: 5400, Loss: 0.048, Accuracy: 98.32%\n",
      "Epoch: 2, Batch: 5500, Loss: 0.054, Accuracy: 98.33%\n",
      "Epoch: 2, Batch: 5600, Loss: 0.049, Accuracy: 98.33%\n",
      "Epoch: 2, Batch: 5700, Loss: 0.055, Accuracy: 98.32%\n",
      "Epoch: 2, Batch: 5800, Loss: 0.027, Accuracy: 98.33%\n",
      "Epoch: 2, Batch: 5900, Loss: 0.059, Accuracy: 98.33%\n",
      "Epoch: 2, Batch: 6000, Loss: 0.050, Accuracy: 98.34%\n",
      "Epoch: 2, Batch: 6100, Loss: 0.072, Accuracy: 98.33%\n",
      "Epoch: 2, Batch: 6200, Loss: 0.036, Accuracy: 98.34%\n",
      "Epoch: 2, Batch: 6300, Loss: 0.020, Accuracy: 98.36%\n",
      "Epoch: 2, Batch: 6400, Loss: 0.059, Accuracy: 98.36%\n",
      "Epoch: 2, Batch: 6500, Loss: 0.037, Accuracy: 98.36%\n",
      "Epoch: 2, Batch: 6600, Loss: 0.081, Accuracy: 98.35%\n",
      "Epoch: 2, Batch: 6700, Loss: 0.072, Accuracy: 98.35%\n",
      "Epoch: 2, Batch: 6800, Loss: 0.074, Accuracy: 98.35%\n",
      "Epoch: 2, Batch: 6900, Loss: 0.072, Accuracy: 98.34%\n",
      "Epoch: 2, Batch: 7000, Loss: 0.031, Accuracy: 98.35%\n",
      "Epoch: 2, Batch: 7100, Loss: 0.041, Accuracy: 98.35%\n",
      "Epoch: 2, Batch: 7200, Loss: 0.047, Accuracy: 98.35%\n",
      "Epoch: 2, Batch: 7300, Loss: 0.045, Accuracy: 98.36%\n",
      "Epoch: 2, Batch: 7400, Loss: 0.035, Accuracy: 98.36%\n",
      "Epoch: 2, Batch: 7500, Loss: 0.049, Accuracy: 98.36%\n",
      "Train Accuracy: 98.36%\n",
      "Test Accuracy: 98.67%\n"
     ]
    }
   ],
   "source": [
    "class ConvResidualModel(nn.Module):\n",
    "    def __init__(self, num_blocks=2, channels=8, hidden_dim=16, output_dim=10):\n",
    "        super(ConvResidualModel, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=channels, kernel_size=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.res_blocks = nn.Sequential(\n",
    "            *[ConvResidualBlock(channels, channels) for _ in range(num_blocks)]\n",
    "        )\n",
    "        self.flat_features = channels * 13 * 13\n",
    "        self.fc = nn.Linear(self.flat_features, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.res_blocks(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model_resnet = ConvResidualModel(num_blocks=3, channels=8).to(device)\n",
    "optimizer_resnet = torch.optim.Adam(model_resnet.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCH + 1):\n",
    "    optimizer_resnet, train_acc = train(model_resnet, epoch, identity_preprocess, optimizer_resnet)\n",
    "    test_acc = test(model_resnet, identity_preprocess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127099ed",
   "metadata": {},
   "source": [
    "With only 2 epochs, the res model with 3 blocks can achieves the same accuracy or even better than a simple CNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df418703-b1e1-4276-8ba7-dd5622c7b7cd",
   "metadata": {
    "id": "2nes_ZtBoBu0"
   },
   "source": [
    "# Part C - Reimplementing loss functions\n",
    "\n",
    "## C.0 - Combining losses\n",
    "First, we recall that, for a batch of score vectors $s\\in\\mathbb{R}^{n\\times C}$ and true labels $y\\in[1,C]^n$, **cross entropy** is defined as\n",
    "$$CE(s, y) = -\\frac{1}{n}\\sum_{i=1}^n \\log\\left( \\mbox{softmax}(s_i)_{y_i} \\right)$$\n",
    "\n",
    "where $\\mbox{softmax}(x)_i = \\frac{e^{x_i}}{\\sum_{j=1}^n e^{x_j}}$ is the probability associated to class $i\\in[1,C]$ for a score vector $x\\in\\mathbb{R}^C$.\n",
    "\n",
    "Let's try to compute cross-entropy in three different ways (see the [documentation](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)):\n",
    "1. Using `nn.CrossEntropyLoss()`.\n",
    "2. Using `nn.NLLLoss()` and `nn.LogSoftmax()`.\n",
    "3. Using `nn.NLLLoss()` and `nn.Softmax()`.\n",
    "\n",
    "Check that the output is the same for all three methods on Gaussian random scores `torch.randn(n_batch, n_classes)` and random labels `torch.randint(0, n_classes, [n_batch])`, where `n_batch=4` and `n_classes=10`. Note that the scores are real valued vectors while the labels are integers corresponding to the true class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1b6c172",
   "metadata": {
    "id": "e1b6c172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss: 2.907355785369873\n",
      "NLLLoss + LogSoftmax: 2.907355785369873\n",
      "NLLLoss + Softmax + Log: 2.907355785369873\n"
     ]
    }
   ],
   "source": [
    "n_batch = 4\n",
    "n_classes = 10\n",
    "\n",
    "scores = torch.randn(n_batch, n_classes)\n",
    "\n",
    "labels = torch.randint(0, n_classes, [n_batch])\n",
    "\n",
    "cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "loss_ce = cross_entropy_loss(scores, labels)\n",
    "\n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "scores_log = log_softmax(scores)\n",
    "nll_loss = nn.NLLLoss()\n",
    "loss_log_softmax = nll_loss(scores_log, labels)\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "scores_softmax = softmax(scores)\n",
    "scores_log2 = torch.log(scores_softmax)\n",
    "loss_softmax = nll_loss(scores_log2, labels)\n",
    "\n",
    "print(f\"CrossEntropyLoss: {loss_ce.item()}\")\n",
    "print(f\"NLLLoss + LogSoftmax: {loss_log_softmax.item()}\")\n",
    "print(f\"NLLLoss + Softmax + Log: {loss_softmax.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba900c6-f7b2-4179-a2f1-f1eede4b6697",
   "metadata": {
    "id": "TWKaTBVd5ftN"
   },
   "source": [
    "## C.1 - Re-implementation\n",
    "Now re-implement cross-entropy using base functions (`torch.log`, `torch.exp`, `torch.sum`, etc...). Verify that your function returns the same value as Pytorch's implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41f17f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My loss: 1.8601641654968262\n",
      "PyTorch loss: 1.8601644039154053\n"
     ]
    }
   ],
   "source": [
    "def ce(logits, targets):\n",
    "    log_probs = logits - torch.log(torch.sum(torch.exp(logits), dim=1, keepdim=True))\n",
    "    selected_log_probs = log_probs[torch.arange(len(targets)), targets]\n",
    "    loss = -torch.mean(selected_log_probs)\n",
    "    return loss\n",
    "\n",
    "logits = torch.tensor([[5.0, 5.0, 5.1],\n",
    "                       [5., 2.5, 0.3]], requires_grad=True)\n",
    "targets = torch.tensor([0, 1])\n",
    "\n",
    "my_loss = ce(logits, targets)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "torch_loss = criterion(logits, targets)\n",
    "\n",
    "print(\"My loss:\", my_loss.item())\n",
    "print(\"PyTorch loss:\", torch_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ec13a-330a-4073-99b9-2eb9dd42d1f8",
   "metadata": {
    "id": "OFG0QfKN7WtO"
   },
   "source": [
    "## C.2 - Stability analysis\n",
    "Softmax probabilities can be relatively unstable due to their use of exponentials. Pytorch implementations thus usually use log probas or logits to avoid overflows or floating point errors. Test all methods (including your own) on Gaussian random scores of standard deviation equal to $100$. Which methods are stable? Why? Is it an issue in practice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "741771f5-864d-446a-b654-3b4f5a2598ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. CrossEntropyLoss: 153.29978942871094\n",
      "2. NLLLoss + LogSoftmax: 153.29978942871094\n",
      "3. NLLLoss + Softmax + Log: inf\n",
      "4. Custom implementation: inf\n"
     ]
    }
   ],
   "source": [
    "n_batch = 4\n",
    "n_classes = 10\n",
    "\n",
    "\n",
    "gauss_rand = torch.randn(n_batch, n_classes) * 100\n",
    "labels = torch.randint(0, n_classes, [n_batch])\n",
    "\n",
    "try:\n",
    "    cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "    loss_ce = cross_entropy_loss(gauss_rand, labels)\n",
    "    print(f\"1. CrossEntropyLoss: {loss_ce.item()}\")\n",
    "except Exception as e:\n",
    "    print(f\"1. CrossEntropyLoss failed: {e}\")\n",
    "\n",
    "try:\n",
    "    log_softmax = nn.LogSoftmax(dim=1)\n",
    "    scores_log = log_softmax(gauss_rand)\n",
    "    nll_loss = nn.NLLLoss()\n",
    "    loss_log_softmax = nll_loss(scores_log, labels)\n",
    "    print(f\"2. NLLLoss + LogSoftmax: {loss_log_softmax.item()}\")\n",
    "except Exception as e:\n",
    "    print(f\"2. NLLLoss + LogSoftmax failed: {e}\")\n",
    "\n",
    "try:\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    scores_softmax = softmax(gauss_rand)\n",
    "    scores_log2 = torch.log(scores_softmax)\n",
    "    loss_softmax = nll_loss(scores_log2, labels)\n",
    "    print(f\"3. NLLLoss + Softmax + Log: {loss_softmax.item()}\")\n",
    "except Exception as e:\n",
    "    print(f\"3. NLLLoss + Softmax + Log failed: {e}\")\n",
    "\n",
    "try:\n",
    "    my_loss = ce(gauss_rand, labels)\n",
    "    print(f\"4. Custom implementation: {my_loss.item()}\")\n",
    "except Exception as e:\n",
    "    print(f\"4. Custom implementation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788ca474",
   "metadata": {},
   "source": [
    "Cross entropy loss and NLLLoss + logsoftmax are both stable the others aren't because the exponential function is calculated first and the numbers can get too big."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecaaf7c-b21f-4e18-ac53-1a77adbc60bf",
   "metadata": {
    "id": "Y3y4BfwbBIGy"
   },
   "source": [
    "Re-implement a stable version of cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83d00dab-a37e-48da-880f-81f10efdc133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_ce(logits, targets):\n",
    "    max_logits = torch.max(logits, dim=1, keepdim=True)[0]\n",
    "    logits_stable = logits - max_logits\n",
    "    \n",
    "    exp_logits = torch.exp(logits_stable)\n",
    "    sum_exp_logits = torch.sum(exp_logits, dim=1, keepdim=True)\n",
    "    log_probs = logits_stable - torch.log(sum_exp_logits)\n",
    "    \n",
    "    selected_log_probs = log_probs[torch.arange(len(targets)), targets]\n",
    "    \n",
    "    loss = -torch.mean(selected_log_probs)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7cc0e989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Stable custom implementation: 153.29978942871094\n"
     ]
    }
   ],
   "source": [
    "stable_loss = stable_ce(gauss_rand, labels)\n",
    "print(f\"5. Stable custom implementation: {stable_loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackaton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
